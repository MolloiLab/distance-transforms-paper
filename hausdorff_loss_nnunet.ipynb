{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"T4","authorship_tag":"ABX9TyPzl9nFdzJfT1EV2aR0oEp1"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GiOW_on7ohah","executionInfo":{"status":"ok","timestamp":1721252402899,"user_tz":420,"elapsed":37945,"user":{"displayName":"Dale Black","userId":"06644162883191190715"}},"outputId":"335c6e11-fe77-4f96-fdba-0fce087631a6"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["!python3 -c \"import monai\" || pip install -q \"monai\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1uzhSdbApJUf","executionInfo":{"status":"ok","timestamp":1721252559396,"user_tz":420,"elapsed":56636,"user":{"displayName":"Dale Black","userId":"06644162883191190715"}},"outputId":"b089279c-0c03-4123-f4cc-707230cc3e3d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Traceback (most recent call last):\n","  File \"<string>\", line 1, in <module>\n","ModuleNotFoundError: No module named 'monai'\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m73.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}]},{"cell_type":"code","source":["import os\n","import json\n","import random\n","import shutil\n","import tempfile\n","from monai.config import print_config\n","from monai.apps import download_and_extract"],"metadata":{"id":"LFPJXM_EpPSH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["directory = os.environ.get(\"MONAI_DATA_DIRECTORY\")\n","if directory is not None:\n","    os.makedirs(directory, exist_ok=True)\n","root_dir = tempfile.mkdtemp() if directory is None else directory\n","print(root_dir)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ur8_5q3QpSPH","executionInfo":{"status":"ok","timestamp":1721252571168,"user_tz":420,"elapsed":2,"user":{"displayName":"Dale Black","userId":"06644162883191190715"}},"outputId":"3f3c1b22-6b63-487f-effd-f09b0c68c2dc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/tmp/tmptwamkqlu\n"]}]},{"cell_type":"code","source":["msd_task = \"Task09_Spleen\"\n","resource = \"https://msd-for-monai.s3-us-west-2.amazonaws.com/\" + msd_task + \".tar\"\n","\n","compressed_file = os.path.join(root_dir, msd_task + \".tar\")\n","dataroot = os.path.join(root_dir, msd_task)\n","\n","if not os.path.exists(dataroot):\n","    download_and_extract(resource, compressed_file, root_dir)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_ntlJPr4pV12","executionInfo":{"status":"ok","timestamp":1721252667657,"user_tz":420,"elapsed":94521,"user":{"displayName":"Dale Black","userId":"06644162883191190715"}},"outputId":"587ba209-4bdb-47d7-fbe6-c647ee63785d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Task09_Spleen.tar: 1.50GB [01:32, 17.3MB/s]                            "]},{"output_type":"stream","name":"stdout","text":["2024-07-17 21:44:25,048 - INFO - Downloaded: /tmp/tmptwamkqlu/Task09_Spleen.tar\n","2024-07-17 21:44:25,049 - INFO - Expected md5 is None, skip md5 check for file /tmp/tmptwamkqlu/Task09_Spleen.tar.\n","2024-07-17 21:44:25,050 - INFO - Writing into directory: /tmp/tmptwamkqlu.\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"code","source":["!git clone https://github.com/MIC-DKFZ/nnUNet.git"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"r4zAayoupX08","executionInfo":{"status":"ok","timestamp":1722034828251,"user_tz":420,"elapsed":3018,"user":{"displayName":"Dale Black","userId":"06644162883191190715"}},"outputId":"a91c5d8c-587c-4f67-dbbd-923120e6a2d4"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'nnUNet'...\n","remote: Enumerating objects: 12735, done.\u001b[K\n","remote: Counting objects: 100% (18/18), done.\u001b[K\n","remote: Compressing objects: 100% (14/14), done.\u001b[K\n","remote: Total 12735 (delta 8), reused 12 (delta 4), pack-reused 12717\u001b[K\n","Receiving objects: 100% (12735/12735), 7.71 MiB | 14.43 MiB/s, done.\n","Resolving deltas: 100% (9769/9769), done.\n"]}]},{"cell_type":"code","source":["!cd nnUNet && pip install -e ."],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hccZ1zW9qd9H","executionInfo":{"status":"ok","timestamp":1721253050678,"user_tz":420,"elapsed":31602,"user":{"displayName":"Dale Black","userId":"06644162883191190715"}},"outputId":"01179b66-6d9e-4a1b-fe9e-227bfac580d5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Obtaining file:///content/nnUNet\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n","  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: torch>=2.1.2 in /usr/local/lib/python3.10/dist-packages (from nnunetv2==2.5) (2.3.1+cu121)\n","Collecting acvl-utils<0.3,>=0.2 (from nnunetv2==2.5)\n","  Downloading acvl_utils-0.2.tar.gz (18 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting dynamic-network-architectures<0.4,>=0.3.1 (from nnunetv2==2.5)\n","  Downloading dynamic_network_architectures-0.3.1.tar.gz (20 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nnunetv2==2.5) (4.66.4)\n","Collecting dicom2nifti (from nnunetv2==2.5)\n","  Downloading dicom2nifti-2.4.11-py3-none-any.whl (43 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from nnunetv2==2.5) (1.11.4)\n","Collecting batchgenerators>=0.25 (from nnunetv2==2.5)\n","  Downloading batchgenerators-0.25.tar.gz (61 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.7/61.7 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from nnunetv2==2.5) (1.25.2)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from nnunetv2==2.5) (1.2.2)\n","Requirement already satisfied: scikit-image>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from nnunetv2==2.5) (0.19.3)\n","Collecting SimpleITK>=2.2.1 (from nnunetv2==2.5)\n","  Downloading SimpleITK-2.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (52.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.7/52.7 MB\u001b[0m \u001b[31m23.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from nnunetv2==2.5) (2.0.3)\n","Requirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from nnunetv2==2.5) (0.20.3)\n","Requirement already satisfied: tifffile in /usr/local/lib/python3.10/dist-packages (from nnunetv2==2.5) (2024.7.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from nnunetv2==2.5) (2.31.0)\n","Requirement already satisfied: nibabel in /usr/local/lib/python3.10/dist-packages (from nnunetv2==2.5) (4.0.2)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from nnunetv2==2.5) (3.7.1)\n","Requirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (from nnunetv2==2.5) (0.13.1)\n","Collecting imagecodecs (from nnunetv2==2.5)\n","  Downloading imagecodecs-2024.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (39.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.5/39.5 MB\u001b[0m \u001b[31m42.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting yacs (from nnunetv2==2.5)\n","  Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n","Collecting batchgeneratorsv2 (from nnunetv2==2.5)\n","  Downloading batchgeneratorsv2-0.1.1.tar.gz (32 kB)\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Collecting einops (from nnunetv2==2.5)\n","  Downloading einops-0.8.0-py3-none-any.whl (43 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.2/43.2 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting connected-components-3d (from acvl-utils<0.3,>=0.2->nnunetv2==2.5)\n","  Downloading connected_components_3d-3.17.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m79.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from batchgenerators>=0.25->nnunetv2==2.5) (9.4.0)\n","Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from batchgenerators>=0.25->nnunetv2==2.5) (0.18.3)\n","Collecting unittest2 (from batchgenerators>=0.25->nnunetv2==2.5)\n","  Downloading unittest2-1.1.0-py2.py3-none-any.whl (96 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.4/96.4 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: threadpoolctl in /usr/local/lib/python3.10/dist-packages (from batchgenerators>=0.25->nnunetv2==2.5) (3.5.0)\n","Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.19.3->nnunetv2==2.5) (3.3)\n","Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.19.3->nnunetv2==2.5) (2.31.6)\n","Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.19.3->nnunetv2==2.5) (1.6.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.19.3->nnunetv2==2.5) (24.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.2->nnunetv2==2.5) (3.15.4)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.2->nnunetv2==2.5) (4.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.2->nnunetv2==2.5) (1.13.0)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.2->nnunetv2==2.5) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.2->nnunetv2==2.5) (2023.6.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.2->nnunetv2==2.5) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.2->nnunetv2==2.5) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.2->nnunetv2==2.5) (12.1.105)\n","Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.2->nnunetv2==2.5) (8.9.2.26)\n","Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.2->nnunetv2==2.5) (12.1.3.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.2->nnunetv2==2.5) (11.0.2.54)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.2->nnunetv2==2.5) (10.3.2.106)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.2->nnunetv2==2.5) (11.4.5.107)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.2->nnunetv2==2.5) (12.1.0.106)\n","Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.2->nnunetv2==2.5) (2.20.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.2->nnunetv2==2.5) (12.1.105)\n","Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.2->nnunetv2==2.5) (2.3.1)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=2.1.2->nnunetv2==2.5) (12.5.82)\n","Collecting fft-conv-pytorch (from batchgeneratorsv2->nnunetv2==2.5)\n","  Downloading fft_conv_pytorch-1.2.0-py3-none-any.whl (6.8 kB)\n","Collecting pydicom>=2.2.0 (from dicom2nifti->nnunetv2==2.5)\n","  Downloading pydicom-2.4.4-py3-none-any.whl (1.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m87.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting python-gdcm (from dicom2nifti->nnunetv2==2.5)\n","  Downloading python_gdcm-3.0.24.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m87.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->nnunetv2==2.5) (1.2.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->nnunetv2==2.5) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->nnunetv2==2.5) (4.53.1)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->nnunetv2==2.5) (1.4.5)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->nnunetv2==2.5) (3.1.2)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->nnunetv2==2.5) (2.8.2)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nibabel->nnunetv2==2.5) (67.7.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->nnunetv2==2.5) (2023.4)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->nnunetv2==2.5) (2024.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->nnunetv2==2.5) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->nnunetv2==2.5) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->nnunetv2==2.5) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->nnunetv2==2.5) (2024.7.4)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->nnunetv2==2.5) (1.4.2)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from yacs->nnunetv2==2.5) (6.0.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->nnunetv2==2.5) (1.16.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.1.2->nnunetv2==2.5) (2.1.5)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=2.1.2->nnunetv2==2.5) (1.3.0)\n","Collecting argparse (from unittest2->batchgenerators>=0.25->nnunetv2==2.5)\n","  Downloading argparse-1.4.0-py2.py3-none-any.whl (23 kB)\n","Collecting traceback2 (from unittest2->batchgenerators>=0.25->nnunetv2==2.5)\n","  Downloading traceback2-1.4.0-py2.py3-none-any.whl (16 kB)\n","Collecting linecache2 (from traceback2->unittest2->batchgenerators>=0.25->nnunetv2==2.5)\n","  Downloading linecache2-1.0.0-py2.py3-none-any.whl (12 kB)\n","Building wheels for collected packages: nnunetv2, acvl-utils, batchgenerators, dynamic-network-architectures, batchgeneratorsv2\n","  Building editable for nnunetv2 (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for nnunetv2: filename=nnunetv2-2.5-0.editable-py3-none-any.whl size=16624 sha256=32e19f978b485026bf2b736e87bb742a3368a87d66ce6f811a29595265097a6d\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-s7k8s3gm/wheels/66/a8/0c/d8553e2873068c742a2c91eadf0e7dbc86388a52232ce6319b\n","  Building wheel for acvl-utils (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for acvl-utils: filename=acvl_utils-0.2-py3-none-any.whl size=22439 sha256=f93b27871e0ae8992e791a33dc78153a89fe081db58140e9c5540f5d82df65a8\n","  Stored in directory: /root/.cache/pip/wheels/ad/f0/84/52e8897591e66339bd2796681b9540b6c5e453c1461fa92a9e\n","  Building wheel for batchgenerators (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for batchgenerators: filename=batchgenerators-0.25-py3-none-any.whl size=89007 sha256=44651f8b4445977bfee2c459db321e67623a922ae52aa6acd7a8261c5dcb16aa\n","  Stored in directory: /root/.cache/pip/wheels/9e/b0/1b/40912fb58eb167b86cbc444ddb2e6ba382b248215295f932e2\n","  Building wheel for dynamic-network-architectures (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for dynamic-network-architectures: filename=dynamic_network_architectures-0.3.1-py3-none-any.whl size=30049 sha256=50ba1a226fd31c9217bd83733b61c19b511e747298de8f762bfd1e635374e239\n","  Stored in directory: /root/.cache/pip/wheels/55/1b/13/a6419c8dbf998b9343710355ec3edc5c8e24d9b7b22eec95fb\n","  Building wheel for batchgeneratorsv2 (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for batchgeneratorsv2: filename=batchgeneratorsv2-0.1.1-py3-none-any.whl size=43534 sha256=ba505b47652a044a7f1840d666788b6ab4159b52dc7b352d342c456a634bbdab\n","  Stored in directory: /root/.cache/pip/wheels/86/6d/f1/6dc72a5516d434203da1a92c138e09a070a31cdff9bcaf1721\n","Successfully built nnunetv2 acvl-utils batchgenerators dynamic-network-architectures batchgeneratorsv2\n","Installing collected packages: SimpleITK, linecache2, argparse, yacs, traceback2, python-gdcm, pydicom, imagecodecs, einops, connected-components-3d, unittest2, dicom2nifti, batchgenerators, fft-conv-pytorch, dynamic-network-architectures, acvl-utils, batchgeneratorsv2, nnunetv2\n","Successfully installed SimpleITK-2.3.1 acvl-utils-0.2 argparse-1.4.0 batchgenerators-0.25 batchgeneratorsv2-0.1.1 connected-components-3d-3.17.0 dicom2nifti-2.4.11 dynamic-network-architectures-0.3.1 einops-0.8.0 fft-conv-pytorch-1.2.0 imagecodecs-2024.6.1 linecache2-1.0.0 nnunetv2-2.5 pydicom-2.4.4 python-gdcm-3.0.24.1 traceback2-1.4.0 unittest2-1.1.0 yacs-0.1.8\n"]}]},{"cell_type":"code","source":["import numpy as np\n","import glob as gb\n","import matplotlib.pyplot as plt\n","from tqdm import tqdm\n","import matplotlib\n","import time\n","import gc\n","import os\n","import copy\n","from collections import defaultdict\n","from scipy.ndimage import distance_transform_edt as edt\n","import shutil\n","import torch.nn.functional as F\n","from nnUNet.nnunetv2.dataset_conversion.generate_dataset_json import generate_dataset_json\n","import SimpleITK as sitk\n","from scipy import ndimage\n","import nibabel as nib\n","import pydicom\n","import ipywidgets as widgets\n","from IPython.display import display\n","import numpy as np\n","from ipywidgets import interact\n","from ipywidgets.widgets import IntSlider\n","import cv2\n","\n","id = 99"],"metadata":{"id":"ynDNCJYrrp-n"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def make_if_dont_exist(folder_path,overwrite=False):\n","    \"\"\"\n","    creates a folder if it does not exists\n","    input:\n","    folder_path : relative path of the folder which needs to be created\n","    over_write :(default: False) if True overwrite the existing folder\n","    \"\"\"\n","    if os.path.exists(folder_path):\n","        if overwrite:\n","            shutil.rmtree(folder_path)\n","            os.makedirs(folder_path)\n","    else:\n","        os.makedirs(folder_path)\n","\n","working_dir = \".\"\n","nnunet_dir = \"nn_UNet/nnUNet_raw\"\n","nnunet_prepocess = \"nn_UNet/nnUNet_preprocessed\"\n","nnunet_result = \"nn_UNet/nnUNet_results\"\n","task_name = f'Dataset0{id}_CHD'\n","main_dir = os.path.join(working_dir, nnunet_dir)\n","task_folder_name = os.path.join(main_dir, task_name)\n","train_image_dir = os.path.join(task_folder_name,'imagesTr')\n","train_label_dir = os.path.join(task_folder_name,'labelsTr')\n","test_dir = os.path.join(task_folder_name,'imagesTs')\n","for i in [main_dir, task_folder_name, train_image_dir, train_label_dir]:\n","    print(i)\n","    make_if_dont_exist(i)\n","make_if_dont_exist(nnunet_prepocess)\n","make_if_dont_exist(nnunet_result)\n","os.environ['nnUNet_raw'] = os.path.join(working_dir, nnunet_dir)\n","os.environ['nnUNet_preprocessed'] = os.path.join(working_dir, nnunet_prepocess)\n","os.environ['nnUNet_results'] = os.path.join(working_dir,nnunet_result)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dk_dXelhsIAn","executionInfo":{"status":"ok","timestamp":1721255716629,"user_tz":420,"elapsed":378,"user":{"displayName":"Dale Black","userId":"06644162883191190715"}},"outputId":"0c41f5b2-2848-4ab2-a66d-29fbcc386378"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["./nn_UNet/nnUNet_raw\n","./nn_UNet/nnUNet_raw/Dataset099_CHD\n","./nn_UNet/nnUNet_raw/Dataset099_CHD/imagesTr\n","./nn_UNet/nnUNet_raw/Dataset099_CHD/labelsTr\n"]}]},{"cell_type":"code","source":["test_dir = os.path.join(dataroot, \"imagesTs/\")\n","train_dir = os.path.join(dataroot, \"imagesTr/\")\n","label_dir = os.path.join(dataroot, \"labelsTr/\")\n","dataset = os.path.join(dataroot, \"dataset.json\")"],"metadata":{"id":"c-8Njkw_t2y_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def copy_and_format(in_file: str, out_file: str):\n","    img = sitk.ReadImage(in_file)\n","    sitk.WriteImage(img, out_file)\n","remove = len(\".nii.gz\")\n","for file in tqdm(os.listdir(train_dir)):\n","    flie_path = os.path.join(train_dir, file)\n","    if file.endswith(\".nii.gz\") and not file.startswith(\"._\"):\n","        dest = copy_and_format(flie_path, os.path.join(train_image_dir, file[:-remove] + \"_0000.nii\"))\n","\n","for file in tqdm(os.listdir(label_dir)):\n","    flie_path = os.path.join(label_dir, file)\n","    if file.endswith(\".nii.gz\") and not file.startswith(\"._\"):\n","        dest = copy_and_format(flie_path, os.path.join(train_label_dir, file[:-remove] + \".nii\"))\n","num_train = sum([len(x[2]) for x in list(os.walk(train_image_dir))])\n","print(num_train)\n","print(sum([len(x[2]) for x in list(os.walk(train_label_dir))]))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8fK_YtZ2vavH","executionInfo":{"status":"ok","timestamp":1721254704505,"user_tz":420,"elapsed":30678,"user":{"displayName":"Dale Black","userId":"06644162883191190715"}},"outputId":"dddd2e48-7e72-41cd-f840-7e74a676654b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 82/82 [00:29<00:00,  2.82it/s]\n","100%|██████████| 82/82 [00:01<00:00, 46.49it/s]"]},{"output_type":"stream","name":"stdout","text":["41\n","41\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"code","source":["labels = {\n","        \"background\": 0,\n","        \"spleen\": 1\n","    }\n","generate_dataset_json(task_folder_name, {0: 'RGB'}, labels, num_train, '.nii', overwrite_image_reader_writer='NibabelIO', dataset_name=task_name)"],"metadata":{"id":"S-HX-lIWxYin"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!nnUNetv2_plan_and_preprocess -d 0{id} --verify_dataset_integrity  -pl nnUNetPlannerResEncL"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"C7cHwELXwOjQ","executionInfo":{"status":"ok","timestamp":1721258133785,"user_tz":420,"elapsed":515636,"user":{"displayName":"Dale Black","userId":"06644162883191190715"}},"outputId":"5fd12739-27bb-4c0d-c4d3-9b7c83de6f6e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Fingerprint extraction...\n","Dataset099_CHD\n","Using <class 'nnunetv2.imageio.nibabel_reader_writer.NibabelIO'> reader/writer\n","\n","####################\n","verify_dataset_integrity Done. \n","If you didn't see any error messages then your dataset is most likely OK!\n","####################\n","\n","Experiment planning...\n","Attempting to find 3d_lowres config. \n","Current spacing: [1.60001004 0.81675806 0.81675806]. \n","Current patch size: (112, 256, 256). \n","Current median shape: [187.         497.08737864 497.08737864]\n","Attempting to find 3d_lowres config. \n","Current spacing: [1.64801034 0.8412608  0.8412608 ]. \n","Current patch size: (112, 256, 256). \n","Current median shape: [181.55339806 482.60910548 482.60910548]\n","Attempting to find 3d_lowres config. \n","Current spacing: [1.69745065 0.86649862 0.86649862]. \n","Current patch size: (112, 256, 256). \n","Current median shape: [176.26543501 468.55252959 468.55252959]\n","Attempting to find 3d_lowres config. \n","Current spacing: [1.74837417 0.89249358 0.89249358]. \n","Current patch size: (112, 256, 256). \n","Current median shape: [171.1314903  454.90536853 454.90536853]\n","Attempting to find 3d_lowres config. \n","Current spacing: [1.80082539 0.91926839 0.91926839]. \n","Current patch size: (112, 256, 256). \n","Current median shape: [166.14707796 441.6556976  441.6556976 ]\n","Attempting to find 3d_lowres config. \n","Current spacing: [1.85485016 0.94684644 0.94684644]. \n","Current patch size: (112, 256, 256). \n","Current median shape: [161.30784268 428.79193942 428.79193942]\n","Attempting to find 3d_lowres config. \n","Current spacing: [1.91049566 0.97525183 0.97525183]. \n","Current patch size: (112, 256, 256). \n","Current median shape: [156.609556   416.30285381 416.30285381]\n","Dropping 3d_lowres config because the image size difference to 3d_fullres is too small. 3d_fullres: [187. 512. 512.], 3d_lowres: [157, 416, 416]\n","2D U-Net configuration:\n","{'data_identifier': 'nnUNetPlans_2d', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 35, 'patch_size': (512, 512), 'median_image_size_in_voxels': array([512., 512.]), 'spacing': array([0.79296899, 0.79296899]), 'normalization_schemes': ['ZScoreNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.ResidualEncoderUNet', 'arch_kwargs': {'n_stages': 8, 'features_per_stage': (32, 64, 128, 256, 512, 512, 512, 512), 'conv_op': 'torch.nn.modules.conv.Conv2d', 'kernel_sizes': ((3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3)), 'strides': ((1, 1), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2)), 'n_blocks_per_stage': (1, 3, 4, 6, 6, 6, 6, 6), 'n_conv_per_stage_decoder': (1, 1, 1, 1, 1, 1, 1), 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm2d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ('conv_op', 'norm_op', 'dropout_op', 'nonlin')}, 'batch_dice': True}\n","\n","Using <class 'nnunetv2.imageio.nibabel_reader_writer.NibabelIO'> reader/writer\n","3D fullres U-Net configuration:\n","{'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': (80, 256, 256), 'median_image_size_in_voxels': array([187., 512., 512.]), 'spacing': array([1.60001004, 0.79296899, 0.79296899]), 'normalization_schemes': ['ZScoreNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.ResidualEncoderUNet', 'arch_kwargs': {'n_stages': 7, 'features_per_stage': (32, 64, 128, 256, 320, 320, 320), 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': ((1, 3, 3), (3, 3, 3), (3, 3, 3), (3, 3, 3), (3, 3, 3), (3, 3, 3), (3, 3, 3)), 'strides': ((1, 1, 1), (1, 2, 2), (2, 2, 2), (2, 2, 2), (2, 2, 2), (2, 2, 2), (1, 2, 2)), 'n_blocks_per_stage': (1, 3, 4, 6, 6, 6, 6), 'n_conv_per_stage_decoder': (1, 1, 1, 1, 1, 1), 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ('conv_op', 'norm_op', 'dropout_op', 'nonlin')}, 'batch_dice': False}\n","\n","Plans were saved to ./nn_UNet/nnUNet_preprocessed/Dataset099_CHD/nnUNetResEncUNetLPlans.json\n","Preprocessing...\n","Preprocessing dataset Dataset099_CHD\n","Configuration: 2d...\n","100% 41/41 [02:08<00:00,  3.14s/it]\n","Configuration: 3d_fullres...\n","100% 41/41 [05:57<00:00,  8.71s/it]\n","Configuration: 3d_lowres...\n","INFO: Configuration 3d_lowres not found in plans file nnUNetResEncUNetLPlans.json of dataset Dataset099_CHD. Skipping.\n"]}]},{"cell_type":"code","source":["# folder = os.path.join(working_dir, nnunet_prepocess, task_name, \"nnUNetPlans_3d_fullres\")\n","# for file in os.listdir(folder):\n","#     file_path = os.path.join(folder, file)\n","#     if file_path.endswith(\".npy\"):\n","#         os.remove(file_path)"],"metadata":{"id":"V3p6_vCi7Dg8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!nnUNetv2_train 0{id} 3d_fullres 0 -p nnUNetResEncUNetLPlans"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MehXxHJhwY7n","outputId":"134600f6-8c21-4345-9b02-9adaea20f4b6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Using device: cuda:0\n","\n","#######################################################################\n","Please cite the following paper when using nnU-Net:\n","Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.\n","#######################################################################\n","\n","2024-07-17 23:20:50.615744: do_dummy_2d_data_aug: True\n","2024-07-17 23:20:50.616250: Using splits from existing split file: ./nn_UNet/nnUNet_preprocessed/Dataset099_CHD/splits_final.json\n","2024-07-17 23:20:50.616452: The split file contains 5 splits.\n","2024-07-17 23:20:50.616509: Desired fold for training: 0\n","2024-07-17 23:20:50.616555: This split has 32 training and 9 validation cases.\n","using pin_memory on device 0\n","using pin_memory on device 0\n","2024-07-17 23:21:14.082734: Using torch.compile...\n","/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n","  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n","\n","This is the configuration used by this training:\n","Configuration name: 3d_fullres\n"," {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': [80, 256, 256], 'median_image_size_in_voxels': [187.0, 512.0, 512.0], 'spacing': [1.6000100374221802, 0.7929689884185791, 0.7929689884185791], 'normalization_schemes': ['ZScoreNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.ResidualEncoderUNet', 'arch_kwargs': {'n_stages': 7, 'features_per_stage': [32, 64, 128, 256, 320, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[1, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [1, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [1, 2, 2]], 'n_blocks_per_stage': [1, 3, 4, 6, 6, 6, 6], 'n_conv_per_stage_decoder': [1, 1, 1, 1, 1, 1], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}, 'deep_supervision': True}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': False} \n","\n","These are the global plan.json settings:\n"," {'dataset_name': 'Dataset099_CHD', 'plans_name': 'nnUNetResEncUNetLPlans', 'original_median_spacing_after_transp': [5.0, 0.7929689884185791, 0.7929689884185791], 'original_median_shape_after_transp': [90, 512, 512], 'image_reader_writer': 'NibabelIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'nnUNetPlannerResEncL', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 1038.0, 'mean': 93.19259643554688, 'median': 97.0, 'min': -620.0, 'percentile_00_5': -42.0, 'percentile_99_5': 176.0, 'std': 40.78370666503906}}} \n","\n","2024-07-17 23:21:14.896966: unpacking dataset...\n","2024-07-17 23:21:51.565452: unpacking done...\n","2024-07-17 23:21:51.567706: Unable to plot network architecture: nnUNet_compile is enabled!\n","2024-07-17 23:21:51.578909: \n","2024-07-17 23:21:51.579204: Epoch 0\n","2024-07-17 23:21:51.579414: Current learning rate: 0.01\n","2024-07-17 23:26:49.925654: train_loss -0.0564\n","2024-07-17 23:26:49.925909: val_loss -0.1446\n","2024-07-17 23:26:49.926056: Pseudo dice [0.3956]\n","2024-07-17 23:26:49.926168: Epoch time: 298.35 s\n","2024-07-17 23:26:49.926240: Yayy! New best EMA pseudo Dice: 0.3956\n","2024-07-17 23:26:53.011564: \n","2024-07-17 23:26:53.011989: Epoch 1\n","2024-07-17 23:26:53.012177: Current learning rate: 0.00999\n","2024-07-17 23:28:35.475758: train_loss -0.3146\n","2024-07-17 23:28:35.476066: val_loss -0.3254\n","2024-07-17 23:28:35.476205: Pseudo dice [0.6217]\n","2024-07-17 23:28:35.476351: Epoch time: 102.47 s\n","2024-07-17 23:28:35.476473: Yayy! New best EMA pseudo Dice: 0.4182\n","2024-07-17 23:28:39.075489: \n","2024-07-17 23:28:39.075818: Epoch 2\n","2024-07-17 23:28:39.075966: Current learning rate: 0.00998\n","2024-07-17 23:30:21.240891: train_loss -0.4084\n","2024-07-17 23:30:21.241243: val_loss -0.4878\n","2024-07-17 23:30:21.241451: Pseudo dice [0.7819]\n","2024-07-17 23:30:21.241573: Epoch time: 102.17 s\n","2024-07-17 23:30:21.241671: Yayy! New best EMA pseudo Dice: 0.4546\n","2024-07-17 23:30:24.999428: \n","2024-07-17 23:30:24.999817: Epoch 3\n","2024-07-17 23:30:24.999987: Current learning rate: 0.00997\n","2024-07-17 23:32:07.243548: train_loss -0.4532\n","2024-07-17 23:32:07.243825: val_loss -0.3879\n","2024-07-17 23:32:07.244028: Pseudo dice [0.7192]\n","2024-07-17 23:32:07.244140: Epoch time: 102.25 s\n","2024-07-17 23:32:07.244215: Yayy! New best EMA pseudo Dice: 0.4811\n","2024-07-17 23:32:11.838835: \n","2024-07-17 23:32:11.839230: Epoch 4\n","2024-07-17 23:32:11.839370: Current learning rate: 0.00996\n","2024-07-17 23:33:54.066676: train_loss -0.4657\n","2024-07-17 23:33:54.066907: val_loss -0.4436\n","2024-07-17 23:33:54.067044: Pseudo dice [0.7622]\n","2024-07-17 23:33:54.067148: Epoch time: 102.23 s\n","2024-07-17 23:33:54.067327: Yayy! New best EMA pseudo Dice: 0.5092\n","2024-07-17 23:33:58.447763: \n","2024-07-17 23:33:58.448141: Epoch 5\n","2024-07-17 23:33:58.448424: Current learning rate: 0.00995\n","2024-07-17 23:35:40.587111: train_loss -0.4876\n","2024-07-17 23:35:40.587380: val_loss -0.5422\n","2024-07-17 23:35:40.587509: Pseudo dice [0.8039]\n","2024-07-17 23:35:40.587679: Epoch time: 102.14 s\n","2024-07-17 23:35:40.587761: Yayy! New best EMA pseudo Dice: 0.5387\n","2024-07-17 23:35:43.986874: \n","2024-07-17 23:35:43.987305: Epoch 6\n","2024-07-17 23:35:43.987484: Current learning rate: 0.00995\n","2024-07-17 23:37:26.310830: train_loss -0.5292\n","2024-07-17 23:37:26.311105: val_loss -0.539\n","2024-07-17 23:37:26.311231: Pseudo dice [0.8292]\n","2024-07-17 23:37:26.311348: Epoch time: 102.33 s\n","2024-07-17 23:37:26.311438: Yayy! New best EMA pseudo Dice: 0.5677\n","2024-07-17 23:37:29.541038: \n","2024-07-17 23:37:29.541334: Epoch 7\n","2024-07-17 23:37:29.541485: Current learning rate: 0.00994\n","2024-07-17 23:39:11.847982: train_loss -0.5082\n","2024-07-17 23:39:11.848364: val_loss -0.4613\n","2024-07-17 23:39:11.848528: Pseudo dice [0.7342]\n","2024-07-17 23:39:11.848628: Epoch time: 102.31 s\n","2024-07-17 23:39:11.848703: Yayy! New best EMA pseudo Dice: 0.5844\n","2024-07-17 23:39:15.173415: \n","2024-07-17 23:39:15.173732: Epoch 8\n","2024-07-17 23:39:15.173891: Current learning rate: 0.00993\n","2024-07-17 23:40:57.461331: train_loss -0.5419\n","2024-07-17 23:40:57.461737: val_loss -0.5719\n","2024-07-17 23:40:57.461841: Pseudo dice [0.8425]\n","2024-07-17 23:40:57.461968: Epoch time: 102.29 s\n","2024-07-17 23:40:57.462082: Yayy! New best EMA pseudo Dice: 0.6102\n","2024-07-17 23:41:01.211536: \n","2024-07-17 23:41:01.211915: Epoch 9\n","2024-07-17 23:41:01.212121: Current learning rate: 0.00992\n","2024-07-17 23:42:43.414177: train_loss -0.5366\n","2024-07-17 23:42:43.414454: val_loss -0.5017\n","2024-07-17 23:42:43.414558: Pseudo dice [0.8049]\n","2024-07-17 23:42:43.414662: Epoch time: 102.21 s\n","2024-07-17 23:42:43.414790: Yayy! New best EMA pseudo Dice: 0.6297\n","2024-07-17 23:42:46.787751: \n","2024-07-17 23:42:46.788164: Epoch 10\n","2024-07-17 23:42:46.788315: Current learning rate: 0.00991\n","2024-07-17 23:44:28.937282: train_loss -0.5486\n","2024-07-17 23:44:28.937578: val_loss -0.5289\n","2024-07-17 23:44:28.937684: Pseudo dice [0.8628]\n","2024-07-17 23:44:28.937785: Epoch time: 102.15 s\n","2024-07-17 23:44:28.937869: Yayy! New best EMA pseudo Dice: 0.653\n","2024-07-17 23:44:32.783329: \n","2024-07-17 23:44:32.783723: Epoch 11\n","2024-07-17 23:44:32.783871: Current learning rate: 0.0099\n","2024-07-17 23:46:15.172204: train_loss -0.5524\n","2024-07-17 23:46:15.172516: val_loss -0.5409\n","2024-07-17 23:46:15.172647: Pseudo dice [0.8215]\n","2024-07-17 23:46:15.172824: Epoch time: 102.39 s\n","2024-07-17 23:46:15.173144: Yayy! New best EMA pseudo Dice: 0.6698\n","2024-07-17 23:46:18.499690: \n","2024-07-17 23:46:18.500045: Epoch 12\n","2024-07-17 23:46:18.500201: Current learning rate: 0.00989\n","2024-07-17 23:48:00.944563: train_loss -0.5631\n","2024-07-17 23:48:00.944906: val_loss -0.5452\n","2024-07-17 23:48:00.945039: Pseudo dice [0.8262]\n","2024-07-17 23:48:00.945151: Epoch time: 102.45 s\n","2024-07-17 23:48:00.945226: Yayy! New best EMA pseudo Dice: 0.6855\n","2024-07-17 23:48:05.371631: \n","2024-07-17 23:48:05.372089: Epoch 13\n","2024-07-17 23:48:05.372259: Current learning rate: 0.00988\n","2024-07-17 23:49:47.708966: train_loss -0.5779\n","2024-07-17 23:49:47.709256: val_loss -0.5449\n","2024-07-17 23:49:47.709366: Pseudo dice [0.852]\n","2024-07-17 23:49:47.709458: Epoch time: 102.34 s\n","2024-07-17 23:49:47.709531: Yayy! New best EMA pseudo Dice: 0.7021\n","2024-07-17 23:49:51.226409: \n","2024-07-17 23:49:51.226792: Epoch 14\n","2024-07-17 23:49:51.226992: Current learning rate: 0.00987\n","2024-07-17 23:51:33.494986: train_loss -0.563\n","2024-07-17 23:51:33.495279: val_loss -0.3261\n","2024-07-17 23:51:33.495390: Pseudo dice [0.6633]\n","2024-07-17 23:51:33.495494: Epoch time: 102.27 s\n","2024-07-17 23:51:35.037146: \n","2024-07-17 23:51:35.037614: Epoch 15\n","2024-07-17 23:51:35.037767: Current learning rate: 0.00986\n","2024-07-17 23:53:17.510872: train_loss -0.5438\n","2024-07-17 23:53:17.511208: val_loss -0.5864\n","2024-07-17 23:53:17.511312: Pseudo dice [0.8062]\n","2024-07-17 23:53:17.511416: Epoch time: 102.48 s\n","2024-07-17 23:53:17.511493: Yayy! New best EMA pseudo Dice: 0.709\n","2024-07-17 23:53:21.100435: \n","2024-07-17 23:53:21.100856: Epoch 16\n","2024-07-17 23:53:21.101011: Current learning rate: 0.00986\n","2024-07-17 23:55:03.425660: train_loss -0.5634\n","2024-07-17 23:55:03.425889: val_loss -0.5398\n","2024-07-17 23:55:03.426031: Pseudo dice [0.8463]\n","2024-07-17 23:55:03.426152: Epoch time: 102.33 s\n","2024-07-17 23:55:03.426243: Yayy! New best EMA pseudo Dice: 0.7228\n","2024-07-17 23:55:07.536671: \n","2024-07-17 23:55:07.537025: Epoch 17\n","2024-07-17 23:55:07.537178: Current learning rate: 0.00985\n","2024-07-17 23:56:49.723841: train_loss -0.5453\n","2024-07-17 23:56:49.724188: val_loss -0.4119\n","2024-07-17 23:56:49.724339: Pseudo dice [0.7242]\n","2024-07-17 23:56:49.724456: Epoch time: 102.19 s\n","2024-07-17 23:56:49.724531: Yayy! New best EMA pseudo Dice: 0.7229\n","2024-07-17 23:56:53.176625: \n","2024-07-17 23:56:53.177031: Epoch 18\n","2024-07-17 23:56:53.177173: Current learning rate: 0.00984\n","2024-07-17 23:58:35.456832: train_loss -0.5599\n","2024-07-17 23:58:35.457106: val_loss -0.5769\n","2024-07-17 23:58:35.457209: Pseudo dice [0.8505]\n","2024-07-17 23:58:35.457303: Epoch time: 102.28 s\n","2024-07-17 23:58:35.457397: Yayy! New best EMA pseudo Dice: 0.7357\n","2024-07-17 23:58:38.911005: \n","2024-07-17 23:58:38.911406: Epoch 19\n","2024-07-17 23:58:38.911573: Current learning rate: 0.00983\n","2024-07-18 00:00:21.246936: train_loss -0.5759\n","2024-07-18 00:00:21.247257: val_loss -0.5993\n","2024-07-18 00:00:21.247377: Pseudo dice [0.846]\n","2024-07-18 00:00:21.247490: Epoch time: 102.34 s\n","2024-07-18 00:00:21.247564: Yayy! New best EMA pseudo Dice: 0.7467\n","2024-07-18 00:00:24.625868: \n","2024-07-18 00:00:24.626239: Epoch 20\n","2024-07-18 00:00:24.626383: Current learning rate: 0.00982\n","2024-07-18 00:02:06.755792: train_loss -0.6199\n","2024-07-18 00:02:06.756181: val_loss -0.3802\n","2024-07-18 00:02:06.756374: Pseudo dice [0.6525]\n","2024-07-18 00:02:06.756480: Epoch time: 102.13 s\n","2024-07-18 00:02:08.378484: \n","2024-07-18 00:02:08.378892: Epoch 21\n","2024-07-18 00:02:08.379080: Current learning rate: 0.00981\n","2024-07-18 00:03:50.557212: train_loss -0.6095\n","2024-07-18 00:03:50.557516: val_loss -0.5188\n","2024-07-18 00:03:50.557635: Pseudo dice [0.8756]\n","2024-07-18 00:03:50.557738: Epoch time: 102.18 s\n","2024-07-18 00:03:50.557914: Yayy! New best EMA pseudo Dice: 0.7511\n","2024-07-18 00:03:53.858130: \n","2024-07-18 00:03:53.858495: Epoch 22\n","2024-07-18 00:03:53.858671: Current learning rate: 0.0098\n","2024-07-18 00:05:36.060796: train_loss -0.6088\n","2024-07-18 00:05:36.061091: val_loss -0.6166\n","2024-07-18 00:05:36.061200: Pseudo dice [0.8836]\n","2024-07-18 00:05:36.061294: Epoch time: 102.21 s\n","2024-07-18 00:05:36.061381: Yayy! New best EMA pseudo Dice: 0.7644\n","2024-07-18 00:05:39.380246: \n","2024-07-18 00:05:39.380639: Epoch 23\n","2024-07-18 00:05:39.380821: Current learning rate: 0.00979\n","2024-07-18 00:07:22.074204: train_loss -0.606\n","2024-07-18 00:07:22.074589: val_loss -0.6482\n","2024-07-18 00:07:22.074703: Pseudo dice [0.8917]\n","2024-07-18 00:07:22.074805: Epoch time: 102.7 s\n","2024-07-18 00:07:22.074878: Yayy! New best EMA pseudo Dice: 0.7771\n","2024-07-18 00:07:25.457841: \n","2024-07-18 00:07:25.458287: Epoch 24\n","2024-07-18 00:07:25.458441: Current learning rate: 0.00978\n","2024-07-18 00:09:07.614366: train_loss -0.6126\n","2024-07-18 00:09:07.614743: val_loss -0.5974\n","2024-07-18 00:09:07.614843: Pseudo dice [0.8935]\n","2024-07-18 00:09:07.614961: Epoch time: 102.16 s\n","2024-07-18 00:09:07.615043: Yayy! New best EMA pseudo Dice: 0.7887\n","2024-07-18 00:09:11.201114: \n","2024-07-18 00:09:11.201488: Epoch 25\n","2024-07-18 00:09:11.201629: Current learning rate: 0.00977\n","2024-07-18 00:10:53.460058: train_loss -0.614\n","2024-07-18 00:10:53.460334: val_loss -0.6548\n","2024-07-18 00:10:53.460446: Pseudo dice [0.9096]\n","2024-07-18 00:10:53.460556: Epoch time: 102.26 s\n","2024-07-18 00:10:53.460642: Yayy! New best EMA pseudo Dice: 0.8008\n","2024-07-18 00:10:56.820947: \n","2024-07-18 00:10:56.821288: Epoch 26\n","2024-07-18 00:10:56.821434: Current learning rate: 0.00977\n","2024-07-18 00:12:39.052275: train_loss -0.624\n","2024-07-18 00:12:39.052737: val_loss -0.5739\n","2024-07-18 00:12:39.052844: Pseudo dice [0.8866]\n","2024-07-18 00:12:39.052965: Epoch time: 102.24 s\n","2024-07-18 00:12:39.053046: Yayy! New best EMA pseudo Dice: 0.8094\n","2024-07-18 00:12:42.413729: \n","2024-07-18 00:12:42.414115: Epoch 27\n","2024-07-18 00:12:42.414258: Current learning rate: 0.00976\n","2024-07-18 00:14:24.750339: train_loss -0.6002\n","2024-07-18 00:14:24.750698: val_loss -0.5894\n","2024-07-18 00:14:24.750815: Pseudo dice [0.8981]\n","2024-07-18 00:14:24.750940: Epoch time: 102.34 s\n","2024-07-18 00:14:24.751043: Yayy! New best EMA pseudo Dice: 0.8183\n","2024-07-18 00:14:28.287592: \n","2024-07-18 00:14:28.288019: Epoch 28\n","2024-07-18 00:14:28.288179: Current learning rate: 0.00975\n","2024-07-18 00:16:10.377464: train_loss -0.6222\n","2024-07-18 00:16:10.377713: val_loss -0.5325\n","2024-07-18 00:16:10.377875: Pseudo dice [0.8778]\n","2024-07-18 00:16:10.378072: Epoch time: 102.09 s\n","2024-07-18 00:16:10.378155: Yayy! New best EMA pseudo Dice: 0.8242\n","2024-07-18 00:16:13.887310: \n","2024-07-18 00:16:13.887756: Epoch 29\n","2024-07-18 00:16:13.887949: Current learning rate: 0.00974\n","2024-07-18 00:17:56.716210: train_loss -0.6269\n","2024-07-18 00:17:56.716451: val_loss -0.522\n","2024-07-18 00:17:56.716552: Pseudo dice [0.8558]\n","2024-07-18 00:17:56.716644: Epoch time: 102.83 s\n","2024-07-18 00:17:56.716722: Yayy! New best EMA pseudo Dice: 0.8274\n","2024-07-18 00:18:00.151042: \n","2024-07-18 00:18:00.151373: Epoch 30\n","2024-07-18 00:18:00.151510: Current learning rate: 0.00973\n","2024-07-18 00:19:42.323189: train_loss -0.6238\n","2024-07-18 00:19:42.323585: val_loss -0.643\n","2024-07-18 00:19:42.323752: Pseudo dice [0.9127]\n","2024-07-18 00:19:42.323849: Epoch time: 102.18 s\n","2024-07-18 00:19:42.323940: Yayy! New best EMA pseudo Dice: 0.8359\n","2024-07-18 00:19:45.733985: \n","2024-07-18 00:19:45.734371: Epoch 31\n","2024-07-18 00:19:45.734511: Current learning rate: 0.00972\n","2024-07-18 00:21:28.087260: train_loss -0.6011\n","2024-07-18 00:21:28.087539: val_loss -0.6015\n","2024-07-18 00:21:28.087727: Pseudo dice [0.9119]\n","2024-07-18 00:21:28.087989: Epoch time: 102.36 s\n","2024-07-18 00:21:28.088098: Yayy! New best EMA pseudo Dice: 0.8435\n","2024-07-18 00:21:31.612740: \n","2024-07-18 00:21:31.613120: Epoch 32\n","2024-07-18 00:21:31.613262: Current learning rate: 0.00971\n","2024-07-18 00:23:13.734966: train_loss -0.5948\n","2024-07-18 00:23:13.735394: val_loss -0.6704\n","2024-07-18 00:23:13.735515: Pseudo dice [0.9398]\n","2024-07-18 00:23:13.735613: Epoch time: 102.13 s\n","2024-07-18 00:23:13.735687: Yayy! New best EMA pseudo Dice: 0.8531\n","2024-07-18 00:23:17.264405: \n","2024-07-18 00:23:17.264752: Epoch 33\n","2024-07-18 00:23:17.264892: Current learning rate: 0.0097\n","2024-07-18 00:24:59.606896: train_loss -0.6218\n","2024-07-18 00:24:59.607205: val_loss -0.6503\n","2024-07-18 00:24:59.607361: Pseudo dice [0.9291]\n","2024-07-18 00:24:59.607561: Epoch time: 102.35 s\n","2024-07-18 00:24:59.607683: Yayy! New best EMA pseudo Dice: 0.8607\n","2024-07-18 00:25:03.111881: \n","2024-07-18 00:25:03.112270: Epoch 34\n","2024-07-18 00:25:03.112428: Current learning rate: 0.00969\n","2024-07-18 00:26:45.411491: train_loss -0.6258\n","2024-07-18 00:26:45.411739: val_loss -0.6242\n","2024-07-18 00:26:45.411843: Pseudo dice [0.9028]\n","2024-07-18 00:26:45.411965: Epoch time: 102.3 s\n","2024-07-18 00:26:45.412097: Yayy! New best EMA pseudo Dice: 0.8649\n","2024-07-18 00:26:50.891997: \n","2024-07-18 00:26:50.892404: Epoch 35\n","2024-07-18 00:26:50.892545: Current learning rate: 0.00968\n","2024-07-18 00:28:33.593729: train_loss -0.6382\n","2024-07-18 00:28:33.594004: val_loss -0.5805\n","2024-07-18 00:28:33.594150: Pseudo dice [0.8932]\n","2024-07-18 00:28:33.594266: Epoch time: 102.71 s\n","2024-07-18 00:28:33.594355: Yayy! New best EMA pseudo Dice: 0.8678\n","2024-07-18 00:28:37.136360: \n","2024-07-18 00:28:37.136838: Epoch 36\n","2024-07-18 00:28:37.137027: Current learning rate: 0.00968\n","2024-07-18 00:30:19.267360: train_loss -0.6221\n","2024-07-18 00:30:19.267663: val_loss -0.5452\n","2024-07-18 00:30:19.267765: Pseudo dice [0.8145]\n","2024-07-18 00:30:19.267858: Epoch time: 102.14 s\n","2024-07-18 00:30:20.847252: \n","2024-07-18 00:30:20.847708: Epoch 37\n","2024-07-18 00:30:20.847851: Current learning rate: 0.00967\n","2024-07-18 00:32:03.102748: train_loss -0.6387\n","2024-07-18 00:32:03.103010: val_loss -0.5948\n","2024-07-18 00:32:03.103233: Pseudo dice [0.8829]\n","2024-07-18 00:32:03.103357: Epoch time: 102.26 s\n","2024-07-18 00:32:04.632766: \n","2024-07-18 00:32:04.633118: Epoch 38\n","2024-07-18 00:32:04.633258: Current learning rate: 0.00966\n","2024-07-18 00:33:46.958450: train_loss -0.6349\n","2024-07-18 00:33:46.958696: val_loss -0.4647\n","2024-07-18 00:33:46.958799: Pseudo dice [0.7657]\n","2024-07-18 00:33:46.958894: Epoch time: 102.33 s\n","2024-07-18 00:33:48.525117: \n","2024-07-18 00:33:48.525558: Epoch 39\n","2024-07-18 00:33:48.525717: Current learning rate: 0.00965\n","2024-07-18 00:35:30.839247: train_loss -0.6109\n","2024-07-18 00:35:30.839524: val_loss -0.6392\n","2024-07-18 00:35:30.839624: Pseudo dice [0.9031]\n","2024-07-18 00:35:30.839729: Epoch time: 102.32 s\n","2024-07-18 00:35:32.439350: \n","2024-07-18 00:35:32.439787: Epoch 40\n","2024-07-18 00:35:32.439969: Current learning rate: 0.00964\n","2024-07-18 00:37:14.727962: train_loss -0.6238\n","2024-07-18 00:37:14.728364: val_loss -0.6149\n","2024-07-18 00:37:14.728509: Pseudo dice [0.9224]\n","2024-07-18 00:37:14.728605: Epoch time: 102.29 s\n","2024-07-18 00:37:16.315743: \n","2024-07-18 00:37:16.316038: Epoch 41\n","2024-07-18 00:37:16.316264: Current learning rate: 0.00963\n","2024-07-18 00:38:58.683551: train_loss -0.6246\n","2024-07-18 00:38:58.683792: val_loss -0.5967\n","2024-07-18 00:38:58.683895: Pseudo dice [0.8724]\n","2024-07-18 00:38:58.684011: Epoch time: 102.37 s\n","2024-07-18 00:39:00.196065: \n","2024-07-18 00:39:00.196432: Epoch 42\n","2024-07-18 00:39:00.196570: Current learning rate: 0.00962\n","2024-07-18 00:40:43.002006: train_loss -0.6152\n","2024-07-18 00:40:43.002258: val_loss -0.6128\n","2024-07-18 00:40:43.002360: Pseudo dice [0.9341]\n","2024-07-18 00:40:43.002456: Epoch time: 102.81 s\n","2024-07-18 00:40:43.002570: Yayy! New best EMA pseudo Dice: 0.8732\n","2024-07-18 00:40:46.721788: \n","2024-07-18 00:40:46.722215: Epoch 43\n","2024-07-18 00:40:46.722364: Current learning rate: 0.00961\n","2024-07-18 00:42:28.908232: train_loss -0.6035\n","2024-07-18 00:42:28.908499: val_loss -0.6673\n","2024-07-18 00:42:28.908626: Pseudo dice [0.9312]\n","2024-07-18 00:42:28.908757: Epoch time: 102.19 s\n","2024-07-18 00:42:28.908866: Yayy! New best EMA pseudo Dice: 0.879\n","2024-07-18 00:42:32.314472: \n","2024-07-18 00:42:32.314819: Epoch 44\n","2024-07-18 00:42:32.314990: Current learning rate: 0.0096\n","2024-07-18 00:44:14.612912: train_loss -0.6206\n","2024-07-18 00:44:14.613162: val_loss -0.7074\n","2024-07-18 00:44:14.613264: Pseudo dice [0.9433]\n","2024-07-18 00:44:14.613369: Epoch time: 102.3 s\n","2024-07-18 00:44:14.613520: Yayy! New best EMA pseudo Dice: 0.8854\n","2024-07-18 00:44:18.034983: \n","2024-07-18 00:44:18.035326: Epoch 45\n","2024-07-18 00:44:18.035473: Current learning rate: 0.00959\n","2024-07-18 00:46:00.354171: train_loss -0.5955\n","2024-07-18 00:46:00.354469: val_loss -0.6368\n","2024-07-18 00:46:00.354600: Pseudo dice [0.9335]\n","2024-07-18 00:46:00.354729: Epoch time: 102.32 s\n","2024-07-18 00:46:00.354823: Yayy! New best EMA pseudo Dice: 0.8902\n","2024-07-18 00:46:03.826685: \n","2024-07-18 00:46:03.827098: Epoch 46\n","2024-07-18 00:46:03.827237: Current learning rate: 0.00959\n","2024-07-18 00:47:46.160439: train_loss -0.6594\n","2024-07-18 00:47:46.160709: val_loss -0.6828\n","2024-07-18 00:47:46.160814: Pseudo dice [0.942]\n","2024-07-18 00:47:46.160911: Epoch time: 102.34 s\n","2024-07-18 00:47:46.161075: Yayy! New best EMA pseudo Dice: 0.8954\n","2024-07-18 00:47:49.528221: \n","2024-07-18 00:47:49.528621: Epoch 47\n","2024-07-18 00:47:49.528794: Current learning rate: 0.00958\n","2024-07-18 00:49:31.856676: train_loss -0.6568\n","2024-07-18 00:49:31.857021: val_loss -0.6734\n","2024-07-18 00:49:31.857131: Pseudo dice [0.9237]\n","2024-07-18 00:49:31.857225: Epoch time: 102.33 s\n","2024-07-18 00:49:31.857300: Yayy! New best EMA pseudo Dice: 0.8982\n","2024-07-18 00:49:35.298356: \n","2024-07-18 00:49:35.298736: Epoch 48\n","2024-07-18 00:49:35.298877: Current learning rate: 0.00957\n","2024-07-18 00:51:17.757396: train_loss -0.6501\n","2024-07-18 00:51:17.757739: val_loss -0.5923\n","2024-07-18 00:51:17.757913: Pseudo dice [0.9101]\n","2024-07-18 00:51:17.758165: Epoch time: 102.46 s\n","2024-07-18 00:51:17.758299: Yayy! New best EMA pseudo Dice: 0.8994\n","2024-07-18 00:51:21.774738: \n","2024-07-18 00:51:21.775230: Epoch 49\n","2024-07-18 00:51:21.775441: Current learning rate: 0.00956\n","2024-07-18 00:53:04.167549: train_loss -0.6215\n","2024-07-18 00:53:04.167780: val_loss -0.6618\n","2024-07-18 00:53:04.167877: Pseudo dice [0.9395]\n","2024-07-18 00:53:04.167991: Epoch time: 102.4 s\n","2024-07-18 00:53:05.740354: Yayy! New best EMA pseudo Dice: 0.9034\n","2024-07-18 00:53:11.597229: \n","2024-07-18 00:53:11.597573: Epoch 50\n","2024-07-18 00:53:11.597730: Current learning rate: 0.00955\n","2024-07-18 00:54:54.040405: train_loss -0.6943\n","2024-07-18 00:54:54.040715: val_loss -0.6578\n","2024-07-18 00:54:54.040821: Pseudo dice [0.9412]\n","2024-07-18 00:54:54.040916: Epoch time: 102.45 s\n","2024-07-18 00:54:54.041021: Yayy! New best EMA pseudo Dice: 0.9072\n","2024-07-18 00:54:57.513649: \n","2024-07-18 00:54:57.514068: Epoch 51\n","2024-07-18 00:54:57.514213: Current learning rate: 0.00954\n","2024-07-18 00:56:39.818793: train_loss -0.625\n","2024-07-18 00:56:39.819116: val_loss -0.6633\n","2024-07-18 00:56:39.819237: Pseudo dice [0.9313]\n","2024-07-18 00:56:39.819344: Epoch time: 102.31 s\n","2024-07-18 00:56:39.819418: Yayy! New best EMA pseudo Dice: 0.9096\n","2024-07-18 00:56:43.275020: \n","2024-07-18 00:56:43.275468: Epoch 52\n","2024-07-18 00:56:43.275644: Current learning rate: 0.00953\n","2024-07-18 00:58:25.396705: train_loss -0.6489\n","2024-07-18 00:58:25.397045: val_loss -0.5401\n","2024-07-18 00:58:25.397155: Pseudo dice [0.8284]\n","2024-07-18 00:58:25.397260: Epoch time: 102.13 s\n","2024-07-18 00:58:26.901023: \n","2024-07-18 00:58:26.901398: Epoch 53\n","2024-07-18 00:58:26.901565: Current learning rate: 0.00952\n","2024-07-18 01:00:08.990408: train_loss -0.6038\n","2024-07-18 01:00:08.990673: val_loss -0.6336\n","2024-07-18 01:00:08.990781: Pseudo dice [0.9044]\n","2024-07-18 01:00:08.991072: Epoch time: 102.09 s\n","2024-07-18 01:00:10.570703: \n","2024-07-18 01:00:10.571055: Epoch 54\n","2024-07-18 01:00:10.571212: Current learning rate: 0.00951\n","2024-07-18 01:01:52.587462: train_loss -0.6325\n","2024-07-18 01:01:52.587758: val_loss -0.6407\n","2024-07-18 01:01:52.587862: Pseudo dice [0.9266]\n","2024-07-18 01:01:52.587973: Epoch time: 102.02 s\n","2024-07-18 01:01:54.592355: \n","2024-07-18 01:01:54.592731: Epoch 55\n","2024-07-18 01:01:54.592875: Current learning rate: 0.0095\n","2024-07-18 01:03:36.881640: train_loss -0.6367\n","2024-07-18 01:03:36.881875: val_loss -0.6417\n","2024-07-18 01:03:36.882016: Pseudo dice [0.9126]\n","2024-07-18 01:03:36.882135: Epoch time: 102.29 s\n","2024-07-18 01:03:38.454383: \n","2024-07-18 01:03:38.454723: Epoch 56\n","2024-07-18 01:03:38.454860: Current learning rate: 0.00949\n","2024-07-18 01:05:20.614568: train_loss -0.6326\n","2024-07-18 01:05:20.614790: val_loss -0.627\n","2024-07-18 01:05:20.614887: Pseudo dice [0.9364]\n","2024-07-18 01:05:20.615021: Epoch time: 102.16 s\n","2024-07-18 01:05:22.124498: \n","2024-07-18 01:05:22.124897: Epoch 57\n","2024-07-18 01:05:22.125053: Current learning rate: 0.00949\n","2024-07-18 01:07:04.408292: train_loss -0.6353\n","2024-07-18 01:07:04.408576: val_loss -0.6857\n","2024-07-18 01:07:04.408688: Pseudo dice [0.9325]\n","2024-07-18 01:07:04.408971: Epoch time: 102.29 s\n","2024-07-18 01:07:04.409092: Yayy! New best EMA pseudo Dice: 0.9106\n","2024-07-18 01:07:07.901729: \n","2024-07-18 01:07:07.902137: Epoch 58\n","2024-07-18 01:07:07.902294: Current learning rate: 0.00948\n","2024-07-18 01:08:50.130908: train_loss -0.6646\n","2024-07-18 01:08:50.131210: val_loss -0.6806\n","2024-07-18 01:08:50.131371: Pseudo dice [0.9418]\n","2024-07-18 01:08:50.131510: Epoch time: 102.23 s\n","2024-07-18 01:08:50.131612: Yayy! New best EMA pseudo Dice: 0.9138\n","2024-07-18 01:08:53.631268: \n","2024-07-18 01:08:53.631707: Epoch 59\n","2024-07-18 01:08:53.631847: Current learning rate: 0.00947\n","2024-07-18 01:10:36.014359: train_loss -0.6375\n","2024-07-18 01:10:36.014605: val_loss -0.6427\n","2024-07-18 01:10:36.014710: Pseudo dice [0.9061]\n","2024-07-18 01:10:36.014835: Epoch time: 102.39 s\n","2024-07-18 01:10:37.758018: \n","2024-07-18 01:10:37.758448: Epoch 60\n","2024-07-18 01:10:37.758621: Current learning rate: 0.00946\n","2024-07-18 01:12:19.977706: train_loss -0.6373\n","2024-07-18 01:12:19.978007: val_loss -0.4927\n","2024-07-18 01:12:19.978223: Pseudo dice [0.8272]\n","2024-07-18 01:12:19.978335: Epoch time: 102.22 s\n","2024-07-18 01:12:21.466900: \n","2024-07-18 01:12:21.467255: Epoch 61\n","2024-07-18 01:12:21.467398: Current learning rate: 0.00945\n","2024-07-18 01:14:04.303411: train_loss -0.5908\n","2024-07-18 01:14:04.303801: val_loss -0.6439\n","2024-07-18 01:14:04.303959: Pseudo dice [0.9081]\n","2024-07-18 01:14:04.304075: Epoch time: 102.84 s\n","2024-07-18 01:14:05.884371: \n","2024-07-18 01:14:05.884842: Epoch 62\n","2024-07-18 01:14:05.885030: Current learning rate: 0.00944\n","2024-07-18 01:15:48.053338: train_loss -0.6237\n","2024-07-18 01:15:48.053597: val_loss -0.6954\n","2024-07-18 01:15:48.053706: Pseudo dice [0.942]\n","2024-07-18 01:15:48.053801: Epoch time: 102.17 s\n","2024-07-18 01:15:49.629107: \n","2024-07-18 01:15:49.629499: Epoch 63\n","2024-07-18 01:15:49.629642: Current learning rate: 0.00943\n","2024-07-18 01:17:31.709156: train_loss -0.609\n","2024-07-18 01:17:31.709408: val_loss -0.5435\n","2024-07-18 01:17:31.709510: Pseudo dice [0.8671]\n","2024-07-18 01:17:31.709604: Epoch time: 102.08 s\n","2024-07-18 01:17:33.240799: \n","2024-07-18 01:17:33.241198: Epoch 64\n","2024-07-18 01:17:33.241370: Current learning rate: 0.00942\n","2024-07-18 01:19:15.570112: train_loss -0.6231\n","2024-07-18 01:19:15.570352: val_loss -0.6611\n","2024-07-18 01:19:15.570449: Pseudo dice [0.9246]\n","2024-07-18 01:19:15.570542: Epoch time: 102.33 s\n","2024-07-18 01:19:17.084189: \n","2024-07-18 01:19:17.084614: Epoch 65\n","2024-07-18 01:19:17.084751: Current learning rate: 0.00941\n","2024-07-18 01:20:59.085895: train_loss -0.6145\n","2024-07-18 01:20:59.086260: val_loss -0.6451\n","2024-07-18 01:20:59.086376: Pseudo dice [0.9154]\n","2024-07-18 01:20:59.086484: Epoch time: 102.01 s\n","2024-07-18 01:21:00.670251: \n","2024-07-18 01:21:00.670600: Epoch 66\n","2024-07-18 01:21:00.670760: Current learning rate: 0.0094\n","2024-07-18 01:22:42.843754: train_loss -0.6341\n","2024-07-18 01:22:42.844074: val_loss -0.6144\n","2024-07-18 01:22:42.844265: Pseudo dice [0.9091]\n","2024-07-18 01:22:42.844386: Epoch time: 102.18 s\n","2024-07-18 01:22:44.375991: \n","2024-07-18 01:22:44.376292: Epoch 67\n","2024-07-18 01:22:44.376434: Current learning rate: 0.00939\n","2024-07-18 01:24:26.606595: train_loss -0.614\n","2024-07-18 01:24:26.606869: val_loss -0.6061\n","2024-07-18 01:24:26.607064: Pseudo dice [0.9044]\n","2024-07-18 01:24:26.607206: Epoch time: 102.23 s\n","2024-07-18 01:24:28.202000: \n","2024-07-18 01:24:28.202433: Epoch 68\n","2024-07-18 01:24:28.202571: Current learning rate: 0.00939\n","2024-07-18 01:26:10.915556: train_loss -0.6316\n","2024-07-18 01:26:10.915857: val_loss -0.6391\n","2024-07-18 01:26:10.916028: Pseudo dice [0.9062]\n","2024-07-18 01:26:10.916150: Epoch time: 102.72 s\n","2024-07-18 01:26:12.489161: \n","2024-07-18 01:26:12.489556: Epoch 69\n","2024-07-18 01:26:12.489719: Current learning rate: 0.00938\n","2024-07-18 01:27:54.731644: train_loss -0.6181\n","2024-07-18 01:27:54.731956: val_loss -0.6148\n","2024-07-18 01:27:54.732107: Pseudo dice [0.9351]\n","2024-07-18 01:27:54.732221: Epoch time: 102.25 s\n","2024-07-18 01:27:56.295160: \n","2024-07-18 01:27:56.295557: Epoch 70\n","2024-07-18 01:27:56.295715: Current learning rate: 0.00937\n","2024-07-18 01:29:38.523432: train_loss -0.6254\n","2024-07-18 01:29:38.523814: val_loss -0.6182\n","2024-07-18 01:29:38.523938: Pseudo dice [0.9222]\n","2024-07-18 01:29:38.524069: Epoch time: 102.23 s\n","2024-07-18 01:29:40.053400: \n","2024-07-18 01:29:40.053788: Epoch 71\n","2024-07-18 01:29:40.053971: Current learning rate: 0.00936\n","2024-07-18 01:31:22.146351: train_loss -0.6428\n","2024-07-18 01:31:22.146711: val_loss -0.6459\n","2024-07-18 01:31:22.146825: Pseudo dice [0.9042]\n","2024-07-18 01:31:22.146957: Epoch time: 102.1 s\n","2024-07-18 01:31:23.744354: \n","2024-07-18 01:31:23.744808: Epoch 72\n","2024-07-18 01:31:23.744973: Current learning rate: 0.00935\n","2024-07-18 01:33:05.882603: train_loss -0.6587\n","2024-07-18 01:33:05.882850: val_loss -0.6464\n","2024-07-18 01:33:05.882966: Pseudo dice [0.8989]\n","2024-07-18 01:33:05.883067: Epoch time: 102.14 s\n","2024-07-18 01:33:07.400196: \n","2024-07-18 01:33:07.400570: Epoch 73\n","2024-07-18 01:33:07.400710: Current learning rate: 0.00934\n","2024-07-18 01:34:49.506860: train_loss -0.6355\n","2024-07-18 01:34:49.507425: val_loss -0.6732\n","2024-07-18 01:34:49.507533: Pseudo dice [0.9377]\n","2024-07-18 01:34:49.507630: Epoch time: 102.11 s\n","2024-07-18 01:34:51.113597: \n","2024-07-18 01:34:51.113995: Epoch 74\n","2024-07-18 01:34:51.114136: Current learning rate: 0.00933\n","2024-07-18 01:36:33.260968: train_loss -0.636\n","2024-07-18 01:36:33.261214: val_loss -0.6311\n","2024-07-18 01:36:33.261313: Pseudo dice [0.9008]\n","2024-07-18 01:36:33.261463: Epoch time: 102.15 s\n","2024-07-18 01:36:34.910940: \n","2024-07-18 01:36:34.911340: Epoch 75\n","2024-07-18 01:36:34.911489: Current learning rate: 0.00932\n","2024-07-18 01:38:17.594959: train_loss -0.6465\n","2024-07-18 01:38:17.595285: val_loss -0.5413\n","2024-07-18 01:38:17.595408: Pseudo dice [0.9081]\n","2024-07-18 01:38:17.595513: Epoch time: 102.69 s\n","2024-07-18 01:38:19.159453: \n","2024-07-18 01:38:19.159877: Epoch 76\n","2024-07-18 01:38:19.160067: Current learning rate: 0.00931\n","2024-07-18 01:40:01.297154: train_loss -0.6568\n","2024-07-18 01:40:01.297446: val_loss -0.5758\n","2024-07-18 01:40:01.297572: Pseudo dice [0.9123]\n","2024-07-18 01:40:01.297709: Epoch time: 102.14 s\n","2024-07-18 01:40:02.902511: \n","2024-07-18 01:40:02.902885: Epoch 77\n","2024-07-18 01:40:02.903067: Current learning rate: 0.0093\n","2024-07-18 01:41:45.044072: train_loss -0.635\n","2024-07-18 01:41:45.044319: val_loss -0.6077\n","2024-07-18 01:41:45.044428: Pseudo dice [0.9314]\n","2024-07-18 01:41:45.044543: Epoch time: 102.15 s\n","2024-07-18 01:41:46.687749: \n","2024-07-18 01:41:46.688141: Epoch 78\n","2024-07-18 01:41:46.688304: Current learning rate: 0.0093\n","2024-07-18 01:43:28.767013: train_loss -0.6419\n","2024-07-18 01:43:28.767264: val_loss -0.6641\n","2024-07-18 01:43:28.767367: Pseudo dice [0.9494]\n","2024-07-18 01:43:28.767464: Epoch time: 102.08 s\n","2024-07-18 01:43:28.767552: Yayy! New best EMA pseudo Dice: 0.9165\n","2024-07-18 01:43:32.200597: \n","2024-07-18 01:43:32.200999: Epoch 79\n","2024-07-18 01:43:32.201143: Current learning rate: 0.00929\n","2024-07-18 01:45:14.450467: train_loss -0.6415\n","2024-07-18 01:45:14.450737: val_loss -0.5461\n","2024-07-18 01:45:14.450836: Pseudo dice [0.8945]\n","2024-07-18 01:45:14.450948: Epoch time: 102.25 s\n","2024-07-18 01:45:16.043157: \n","2024-07-18 01:45:16.043538: Epoch 80\n","2024-07-18 01:45:16.043678: Current learning rate: 0.00928\n","2024-07-18 01:46:58.240659: train_loss -0.6669\n","2024-07-18 01:46:58.241008: val_loss -0.7178\n","2024-07-18 01:46:58.241132: Pseudo dice [0.9489]\n","2024-07-18 01:46:58.241239: Epoch time: 102.2 s\n","2024-07-18 01:46:58.241312: Yayy! New best EMA pseudo Dice: 0.9178\n","2024-07-18 01:47:01.828145: \n","2024-07-18 01:47:01.828491: Epoch 81\n","2024-07-18 01:47:01.828647: Current learning rate: 0.00927\n","2024-07-18 01:48:43.995686: train_loss -0.6188\n","2024-07-18 01:48:43.995955: val_loss -0.5903\n","2024-07-18 01:48:43.996075: Pseudo dice [0.9207]\n","2024-07-18 01:48:43.996170: Epoch time: 102.17 s\n","2024-07-18 01:48:43.996244: Yayy! New best EMA pseudo Dice: 0.9181\n","2024-07-18 01:48:48.209400: \n","2024-07-18 01:48:48.209902: Epoch 82\n","2024-07-18 01:48:48.210109: Current learning rate: 0.00926\n","2024-07-18 01:50:30.373962: train_loss -0.6308\n","2024-07-18 01:50:30.374219: val_loss -0.6345\n","2024-07-18 01:50:30.374316: Pseudo dice [0.9277]\n","2024-07-18 01:50:30.374496: Epoch time: 102.17 s\n","2024-07-18 01:50:30.374577: Yayy! New best EMA pseudo Dice: 0.9191\n","2024-07-18 01:50:33.804854: \n","2024-07-18 01:50:33.805323: Epoch 83\n","2024-07-18 01:50:33.805472: Current learning rate: 0.00925\n","2024-07-18 01:52:16.115813: train_loss -0.6548\n","2024-07-18 01:52:16.116076: val_loss -0.6818\n","2024-07-18 01:52:16.116183: Pseudo dice [0.9198]\n","2024-07-18 01:52:16.116403: Epoch time: 102.31 s\n","2024-07-18 01:52:16.116530: Yayy! New best EMA pseudo Dice: 0.9191\n","2024-07-18 01:52:19.715713: \n","2024-07-18 01:52:19.716009: Epoch 84\n","2024-07-18 01:52:19.716165: Current learning rate: 0.00924\n","2024-07-18 01:54:01.945419: train_loss -0.6534\n","2024-07-18 01:54:01.945707: val_loss -0.6554\n","2024-07-18 01:54:01.945815: Pseudo dice [0.9439]\n","2024-07-18 01:54:01.946108: Epoch time: 102.24 s\n","2024-07-18 01:54:01.946209: Yayy! New best EMA pseudo Dice: 0.9216\n","2024-07-18 01:54:05.449708: \n","2024-07-18 01:54:05.450041: Epoch 85\n","2024-07-18 01:54:05.450182: Current learning rate: 0.00923\n","2024-07-18 01:55:47.665217: train_loss -0.6307\n","2024-07-18 01:55:47.665510: val_loss -0.6485\n","2024-07-18 01:55:47.665628: Pseudo dice [0.9458]\n","2024-07-18 01:55:47.665726: Epoch time: 102.22 s\n","2024-07-18 01:55:47.665812: Yayy! New best EMA pseudo Dice: 0.924\n","2024-07-18 01:55:51.003488: \n","2024-07-18 01:55:51.003941: Epoch 86\n","2024-07-18 01:55:51.004148: Current learning rate: 0.00922\n","2024-07-18 01:57:33.292427: train_loss -0.6388\n","2024-07-18 01:57:33.292672: val_loss -0.694\n","2024-07-18 01:57:33.292772: Pseudo dice [0.9379]\n","2024-07-18 01:57:33.292869: Epoch time: 102.29 s\n","2024-07-18 01:57:33.292973: Yayy! New best EMA pseudo Dice: 0.9254\n","2024-07-18 01:57:36.817630: \n","2024-07-18 01:57:36.818019: Epoch 87\n","2024-07-18 01:57:36.818172: Current learning rate: 0.00921\n","2024-07-18 01:59:19.010316: train_loss -0.6394\n","2024-07-18 01:59:19.010633: val_loss -0.6067\n","2024-07-18 01:59:19.010751: Pseudo dice [0.9212]\n","2024-07-18 01:59:19.010858: Epoch time: 102.2 s\n","2024-07-18 01:59:21.132427: \n","2024-07-18 01:59:21.132855: Epoch 88\n","2024-07-18 01:59:21.133010: Current learning rate: 0.0092\n","2024-07-18 02:01:03.358994: train_loss -0.6216\n","2024-07-18 02:01:03.359282: val_loss -0.5896\n","2024-07-18 02:01:03.359390: Pseudo dice [0.8634]\n","2024-07-18 02:01:03.359485: Epoch time: 102.23 s\n","2024-07-18 02:01:04.911927: \n","2024-07-18 02:01:04.912355: Epoch 89\n","2024-07-18 02:01:04.912542: Current learning rate: 0.0092\n","2024-07-18 02:02:47.140347: train_loss -0.6158\n","2024-07-18 02:02:47.140585: val_loss -0.6674\n","2024-07-18 02:02:47.140685: Pseudo dice [0.9388]\n","2024-07-18 02:02:47.140779: Epoch time: 102.23 s\n","2024-07-18 02:02:48.690783: \n","2024-07-18 02:02:48.691159: Epoch 90\n","2024-07-18 02:02:48.691319: Current learning rate: 0.00919\n","2024-07-18 02:04:30.828673: train_loss -0.6306\n","2024-07-18 02:04:30.828908: val_loss -0.6142\n","2024-07-18 02:04:30.829025: Pseudo dice [0.8907]\n","2024-07-18 02:04:30.829119: Epoch time: 102.14 s\n","2024-07-18 02:04:32.337420: \n","2024-07-18 02:04:32.337787: Epoch 91\n","2024-07-18 02:04:32.337947: Current learning rate: 0.00918\n","2024-07-18 02:06:14.464616: train_loss -0.6252\n","2024-07-18 02:06:14.464865: val_loss -0.6336\n","2024-07-18 02:06:14.464985: Pseudo dice [0.9368]\n","2024-07-18 02:06:14.465085: Epoch time: 102.13 s\n","2024-07-18 02:06:15.983400: \n","2024-07-18 02:06:15.983734: Epoch 92\n","2024-07-18 02:06:15.983876: Current learning rate: 0.00917\n","2024-07-18 02:07:58.382460: train_loss -0.6446\n","2024-07-18 02:07:58.382740: val_loss -0.7219\n","2024-07-18 02:07:58.382852: Pseudo dice [0.9392]\n","2024-07-18 02:07:58.383005: Epoch time: 102.4 s\n","2024-07-18 02:07:59.920673: \n","2024-07-18 02:07:59.921116: Epoch 93\n","2024-07-18 02:07:59.921256: Current learning rate: 0.00916\n","2024-07-18 02:09:42.481169: train_loss -0.6318\n","2024-07-18 02:09:42.481436: val_loss -0.6913\n","2024-07-18 02:09:42.481647: Pseudo dice [0.9548]\n","2024-07-18 02:09:42.481761: Epoch time: 102.56 s\n","2024-07-18 02:09:43.969132: \n","2024-07-18 02:09:43.969471: Epoch 94\n","2024-07-18 02:09:43.969616: Current learning rate: 0.00915\n","2024-07-18 02:11:26.403561: train_loss -0.6582\n","2024-07-18 02:11:26.403814: val_loss -0.6399\n","2024-07-18 02:11:26.403914: Pseudo dice [0.9366]\n","2024-07-18 02:11:26.404021: Epoch time: 102.44 s\n","2024-07-18 02:11:26.404096: Yayy! New best EMA pseudo Dice: 0.9261\n","2024-07-18 02:11:30.454645: \n","2024-07-18 02:11:30.455000: Epoch 95\n","2024-07-18 02:11:30.455149: Current learning rate: 0.00914\n","2024-07-18 02:13:12.931874: train_loss -0.6288\n","2024-07-18 02:13:12.932171: val_loss -0.6685\n","2024-07-18 02:13:12.932283: Pseudo dice [0.9346]\n","2024-07-18 02:13:12.932430: Epoch time: 102.48 s\n","2024-07-18 02:13:12.932515: Yayy! New best EMA pseudo Dice: 0.927\n","2024-07-18 02:13:16.433378: \n","2024-07-18 02:13:16.433798: Epoch 96\n","2024-07-18 02:13:16.433969: Current learning rate: 0.00913\n","2024-07-18 02:14:58.911853: train_loss -0.6494\n","2024-07-18 02:14:58.912127: val_loss -0.6639\n","2024-07-18 02:14:58.912247: Pseudo dice [0.9286]\n","2024-07-18 02:14:58.912372: Epoch time: 102.48 s\n","2024-07-18 02:14:58.912463: Yayy! New best EMA pseudo Dice: 0.9271\n","2024-07-18 02:15:02.319839: \n","2024-07-18 02:15:02.320196: Epoch 97\n","2024-07-18 02:15:02.320335: Current learning rate: 0.00912\n","2024-07-18 02:16:44.768785: train_loss -0.6217\n","2024-07-18 02:16:44.769087: val_loss -0.6639\n","2024-07-18 02:16:44.769192: Pseudo dice [0.9383]\n","2024-07-18 02:16:44.769287: Epoch time: 102.45 s\n","2024-07-18 02:16:44.769379: Yayy! New best EMA pseudo Dice: 0.9283\n","2024-07-18 02:16:48.262979: \n","2024-07-18 02:16:48.263401: Epoch 98\n","2024-07-18 02:16:48.263565: Current learning rate: 0.00911\n","2024-07-18 02:18:30.687185: train_loss -0.6584\n","2024-07-18 02:18:30.687458: val_loss -0.4653\n","2024-07-18 02:18:30.687561: Pseudo dice [0.8351]\n","2024-07-18 02:18:30.687662: Epoch time: 102.43 s\n","2024-07-18 02:18:32.258290: \n","2024-07-18 02:18:32.258656: Epoch 99\n","2024-07-18 02:18:32.258795: Current learning rate: 0.0091\n","2024-07-18 02:20:14.705749: train_loss -0.6392\n","2024-07-18 02:20:14.706035: val_loss -0.7035\n","2024-07-18 02:20:14.706157: Pseudo dice [0.9378]\n","2024-07-18 02:20:14.706256: Epoch time: 102.45 s\n","2024-07-18 02:20:18.057897: \n","2024-07-18 02:20:18.058258: Epoch 100\n","2024-07-18 02:20:18.058405: Current learning rate: 0.0091\n","2024-07-18 02:22:00.487892: train_loss -0.6253\n","2024-07-18 02:22:00.488155: val_loss -0.6907\n","2024-07-18 02:22:00.488254: Pseudo dice [0.9447]\n","2024-07-18 02:22:00.488360: Epoch time: 102.43 s\n","2024-07-18 02:22:02.048672: \n","2024-07-18 02:22:02.049037: Epoch 101\n","2024-07-18 02:22:02.049179: Current learning rate: 0.00909\n","2024-07-18 02:23:44.968718: train_loss -0.6476\n","2024-07-18 02:23:44.969038: val_loss -0.5833\n","2024-07-18 02:23:44.969181: Pseudo dice [0.8981]\n","2024-07-18 02:23:44.969312: Epoch time: 102.92 s\n","2024-07-18 02:23:46.486469: \n","2024-07-18 02:23:46.486995: Epoch 102\n","2024-07-18 02:23:46.487162: Current learning rate: 0.00908\n","2024-07-18 02:25:28.580424: train_loss -0.613\n","2024-07-18 02:25:28.580684: val_loss -0.686\n","2024-07-18 02:25:28.580811: Pseudo dice [0.9376]\n","2024-07-18 02:25:28.580962: Epoch time: 102.1 s\n","2024-07-18 02:25:30.080841: \n","2024-07-18 02:25:30.081252: Epoch 103\n","2024-07-18 02:25:30.081400: Current learning rate: 0.00907\n","2024-07-18 02:27:11.981125: train_loss -0.6223\n","2024-07-18 02:27:11.981549: val_loss -0.6514\n","2024-07-18 02:27:11.981897: Pseudo dice [0.951]\n","2024-07-18 02:27:11.982187: Epoch time: 101.9 s\n","2024-07-18 02:27:13.576479: \n","2024-07-18 02:27:13.576882: Epoch 104\n","2024-07-18 02:27:13.577053: Current learning rate: 0.00906\n","2024-07-18 02:28:55.523895: train_loss -0.6434\n","2024-07-18 02:28:55.524175: val_loss -0.6414\n","2024-07-18 02:28:55.524276: Pseudo dice [0.9041]\n","2024-07-18 02:28:55.524371: Epoch time: 101.95 s\n","2024-07-18 02:28:57.066582: \n","2024-07-18 02:28:57.067091: Epoch 105\n","2024-07-18 02:28:57.067250: Current learning rate: 0.00905\n","2024-07-18 02:30:38.789110: train_loss -0.6338\n","2024-07-18 02:30:38.789340: val_loss -0.6326\n","2024-07-18 02:30:38.789455: Pseudo dice [0.9289]\n","2024-07-18 02:30:38.789553: Epoch time: 101.73 s\n","2024-07-18 02:30:40.319748: \n","2024-07-18 02:30:40.320055: Epoch 106\n","2024-07-18 02:30:40.320199: Current learning rate: 0.00904\n","2024-07-18 02:32:22.140287: train_loss -0.6382\n","2024-07-18 02:32:22.140604: val_loss -0.6465\n","2024-07-18 02:32:22.140707: Pseudo dice [0.9593]\n","2024-07-18 02:32:22.140802: Epoch time: 101.82 s\n","2024-07-18 02:32:23.649638: \n","2024-07-18 02:32:23.650028: Epoch 107\n","2024-07-18 02:32:23.650198: Current learning rate: 0.00903\n","2024-07-18 02:34:05.357102: train_loss -0.6399\n","2024-07-18 02:34:05.357356: val_loss -0.6594\n","2024-07-18 02:34:05.357552: Pseudo dice [0.9379]\n","2024-07-18 02:34:05.357681: Epoch time: 101.71 s\n","2024-07-18 02:34:05.357760: Yayy! New best EMA pseudo Dice: 0.9283\n","2024-07-18 02:34:08.778257: \n","2024-07-18 02:34:08.778659: Epoch 108\n","2024-07-18 02:34:08.778802: Current learning rate: 0.00902\n","2024-07-18 02:35:51.256286: train_loss -0.665\n","2024-07-18 02:35:51.256508: val_loss -0.6841\n","2024-07-18 02:35:51.256609: Pseudo dice [0.9527]\n","2024-07-18 02:35:51.256706: Epoch time: 102.48 s\n","2024-07-18 02:35:51.256782: Yayy! New best EMA pseudo Dice: 0.9308\n","2024-07-18 02:35:54.744386: \n","2024-07-18 02:35:54.744741: Epoch 109\n","2024-07-18 02:35:54.744879: Current learning rate: 0.00901\n","2024-07-18 02:37:36.611293: train_loss -0.6502\n","2024-07-18 02:37:36.611618: val_loss -0.6405\n","2024-07-18 02:37:36.611727: Pseudo dice [0.9453]\n","2024-07-18 02:37:36.611882: Epoch time: 101.87 s\n","2024-07-18 02:37:36.612037: Yayy! New best EMA pseudo Dice: 0.9322\n","2024-07-18 02:37:40.154120: \n","2024-07-18 02:37:40.154505: Epoch 110\n","2024-07-18 02:37:40.154661: Current learning rate: 0.009\n","2024-07-18 02:39:21.990098: train_loss -0.6422\n","2024-07-18 02:39:21.990343: val_loss -0.7271\n","2024-07-18 02:39:21.990488: Pseudo dice [0.9532]\n","2024-07-18 02:39:21.990596: Epoch time: 101.84 s\n","2024-07-18 02:39:21.990685: Yayy! New best EMA pseudo Dice: 0.9343\n","2024-07-18 02:39:25.401063: \n","2024-07-18 02:39:25.401478: Epoch 111\n","2024-07-18 02:39:25.401618: Current learning rate: 0.009\n","2024-07-18 02:41:07.194229: train_loss -0.6501\n","2024-07-18 02:41:07.194475: val_loss -0.6535\n","2024-07-18 02:41:07.194578: Pseudo dice [0.951]\n","2024-07-18 02:41:07.194716: Epoch time: 101.8 s\n","2024-07-18 02:41:07.194891: Yayy! New best EMA pseudo Dice: 0.936\n","2024-07-18 02:41:12.374156: \n","2024-07-18 02:41:12.374500: Epoch 112\n","2024-07-18 02:41:12.374648: Current learning rate: 0.00899\n","2024-07-18 02:42:54.250033: train_loss -0.6285\n","2024-07-18 02:42:54.250272: val_loss -0.6713\n","2024-07-18 02:42:54.250371: Pseudo dice [0.9385]\n","2024-07-18 02:42:54.250475: Epoch time: 101.88 s\n","2024-07-18 02:42:54.250574: Yayy! New best EMA pseudo Dice: 0.9362\n","2024-07-18 02:42:57.767959: \n","2024-07-18 02:42:57.768385: Epoch 113\n","2024-07-18 02:42:57.768527: Current learning rate: 0.00898\n","2024-07-18 02:44:39.535043: train_loss -0.6413\n","2024-07-18 02:44:39.535303: val_loss -0.702\n","2024-07-18 02:44:39.535413: Pseudo dice [0.9009]\n","2024-07-18 02:44:39.535540: Epoch time: 101.77 s\n","2024-07-18 02:44:41.183263: \n","2024-07-18 02:44:41.183594: Epoch 114\n","2024-07-18 02:44:41.183769: Current learning rate: 0.00897\n","2024-07-18 02:46:23.611195: train_loss -0.6627\n","2024-07-18 02:46:23.611500: val_loss -0.6846\n","2024-07-18 02:46:23.611601: Pseudo dice [0.9428]\n","2024-07-18 02:46:23.611699: Epoch time: 102.43 s\n","2024-07-18 02:46:25.100219: \n","2024-07-18 02:46:25.100598: Epoch 115\n","2024-07-18 02:46:25.100740: Current learning rate: 0.00896\n","2024-07-18 02:48:06.891475: train_loss -0.6156\n","2024-07-18 02:48:06.891945: val_loss -0.6606\n","2024-07-18 02:48:06.892094: Pseudo dice [0.9419]\n","2024-07-18 02:48:06.892255: Epoch time: 101.8 s\n","2024-07-18 02:48:08.423854: \n","2024-07-18 02:48:08.424285: Epoch 116\n","2024-07-18 02:48:08.424430: Current learning rate: 0.00895\n","2024-07-18 02:49:50.311562: train_loss -0.6442\n","2024-07-18 02:49:50.311815: val_loss -0.5844\n","2024-07-18 02:49:50.311916: Pseudo dice [0.8923]\n","2024-07-18 02:49:50.312049: Epoch time: 101.89 s\n","2024-07-18 02:49:51.862215: \n","2024-07-18 02:49:51.862450: Epoch 117\n","2024-07-18 02:49:51.862596: Current learning rate: 0.00894\n","2024-07-18 02:51:33.704289: train_loss -0.6503\n","2024-07-18 02:51:33.704681: val_loss -0.6745\n","2024-07-18 02:51:33.704798: Pseudo dice [0.9351]\n","2024-07-18 02:51:33.704935: Epoch time: 101.85 s\n","2024-07-18 02:51:35.260526: \n","2024-07-18 02:51:35.260959: Epoch 118\n","2024-07-18 02:51:35.261164: Current learning rate: 0.00893\n","2024-07-18 02:53:17.121192: train_loss -0.6304\n","2024-07-18 02:53:17.121557: val_loss -0.6077\n","2024-07-18 02:53:17.121672: Pseudo dice [0.9474]\n","2024-07-18 02:53:17.121777: Epoch time: 101.86 s\n","2024-07-18 02:53:18.682541: \n","2024-07-18 02:53:18.682902: Epoch 119\n","2024-07-18 02:53:18.683069: Current learning rate: 0.00892\n","2024-07-18 02:55:00.473481: train_loss -0.6342\n","2024-07-18 02:55:00.473760: val_loss -0.6375\n","2024-07-18 02:55:00.473877: Pseudo dice [0.9206]\n","2024-07-18 02:55:00.474137: Epoch time: 101.79 s\n","2024-07-18 02:55:02.056585: \n","2024-07-18 02:55:02.056963: Epoch 120\n","2024-07-18 02:55:02.057120: Current learning rate: 0.00891\n","2024-07-18 02:56:43.877165: train_loss -0.6755\n","2024-07-18 02:56:43.877414: val_loss -0.6596\n","2024-07-18 02:56:43.877517: Pseudo dice [0.9279]\n","2024-07-18 02:56:43.877611: Epoch time: 101.82 s\n","2024-07-18 02:56:45.416172: \n","2024-07-18 02:56:45.416490: Epoch 121\n","2024-07-18 02:56:45.416647: Current learning rate: 0.0089\n","2024-07-18 02:58:27.876582: train_loss -0.6275\n","2024-07-18 02:58:27.876958: val_loss -0.7266\n","2024-07-18 02:58:27.877109: Pseudo dice [0.9415]\n","2024-07-18 02:58:27.877238: Epoch time: 102.46 s\n","2024-07-18 02:58:29.502277: \n","2024-07-18 02:58:29.502649: Epoch 122\n","2024-07-18 02:58:29.502794: Current learning rate: 0.00889\n","2024-07-18 03:00:11.355213: train_loss -0.6382\n","2024-07-18 03:00:11.355514: val_loss -0.6208\n","2024-07-18 03:00:11.355657: Pseudo dice [0.9285]\n","2024-07-18 03:00:11.355799: Epoch time: 101.86 s\n","2024-07-18 03:00:12.903257: \n","2024-07-18 03:00:12.903576: Epoch 123\n","2024-07-18 03:00:12.903716: Current learning rate: 0.00889\n","2024-07-18 03:01:54.808907: train_loss -0.6334\n","2024-07-18 03:01:54.809291: val_loss -0.6515\n","2024-07-18 03:01:54.809482: Pseudo dice [0.897]\n","2024-07-18 03:01:54.809581: Epoch time: 101.91 s\n","2024-07-18 03:01:56.403501: \n","2024-07-18 03:01:56.403888: Epoch 124\n","2024-07-18 03:01:56.404059: Current learning rate: 0.00888\n","2024-07-18 03:03:38.236370: train_loss -0.5915\n","2024-07-18 03:03:38.236626: val_loss -0.7331\n","2024-07-18 03:03:38.236732: Pseudo dice [0.9508]\n","2024-07-18 03:03:38.236948: Epoch time: 101.84 s\n","2024-07-18 03:03:39.802138: \n","2024-07-18 03:03:39.802568: Epoch 125\n","2024-07-18 03:03:39.802719: Current learning rate: 0.00887\n","2024-07-18 03:05:21.404240: train_loss -0.6694\n","2024-07-18 03:05:21.404531: val_loss -0.5954\n","2024-07-18 03:05:21.404640: Pseudo dice [0.9159]\n","2024-07-18 03:05:21.404734: Epoch time: 101.61 s\n","2024-07-18 03:05:22.923375: \n","2024-07-18 03:05:22.923727: Epoch 126\n","2024-07-18 03:05:22.923944: Current learning rate: 0.00886\n","2024-07-18 03:07:04.750477: train_loss -0.6521\n","2024-07-18 03:07:04.750820: val_loss -0.6129\n","2024-07-18 03:07:04.750968: Pseudo dice [0.915]\n","2024-07-18 03:07:04.751099: Epoch time: 101.83 s\n","2024-07-18 03:07:06.324760: \n","2024-07-18 03:07:06.325195: Epoch 127\n","2024-07-18 03:07:06.325336: Current learning rate: 0.00885\n","2024-07-18 03:08:48.094654: train_loss -0.6711\n","2024-07-18 03:08:48.094890: val_loss -0.6944\n","2024-07-18 03:08:48.095029: Pseudo dice [0.9407]\n","2024-07-18 03:08:48.095135: Epoch time: 101.77 s\n","2024-07-18 03:08:49.651837: \n","2024-07-18 03:08:49.652155: Epoch 128\n","2024-07-18 03:08:49.652297: Current learning rate: 0.00884\n","2024-07-18 03:10:31.977966: train_loss -0.6719\n","2024-07-18 03:10:31.978246: val_loss -0.6993\n","2024-07-18 03:10:31.978473: Pseudo dice [0.9468]\n","2024-07-18 03:10:31.978573: Epoch time: 102.33 s\n","2024-07-18 03:10:33.559147: \n","2024-07-18 03:10:33.559545: Epoch 129\n","2024-07-18 03:10:33.559705: Current learning rate: 0.00883\n","2024-07-18 03:12:15.294392: train_loss -0.6853\n","2024-07-18 03:12:15.294646: val_loss -0.7384\n","2024-07-18 03:12:15.294780: Pseudo dice [0.952]\n","2024-07-18 03:12:15.294904: Epoch time: 101.74 s\n","2024-07-18 03:12:16.862718: \n","2024-07-18 03:12:16.863091: Epoch 130\n","2024-07-18 03:12:16.863234: Current learning rate: 0.00882\n","2024-07-18 03:13:58.719218: train_loss -0.6185\n","2024-07-18 03:13:58.719503: val_loss -0.6126\n","2024-07-18 03:13:58.719644: Pseudo dice [0.8947]\n","2024-07-18 03:13:58.719770: Epoch time: 101.86 s\n","2024-07-18 03:14:00.336978: \n","2024-07-18 03:14:00.337532: Epoch 131\n","2024-07-18 03:14:00.337700: Current learning rate: 0.00881\n","2024-07-18 03:15:42.214029: train_loss -0.6593\n","2024-07-18 03:15:42.214277: val_loss -0.5432\n","2024-07-18 03:15:42.214389: Pseudo dice [0.8629]\n","2024-07-18 03:15:42.214491: Epoch time: 101.88 s\n","2024-07-18 03:15:43.820964: \n","2024-07-18 03:15:43.821369: Epoch 132\n","2024-07-18 03:15:43.821634: Current learning rate: 0.0088\n","2024-07-18 03:17:25.757500: train_loss -0.6708\n","2024-07-18 03:17:25.757744: val_loss -0.6698\n","2024-07-18 03:17:25.757879: Pseudo dice [0.9225]\n","2024-07-18 03:17:25.757996: Epoch time: 101.94 s\n","2024-07-18 03:17:27.301729: \n","2024-07-18 03:17:27.302112: Epoch 133\n","2024-07-18 03:17:27.302252: Current learning rate: 0.00879\n","2024-07-18 03:19:09.019175: train_loss -0.6715\n","2024-07-18 03:19:09.019429: val_loss -0.6538\n","2024-07-18 03:19:09.019532: Pseudo dice [0.9367]\n","2024-07-18 03:19:09.019627: Epoch time: 101.72 s\n","2024-07-18 03:19:10.550503: \n","2024-07-18 03:19:10.550882: Epoch 134\n","2024-07-18 03:19:10.551050: Current learning rate: 0.00879\n","2024-07-18 03:20:52.365342: train_loss -0.6422\n","2024-07-18 03:20:52.365590: val_loss -0.6574\n","2024-07-18 03:20:52.365699: Pseudo dice [0.9173]\n","2024-07-18 03:20:52.365841: Epoch time: 101.82 s\n","2024-07-18 03:20:53.954020: \n","2024-07-18 03:20:53.954345: Epoch 135\n","2024-07-18 03:20:53.954491: Current learning rate: 0.00878\n","2024-07-18 03:22:36.309508: train_loss -0.6435\n","2024-07-18 03:22:36.309759: val_loss -0.6809\n","2024-07-18 03:22:36.309862: Pseudo dice [0.9408]\n","2024-07-18 03:22:36.309973: Epoch time: 102.36 s\n","2024-07-18 03:22:37.870121: \n","2024-07-18 03:22:37.870445: Epoch 136\n","2024-07-18 03:22:37.870584: Current learning rate: 0.00877\n","2024-07-18 03:24:19.740659: train_loss -0.638\n","2024-07-18 03:24:19.740998: val_loss -0.5899\n","2024-07-18 03:24:19.741134: Pseudo dice [0.8648]\n","2024-07-18 03:24:19.741279: Epoch time: 101.87 s\n","2024-07-18 03:24:21.337892: \n","2024-07-18 03:24:21.338294: Epoch 137\n","2024-07-18 03:24:21.338430: Current learning rate: 0.00876\n","2024-07-18 03:26:03.051187: train_loss -0.6617\n","2024-07-18 03:26:03.051527: val_loss -0.6409\n","2024-07-18 03:26:03.051667: Pseudo dice [0.9118]\n","2024-07-18 03:26:03.051807: Epoch time: 101.72 s\n","2024-07-18 03:26:04.694927: \n","2024-07-18 03:26:04.695367: Epoch 138\n","2024-07-18 03:26:04.695507: Current learning rate: 0.00875\n","2024-07-18 03:27:46.498623: train_loss -0.6333\n","2024-07-18 03:27:46.498966: val_loss -0.6603\n","2024-07-18 03:27:46.499091: Pseudo dice [0.9474]\n","2024-07-18 03:27:46.499248: Epoch time: 101.81 s\n","2024-07-18 03:27:48.059480: \n","2024-07-18 03:27:48.059794: Epoch 139\n","2024-07-18 03:27:48.059954: Current learning rate: 0.00874\n","2024-07-18 03:29:29.967750: train_loss -0.6611\n","2024-07-18 03:29:29.968054: val_loss -0.6111\n","2024-07-18 03:29:29.968223: Pseudo dice [0.915]\n","2024-07-18 03:29:29.968365: Epoch time: 101.91 s\n","2024-07-18 03:29:31.545092: \n","2024-07-18 03:29:31.545416: Epoch 140\n","2024-07-18 03:29:31.545557: Current learning rate: 0.00873\n","2024-07-18 03:31:13.350202: train_loss -0.6291\n","2024-07-18 03:31:13.350573: val_loss -0.6791\n","2024-07-18 03:31:13.350736: Pseudo dice [0.9282]\n","2024-07-18 03:31:13.350876: Epoch time: 101.81 s\n","2024-07-18 03:31:15.001354: \n","2024-07-18 03:31:15.001757: Epoch 141\n","2024-07-18 03:31:15.001990: Current learning rate: 0.00872\n","2024-07-18 03:32:56.804543: train_loss -0.6674\n","2024-07-18 03:32:56.804806: val_loss -0.6819\n","2024-07-18 03:32:56.804953: Pseudo dice [0.9335]\n","2024-07-18 03:32:56.805095: Epoch time: 101.81 s\n","2024-07-18 03:32:58.403955: \n","2024-07-18 03:32:58.404364: Epoch 142\n","2024-07-18 03:32:58.404504: Current learning rate: 0.00871\n","2024-07-18 03:34:40.719612: train_loss -0.6413\n","2024-07-18 03:34:40.719853: val_loss -0.7198\n","2024-07-18 03:34:40.719980: Pseudo dice [0.9515]\n","2024-07-18 03:34:40.720085: Epoch time: 102.32 s\n","2024-07-18 03:34:42.327706: \n","2024-07-18 03:34:42.328125: Epoch 143\n","2024-07-18 03:34:42.328274: Current learning rate: 0.0087\n","2024-07-18 03:36:24.106702: train_loss -0.6759\n","2024-07-18 03:36:24.106960: val_loss -0.5882\n","2024-07-18 03:36:24.107070: Pseudo dice [0.8917]\n","2024-07-18 03:36:24.107165: Epoch time: 101.78 s\n","2024-07-18 03:36:25.666402: \n","2024-07-18 03:36:25.666797: Epoch 144\n","2024-07-18 03:36:25.666979: Current learning rate: 0.00869\n","2024-07-18 03:38:07.350643: train_loss -0.6473\n","2024-07-18 03:38:07.350885: val_loss -0.7159\n","2024-07-18 03:38:07.351045: Pseudo dice [0.945]\n","2024-07-18 03:38:07.351152: Epoch time: 101.69 s\n","2024-07-18 03:38:08.966573: \n","2024-07-18 03:38:08.967049: Epoch 145\n","2024-07-18 03:38:08.967205: Current learning rate: 0.00868\n","2024-07-18 03:39:50.879367: train_loss -0.6699\n","2024-07-18 03:39:50.879689: val_loss -0.6855\n","2024-07-18 03:39:50.879825: Pseudo dice [0.9199]\n","2024-07-18 03:39:50.880083: Epoch time: 101.92 s\n","2024-07-18 03:39:52.550467: \n","2024-07-18 03:39:52.550792: Epoch 146\n","2024-07-18 03:39:52.550971: Current learning rate: 0.00868\n","2024-07-18 03:41:34.495477: train_loss -0.6473\n","2024-07-18 03:41:34.495768: val_loss -0.6444\n","2024-07-18 03:41:34.495872: Pseudo dice [0.929]\n","2024-07-18 03:41:34.495999: Epoch time: 101.95 s\n","2024-07-18 03:41:36.132595: \n","2024-07-18 03:41:36.133081: Epoch 147\n","2024-07-18 03:41:36.133241: Current learning rate: 0.00867\n","2024-07-18 03:43:18.128851: train_loss -0.6732\n","2024-07-18 03:43:18.129360: val_loss -0.7546\n","2024-07-18 03:43:18.129539: Pseudo dice [0.9511]\n","2024-07-18 03:43:18.129667: Epoch time: 102.0 s\n","2024-07-18 03:43:19.795812: \n","2024-07-18 03:43:19.796257: Epoch 148\n","2024-07-18 03:43:19.796402: Current learning rate: 0.00866\n","2024-07-18 03:45:01.900658: train_loss -0.6683\n","2024-07-18 03:45:01.900877: val_loss -0.6889\n","2024-07-18 03:45:01.901087: Pseudo dice [0.9453]\n","2024-07-18 03:45:01.901206: Epoch time: 102.11 s\n","2024-07-18 03:45:03.544726: \n","2024-07-18 03:45:03.545183: Epoch 149\n","2024-07-18 03:45:03.545358: Current learning rate: 0.00865\n","2024-07-18 03:46:46.370757: train_loss -0.6443\n","2024-07-18 03:46:46.371029: val_loss -0.7002\n","2024-07-18 03:46:46.371136: Pseudo dice [0.9594]\n","2024-07-18 03:46:46.371231: Epoch time: 102.83 s\n","2024-07-18 03:46:49.975759: \n","2024-07-18 03:46:49.976216: Epoch 150\n","2024-07-18 03:46:49.976357: Current learning rate: 0.00864\n","2024-07-18 03:48:32.056028: train_loss -0.6531\n","2024-07-18 03:48:32.056388: val_loss -0.6058\n","2024-07-18 03:48:32.056508: Pseudo dice [0.882]\n","2024-07-18 03:48:32.056611: Epoch time: 102.08 s\n","2024-07-18 03:48:33.652437: \n","2024-07-18 03:48:33.652899: Epoch 151\n","2024-07-18 03:48:33.653066: Current learning rate: 0.00863\n","2024-07-18 03:50:15.618856: train_loss -0.6386\n","2024-07-18 03:50:15.619154: val_loss -0.6686\n","2024-07-18 03:50:15.619287: Pseudo dice [0.9525]\n","2024-07-18 03:50:15.619439: Epoch time: 101.97 s\n","2024-07-18 03:50:17.246140: \n","2024-07-18 03:50:17.246498: Epoch 152\n","2024-07-18 03:50:17.246643: Current learning rate: 0.00862\n","2024-07-18 03:51:59.381950: train_loss -0.6643\n","2024-07-18 03:51:59.382221: val_loss -0.6781\n","2024-07-18 03:51:59.382324: Pseudo dice [0.9531]\n","2024-07-18 03:51:59.382427: Epoch time: 102.14 s\n","2024-07-18 03:52:00.966722: \n","2024-07-18 03:52:00.967134: Epoch 153\n","2024-07-18 03:52:00.967279: Current learning rate: 0.00861\n","2024-07-18 03:53:43.054369: train_loss -0.6484\n","2024-07-18 03:53:43.054660: val_loss -0.7005\n","2024-07-18 03:53:43.054840: Pseudo dice [0.9444]\n","2024-07-18 03:53:43.055161: Epoch time: 102.09 s\n","2024-07-18 03:53:44.844594: \n","2024-07-18 03:53:44.844978: Epoch 154\n","2024-07-18 03:53:44.845124: Current learning rate: 0.0086\n","2024-07-18 03:55:27.010813: train_loss -0.6429\n","2024-07-18 03:55:27.011090: val_loss -0.6956\n","2024-07-18 03:55:27.011192: Pseudo dice [0.9538]\n","2024-07-18 03:55:27.011285: Epoch time: 102.17 s\n","2024-07-18 03:55:28.617457: \n","2024-07-18 03:55:28.617777: Epoch 155\n","2024-07-18 03:55:28.617978: Current learning rate: 0.00859\n","2024-07-18 03:57:10.752501: train_loss -0.6574\n","2024-07-18 03:57:10.752772: val_loss -0.6371\n","2024-07-18 03:57:10.752909: Pseudo dice [0.9627]\n","2024-07-18 03:57:10.753107: Epoch time: 102.14 s\n","2024-07-18 03:57:10.753191: Yayy! New best EMA pseudo Dice: 0.9379\n","2024-07-18 03:57:14.983416: \n","2024-07-18 03:57:14.983996: Epoch 156\n","2024-07-18 03:57:14.984200: Current learning rate: 0.00858\n","2024-07-18 03:58:57.146692: train_loss -0.6122\n","2024-07-18 03:58:57.147187: val_loss -0.7238\n","2024-07-18 03:58:57.147307: Pseudo dice [0.9379]\n","2024-07-18 03:58:57.147399: Epoch time: 102.17 s\n","2024-07-18 03:58:58.774441: \n","2024-07-18 03:58:58.774881: Epoch 157\n","2024-07-18 03:58:58.775069: Current learning rate: 0.00858\n","2024-07-18 04:00:40.877412: train_loss -0.6536\n","2024-07-18 04:00:40.877714: val_loss -0.6756\n","2024-07-18 04:00:40.877910: Pseudo dice [0.9462]\n","2024-07-18 04:00:40.878055: Epoch time: 102.11 s\n","2024-07-18 04:00:40.878131: Yayy! New best EMA pseudo Dice: 0.9388\n","2024-07-18 04:00:44.444450: \n","2024-07-18 04:00:44.444883: Epoch 158\n","2024-07-18 04:00:44.445052: Current learning rate: 0.00857\n","2024-07-18 04:02:26.741846: train_loss -0.6549\n","2024-07-18 04:02:26.742239: val_loss -0.7136\n","2024-07-18 04:02:26.742458: Pseudo dice [0.9474]\n","2024-07-18 04:02:26.742569: Epoch time: 102.3 s\n","2024-07-18 04:02:26.742649: Yayy! New best EMA pseudo Dice: 0.9396\n","2024-07-18 04:02:30.322165: \n","2024-07-18 04:02:30.322511: Epoch 159\n","2024-07-18 04:02:30.322676: Current learning rate: 0.00856\n","2024-07-18 04:04:12.548355: train_loss -0.6537\n","2024-07-18 04:04:12.548701: val_loss -0.7314\n","2024-07-18 04:04:12.548841: Pseudo dice [0.9581]\n","2024-07-18 04:04:12.548988: Epoch time: 102.23 s\n","2024-07-18 04:04:12.549096: Yayy! New best EMA pseudo Dice: 0.9415\n","2024-07-18 04:04:16.141260: \n","2024-07-18 04:04:16.141668: Epoch 160\n","2024-07-18 04:04:16.141816: Current learning rate: 0.00855\n","2024-07-18 04:05:58.304574: train_loss -0.6753\n","2024-07-18 04:05:58.304844: val_loss -0.6675\n","2024-07-18 04:05:58.305441: Pseudo dice [0.903]\n","2024-07-18 04:05:58.305772: Epoch time: 102.17 s\n","2024-07-18 04:05:59.954366: \n","2024-07-18 04:05:59.954787: Epoch 161\n","2024-07-18 04:05:59.954941: Current learning rate: 0.00854\n","2024-07-18 04:07:42.025686: train_loss -0.6591\n","2024-07-18 04:07:42.025972: val_loss -0.6632\n","2024-07-18 04:07:42.026204: Pseudo dice [0.9511]\n","2024-07-18 04:07:42.026321: Epoch time: 102.08 s\n","2024-07-18 04:07:44.290446: \n","2024-07-18 04:07:44.290881: Epoch 162\n","2024-07-18 04:07:44.291041: Current learning rate: 0.00853\n","2024-07-18 04:09:26.542339: train_loss -0.6605\n","2024-07-18 04:09:26.542737: val_loss -0.6882\n","2024-07-18 04:09:26.542894: Pseudo dice [0.9549]\n","2024-07-18 04:09:26.543037: Epoch time: 102.26 s\n","2024-07-18 04:09:28.166297: \n","2024-07-18 04:09:28.166694: Epoch 163\n","2024-07-18 04:09:28.166853: Current learning rate: 0.00852\n","2024-07-18 04:11:10.169043: train_loss -0.6761\n","2024-07-18 04:11:10.169290: val_loss -0.6503\n","2024-07-18 04:11:10.169388: Pseudo dice [0.9519]\n","2024-07-18 04:11:10.169520: Epoch time: 102.01 s\n","2024-07-18 04:11:10.169622: Yayy! New best EMA pseudo Dice: 0.9417\n","2024-07-18 04:11:13.786678: \n","2024-07-18 04:11:13.787068: Epoch 164\n","2024-07-18 04:11:13.787211: Current learning rate: 0.00851\n","2024-07-18 04:12:55.833550: train_loss -0.6695\n","2024-07-18 04:12:55.833808: val_loss -0.6614\n","2024-07-18 04:12:55.833910: Pseudo dice [0.9482]\n","2024-07-18 04:12:55.834027: Epoch time: 102.05 s\n","2024-07-18 04:12:55.834116: Yayy! New best EMA pseudo Dice: 0.9424\n","2024-07-18 04:12:59.479795: \n","2024-07-18 04:12:59.480263: Epoch 165\n","2024-07-18 04:12:59.480411: Current learning rate: 0.0085\n","2024-07-18 04:14:41.531849: train_loss -0.6716\n","2024-07-18 04:14:41.532435: val_loss -0.6392\n","2024-07-18 04:14:41.532550: Pseudo dice [0.9223]\n","2024-07-18 04:14:41.532642: Epoch time: 102.06 s\n","2024-07-18 04:14:43.090050: \n","2024-07-18 04:14:43.090543: Epoch 166\n","2024-07-18 04:14:43.090685: Current learning rate: 0.00849\n","2024-07-18 04:16:25.035445: train_loss -0.6541\n","2024-07-18 04:16:25.035716: val_loss -0.6265\n","2024-07-18 04:16:25.035958: Pseudo dice [0.9129]\n","2024-07-18 04:16:25.036194: Epoch time: 101.95 s\n","2024-07-18 04:16:26.607010: \n","2024-07-18 04:16:26.607452: Epoch 167\n","2024-07-18 04:16:26.607591: Current learning rate: 0.00848\n","2024-07-18 04:18:08.346285: train_loss -0.6545\n","2024-07-18 04:18:08.346566: val_loss -0.6735\n","2024-07-18 04:18:08.346684: Pseudo dice [0.9494]\n","2024-07-18 04:18:08.346892: Epoch time: 101.74 s\n","2024-07-18 04:18:09.881305: \n","2024-07-18 04:18:09.881641: Epoch 168\n","2024-07-18 04:18:09.881870: Current learning rate: 0.00847\n","2024-07-18 04:19:51.655392: train_loss -0.6445\n","2024-07-18 04:19:51.655618: val_loss -0.6518\n","2024-07-18 04:19:51.655723: Pseudo dice [0.9447]\n","2024-07-18 04:19:51.655812: Epoch time: 101.78 s\n","2024-07-18 04:19:53.818134: \n","2024-07-18 04:19:53.818494: Epoch 169\n","2024-07-18 04:19:53.818629: Current learning rate: 0.00847\n","2024-07-18 04:21:35.514722: train_loss -0.6478\n","2024-07-18 04:21:35.514982: val_loss -0.7047\n","2024-07-18 04:21:35.515088: Pseudo dice [0.9384]\n","2024-07-18 04:21:35.515183: Epoch time: 101.7 s\n","2024-07-18 04:21:37.121956: \n","2024-07-18 04:21:37.122290: Epoch 170\n","2024-07-18 04:21:37.122450: Current learning rate: 0.00846\n","2024-07-18 04:23:18.871449: train_loss -0.6448\n","2024-07-18 04:23:18.872052: val_loss -0.6338\n","2024-07-18 04:23:18.872190: Pseudo dice [0.9277]\n","2024-07-18 04:23:18.872286: Epoch time: 101.75 s\n","2024-07-18 04:23:20.492615: \n","2024-07-18 04:23:20.493041: Epoch 171\n","2024-07-18 04:23:20.493197: Current learning rate: 0.00845\n","2024-07-18 04:25:02.215766: train_loss -0.6598\n","2024-07-18 04:25:02.216098: val_loss -0.7141\n","2024-07-18 04:25:02.216313: Pseudo dice [0.9576]\n","2024-07-18 04:25:02.216529: Epoch time: 101.73 s\n","2024-07-18 04:25:03.822904: \n","2024-07-18 04:25:03.823242: Epoch 172\n","2024-07-18 04:25:03.823384: Current learning rate: 0.00844\n","2024-07-18 04:26:45.479033: train_loss -0.6309\n","2024-07-18 04:26:45.479263: val_loss -0.6251\n","2024-07-18 04:26:45.479400: Pseudo dice [0.924]\n","2024-07-18 04:26:45.479520: Epoch time: 101.66 s\n","2024-07-18 04:26:47.050946: \n","2024-07-18 04:26:47.051330: Epoch 173\n","2024-07-18 04:26:47.051491: Current learning rate: 0.00843\n","2024-07-18 04:28:28.731723: train_loss -0.6322\n","2024-07-18 04:28:28.732145: val_loss -0.6612\n","2024-07-18 04:28:28.732280: Pseudo dice [0.8975]\n","2024-07-18 04:28:28.732400: Epoch time: 101.68 s\n","2024-07-18 04:28:30.310899: \n","2024-07-18 04:28:30.311253: Epoch 174\n","2024-07-18 04:28:30.311410: Current learning rate: 0.00842\n","2024-07-18 04:30:12.036515: train_loss -0.6592\n","2024-07-18 04:30:12.036784: val_loss -0.6125\n","2024-07-18 04:30:12.036886: Pseudo dice [0.9006]\n","2024-07-18 04:30:12.037022: Epoch time: 101.73 s\n","2024-07-18 04:30:13.621186: \n","2024-07-18 04:30:13.621579: Epoch 175\n","2024-07-18 04:30:13.621733: Current learning rate: 0.00841\n","2024-07-18 04:31:55.228753: train_loss -0.6445\n","2024-07-18 04:31:55.229013: val_loss -0.6138\n","2024-07-18 04:31:55.229113: Pseudo dice [0.9077]\n","2024-07-18 04:31:55.229301: Epoch time: 101.61 s\n","2024-07-18 04:31:57.442405: \n","2024-07-18 04:31:57.442771: Epoch 176\n","2024-07-18 04:31:57.442975: Current learning rate: 0.0084\n","2024-07-18 04:33:39.391576: train_loss -0.6699\n","2024-07-18 04:33:39.391956: val_loss -0.6474\n","2024-07-18 04:33:39.392194: Pseudo dice [0.9341]\n","2024-07-18 04:33:39.392322: Epoch time: 101.95 s\n","2024-07-18 04:33:41.008708: \n","2024-07-18 04:33:41.009065: Epoch 177\n","2024-07-18 04:33:41.009240: Current learning rate: 0.00839\n","2024-07-18 04:35:22.796559: train_loss -0.6413\n","2024-07-18 04:35:22.797038: val_loss -0.6472\n","2024-07-18 04:35:22.797196: Pseudo dice [0.9299]\n","2024-07-18 04:35:22.797319: Epoch time: 101.79 s\n","2024-07-18 04:35:24.398016: \n","2024-07-18 04:35:24.398374: Epoch 178\n","2024-07-18 04:35:24.398536: Current learning rate: 0.00838\n","2024-07-18 04:37:06.268440: train_loss -0.6425\n","2024-07-18 04:37:06.268721: val_loss -0.6378\n","2024-07-18 04:37:06.268829: Pseudo dice [0.9442]\n","2024-07-18 04:37:06.268961: Epoch time: 101.87 s\n","2024-07-18 04:37:07.822534: \n","2024-07-18 04:37:07.822895: Epoch 179\n","2024-07-18 04:37:07.823074: Current learning rate: 0.00837\n","2024-07-18 04:38:49.582594: train_loss -0.6447\n","2024-07-18 04:38:49.582907: val_loss -0.6502\n","2024-07-18 04:38:49.583256: Pseudo dice [0.946]\n","2024-07-18 04:38:49.583360: Epoch time: 101.76 s\n","2024-07-18 04:38:51.246465: \n","2024-07-18 04:38:51.246943: Epoch 180\n","2024-07-18 04:38:51.247104: Current learning rate: 0.00836\n","2024-07-18 04:40:32.987150: train_loss -0.6622\n","2024-07-18 04:40:32.987399: val_loss -0.6399\n","2024-07-18 04:40:32.987509: Pseudo dice [0.9202]\n","2024-07-18 04:40:32.987610: Epoch time: 101.74 s\n","2024-07-18 04:40:34.574150: \n","2024-07-18 04:40:34.574553: Epoch 181\n","2024-07-18 04:40:34.574727: Current learning rate: 0.00836\n","2024-07-18 04:42:16.375171: train_loss -0.6507\n","2024-07-18 04:42:16.375422: val_loss -0.5668\n","2024-07-18 04:42:16.375525: Pseudo dice [0.8882]\n","2024-07-18 04:42:16.375623: Epoch time: 101.81 s\n","2024-07-18 04:42:17.926611: \n","2024-07-18 04:42:17.926975: Epoch 182\n","2024-07-18 04:42:17.927121: Current learning rate: 0.00835\n","2024-07-18 04:43:59.744382: train_loss -0.5942\n","2024-07-18 04:43:59.744648: val_loss -0.6417\n","2024-07-18 04:43:59.744754: Pseudo dice [0.9139]\n","2024-07-18 04:43:59.744885: Epoch time: 101.82 s\n","2024-07-18 04:44:01.909819: \n","2024-07-18 04:44:01.910245: Epoch 183\n","2024-07-18 04:44:01.910423: Current learning rate: 0.00834\n","2024-07-18 04:45:43.734599: train_loss -0.6278\n","2024-07-18 04:45:43.734875: val_loss -0.661\n","2024-07-18 04:45:43.735053: Pseudo dice [0.9325]\n","2024-07-18 04:45:43.735194: Epoch time: 101.83 s\n","2024-07-18 04:45:45.268708: \n","2024-07-18 04:45:45.269023: Epoch 184\n","2024-07-18 04:45:45.269170: Current learning rate: 0.00833\n","2024-07-18 04:47:27.021468: train_loss -0.662\n","2024-07-18 04:47:27.021734: val_loss -0.7641\n","2024-07-18 04:47:27.021845: Pseudo dice [0.9559]\n","2024-07-18 04:47:27.021982: Epoch time: 101.76 s\n","2024-07-18 04:47:28.658782: \n","2024-07-18 04:47:28.659254: Epoch 185\n","2024-07-18 04:47:28.659408: Current learning rate: 0.00832\n","2024-07-18 04:49:10.468137: train_loss -0.645\n","2024-07-18 04:49:10.468406: val_loss -0.6948\n","2024-07-18 04:49:10.468541: Pseudo dice [0.9511]\n","2024-07-18 04:49:10.468640: Epoch time: 101.81 s\n","2024-07-18 04:49:12.122389: \n","2024-07-18 04:49:12.122751: Epoch 186\n","2024-07-18 04:49:12.122908: Current learning rate: 0.00831\n","2024-07-18 04:50:53.812245: train_loss -0.6353\n","2024-07-18 04:50:53.812506: val_loss -0.6672\n","2024-07-18 04:50:53.812708: Pseudo dice [0.9001]\n","2024-07-18 04:50:53.812954: Epoch time: 101.69 s\n","2024-07-18 04:50:55.346136: \n","2024-07-18 04:50:55.346486: Epoch 187\n","2024-07-18 04:50:55.346650: Current learning rate: 0.0083\n","2024-07-18 04:52:37.272593: train_loss -0.6656\n","2024-07-18 04:52:37.272884: val_loss -0.7411\n","2024-07-18 04:52:37.273080: Pseudo dice [0.9576]\n","2024-07-18 04:52:37.273274: Epoch time: 101.93 s\n","2024-07-18 04:52:38.856932: \n","2024-07-18 04:52:38.857241: Epoch 188\n","2024-07-18 04:52:38.857418: Current learning rate: 0.00829\n","2024-07-18 04:54:20.501646: train_loss -0.6862\n","2024-07-18 04:54:20.502174: val_loss -0.7699\n","2024-07-18 04:54:20.502302: Pseudo dice [0.9556]\n","2024-07-18 04:54:20.502427: Epoch time: 101.65 s\n","2024-07-18 04:54:22.085438: \n","2024-07-18 04:54:22.085874: Epoch 189\n","2024-07-18 04:54:22.086025: Current learning rate: 0.00828\n","2024-07-18 04:56:03.873209: train_loss -0.6556\n","2024-07-18 04:56:03.873481: val_loss -0.6217\n","2024-07-18 04:56:03.873587: Pseudo dice [0.9313]\n","2024-07-18 04:56:03.873683: Epoch time: 101.79 s\n","2024-07-18 04:56:06.081317: \n","2024-07-18 04:56:06.081686: Epoch 190\n","2024-07-18 04:56:06.081864: Current learning rate: 0.00827\n","2024-07-18 04:57:48.073341: train_loss -0.6473\n","2024-07-18 04:57:48.073719: val_loss -0.7055\n","2024-07-18 04:57:48.073907: Pseudo dice [0.9455]\n","2024-07-18 04:57:48.074045: Epoch time: 102.0 s\n","2024-07-18 04:57:49.686905: \n","2024-07-18 04:57:49.687334: Epoch 191\n","2024-07-18 04:57:49.687478: Current learning rate: 0.00826\n","2024-07-18 04:59:31.504159: train_loss -0.6663\n","2024-07-18 04:59:31.504551: val_loss -0.7606\n","2024-07-18 04:59:31.504671: Pseudo dice [0.9527]\n","2024-07-18 04:59:31.504769: Epoch time: 101.82 s\n","2024-07-18 04:59:33.126455: \n","2024-07-18 04:59:33.126885: Epoch 192\n","2024-07-18 04:59:33.127085: Current learning rate: 0.00825\n","2024-07-18 05:01:14.977303: train_loss -0.6549\n","2024-07-18 05:01:14.977552: val_loss -0.6339\n","2024-07-18 05:01:14.977656: Pseudo dice [0.931]\n","2024-07-18 05:01:14.977751: Epoch time: 101.85 s\n","2024-07-18 05:01:16.617338: \n","2024-07-18 05:01:16.617722: Epoch 193\n","2024-07-18 05:01:16.617866: Current learning rate: 0.00824\n","2024-07-18 05:02:58.315560: train_loss -0.6151\n","2024-07-18 05:02:58.315802: val_loss -0.6281\n","2024-07-18 05:02:58.315904: Pseudo dice [0.9347]\n","2024-07-18 05:02:58.316032: Epoch time: 101.7 s\n","2024-07-18 05:02:59.915293: \n","2024-07-18 05:02:59.915702: Epoch 194\n","2024-07-18 05:02:59.915842: Current learning rate: 0.00824\n","2024-07-18 05:04:41.878901: train_loss -0.6588\n","2024-07-18 05:04:41.879165: val_loss -0.664\n","2024-07-18 05:04:41.879356: Pseudo dice [0.9419]\n","2024-07-18 05:04:41.879473: Epoch time: 101.97 s\n","2024-07-18 05:04:43.471841: \n","2024-07-18 05:04:43.472198: Epoch 195\n","2024-07-18 05:04:43.472361: Current learning rate: 0.00823\n","2024-07-18 05:06:25.419307: train_loss -0.6895\n","2024-07-18 05:06:25.419829: val_loss -0.6572\n","2024-07-18 05:06:25.420004: Pseudo dice [0.9562]\n","2024-07-18 05:06:25.420116: Epoch time: 101.95 s\n","2024-07-18 05:06:27.032721: \n","2024-07-18 05:06:27.033195: Epoch 196\n","2024-07-18 05:06:27.033349: Current learning rate: 0.00822\n","2024-07-18 05:08:08.707709: train_loss -0.6666\n","2024-07-18 05:08:08.707946: val_loss -0.6535\n","2024-07-18 05:08:08.708050: Pseudo dice [0.9178]\n","2024-07-18 05:08:08.708145: Epoch time: 101.68 s\n","2024-07-18 05:08:10.910625: \n","2024-07-18 05:08:10.911016: Epoch 197\n","2024-07-18 05:08:10.911173: Current learning rate: 0.00821\n","2024-07-18 05:09:52.844403: train_loss -0.6353\n","2024-07-18 05:09:52.844658: val_loss -0.6624\n","2024-07-18 05:09:52.844761: Pseudo dice [0.9202]\n","2024-07-18 05:09:52.844856: Epoch time: 101.94 s\n","2024-07-18 05:09:54.464000: \n","2024-07-18 05:09:54.464360: Epoch 198\n","2024-07-18 05:09:54.464515: Current learning rate: 0.0082\n","2024-07-18 05:11:36.187920: train_loss -0.6685\n","2024-07-18 05:11:36.188198: val_loss -0.6451\n","2024-07-18 05:11:36.188295: Pseudo dice [0.9459]\n","2024-07-18 05:11:36.188387: Epoch time: 101.73 s\n","2024-07-18 05:11:37.850966: \n","2024-07-18 05:11:37.851332: Epoch 199\n","2024-07-18 05:11:37.851494: Current learning rate: 0.00819\n","2024-07-18 05:13:19.662306: train_loss -0.6751\n","2024-07-18 05:13:19.662706: val_loss -0.5792\n","2024-07-18 05:13:19.662825: Pseudo dice [0.9299]\n","2024-07-18 05:13:19.662946: Epoch time: 101.82 s\n","2024-07-18 05:13:23.277077: \n","2024-07-18 05:13:23.277488: Epoch 200\n","2024-07-18 05:13:23.277639: Current learning rate: 0.00818\n","2024-07-18 05:15:04.993994: train_loss -0.657\n","2024-07-18 05:15:04.994229: val_loss -0.6427\n","2024-07-18 05:15:04.994330: Pseudo dice [0.9479]\n","2024-07-18 05:15:04.994426: Epoch time: 101.72 s\n","2024-07-18 05:15:06.588235: \n","2024-07-18 05:15:06.588557: Epoch 201\n","2024-07-18 05:15:06.588697: Current learning rate: 0.00817\n","2024-07-18 05:16:48.294761: train_loss -0.6598\n","2024-07-18 05:16:48.295089: val_loss -0.7085\n","2024-07-18 05:16:48.295205: Pseudo dice [0.9542]\n","2024-07-18 05:16:48.295313: Epoch time: 101.71 s\n","2024-07-18 05:16:49.933005: \n","2024-07-18 05:16:49.933393: Epoch 202\n","2024-07-18 05:16:49.933543: Current learning rate: 0.00816\n","2024-07-18 05:18:31.674868: train_loss -0.66\n","2024-07-18 05:18:31.675132: val_loss -0.5693\n","2024-07-18 05:18:31.675233: Pseudo dice [0.9069]\n","2024-07-18 05:18:31.675329: Epoch time: 101.75 s\n","2024-07-18 05:18:33.338938: \n","2024-07-18 05:18:33.339365: Epoch 203\n","2024-07-18 05:18:33.339520: Current learning rate: 0.00815\n","2024-07-18 05:20:15.582168: train_loss -0.6488\n","2024-07-18 05:20:15.582440: val_loss -0.6841\n","2024-07-18 05:20:15.582540: Pseudo dice [0.9382]\n","2024-07-18 05:20:15.582640: Epoch time: 102.25 s\n","2024-07-18 05:20:17.146717: \n","2024-07-18 05:20:17.147075: Epoch 204\n","2024-07-18 05:20:17.147217: Current learning rate: 0.00814\n","2024-07-18 05:21:58.944076: train_loss -0.6643\n","2024-07-18 05:21:58.944597: val_loss -0.6582\n","2024-07-18 05:21:58.944724: Pseudo dice [0.9413]\n","2024-07-18 05:21:58.944857: Epoch time: 101.8 s\n","2024-07-18 05:22:00.622397: \n","2024-07-18 05:22:00.622772: Epoch 205\n","2024-07-18 05:22:00.622964: Current learning rate: 0.00813\n","2024-07-18 05:23:42.412285: train_loss -0.6474\n","2024-07-18 05:23:42.412649: val_loss -0.7332\n","2024-07-18 05:23:42.412767: Pseudo dice [0.9596]\n","2024-07-18 05:23:42.412870: Epoch time: 101.79 s\n","2024-07-18 05:23:43.964507: \n","2024-07-18 05:23:43.964930: Epoch 206\n","2024-07-18 05:23:43.965102: Current learning rate: 0.00813\n","2024-07-18 05:25:25.882891: train_loss -0.6874\n","2024-07-18 05:25:25.883149: val_loss -0.7054\n","2024-07-18 05:25:25.883247: Pseudo dice [0.9574]\n","2024-07-18 05:25:25.883343: Epoch time: 101.92 s\n","2024-07-18 05:25:27.358631: \n","2024-07-18 05:25:27.358986: Epoch 207\n","2024-07-18 05:25:27.359130: Current learning rate: 0.00812\n","2024-07-18 05:27:09.090384: train_loss -0.6534\n","2024-07-18 05:27:09.090630: val_loss -0.6216\n","2024-07-18 05:27:09.090826: Pseudo dice [0.951]\n","2024-07-18 05:27:09.091000: Epoch time: 101.74 s\n","2024-07-18 05:27:10.620474: \n","2024-07-18 05:27:10.620888: Epoch 208\n","2024-07-18 05:27:10.621073: Current learning rate: 0.00811\n","2024-07-18 05:28:52.395427: train_loss -0.6671\n","2024-07-18 05:28:52.395867: val_loss -0.6628\n","2024-07-18 05:28:52.396029: Pseudo dice [0.9562]\n","2024-07-18 05:28:52.396127: Epoch time: 101.78 s\n","2024-07-18 05:28:52.396202: Yayy! New best EMA pseudo Dice: 0.9428\n","2024-07-18 05:28:55.806638: \n","2024-07-18 05:28:55.807040: Epoch 209\n","2024-07-18 05:28:55.807212: Current learning rate: 0.0081\n","2024-07-18 05:30:37.741565: train_loss -0.612\n","2024-07-18 05:30:37.741886: val_loss -0.6404\n","2024-07-18 05:30:37.742011: Pseudo dice [0.8969]\n","2024-07-18 05:30:37.742121: Epoch time: 101.94 s\n","2024-07-18 05:30:39.268970: \n","2024-07-18 05:30:39.269344: Epoch 210\n","2024-07-18 05:30:39.269480: Current learning rate: 0.00809\n","2024-07-18 05:32:21.546438: train_loss -0.594\n","2024-07-18 05:32:21.546685: val_loss -0.6569\n","2024-07-18 05:32:21.546786: Pseudo dice [0.9227]\n","2024-07-18 05:32:21.546880: Epoch time: 102.28 s\n","2024-07-18 05:32:23.093821: \n","2024-07-18 05:32:23.094224: Epoch 211\n","2024-07-18 05:32:23.094364: Current learning rate: 0.00808\n","2024-07-18 05:34:04.842845: train_loss -0.6501\n","2024-07-18 05:34:04.843115: val_loss -0.669\n","2024-07-18 05:34:04.843252: Pseudo dice [0.9412]\n","2024-07-18 05:34:04.843350: Epoch time: 101.75 s\n","2024-07-18 05:34:06.375169: \n","2024-07-18 05:34:06.375599: Epoch 212\n","2024-07-18 05:34:06.375762: Current learning rate: 0.00807\n","2024-07-18 05:35:48.127723: train_loss -0.6332\n","2024-07-18 05:35:48.127987: val_loss -0.6469\n","2024-07-18 05:35:48.128269: Pseudo dice [0.9218]\n","2024-07-18 05:35:48.128414: Epoch time: 101.76 s\n","2024-07-18 05:35:49.661644: \n","2024-07-18 05:35:49.662087: Epoch 213\n","2024-07-18 05:35:49.662240: Current learning rate: 0.00806\n","2024-07-18 05:37:31.457532: train_loss -0.6411\n","2024-07-18 05:37:31.457802: val_loss -0.6638\n","2024-07-18 05:37:31.457959: Pseudo dice [0.932]\n","2024-07-18 05:37:31.458079: Epoch time: 101.8 s\n","2024-07-18 05:37:33.029956: \n","2024-07-18 05:37:33.030349: Epoch 214\n","2024-07-18 05:37:33.030503: Current learning rate: 0.00805\n","2024-07-18 05:39:14.711730: train_loss -0.6454\n","2024-07-18 05:39:14.712103: val_loss -0.6653\n","2024-07-18 05:39:14.712257: Pseudo dice [0.9231]\n","2024-07-18 05:39:14.712390: Epoch time: 101.69 s\n","2024-07-18 05:39:16.226357: \n","2024-07-18 05:39:16.226715: Epoch 215\n","2024-07-18 05:39:16.226856: Current learning rate: 0.00804\n","2024-07-18 05:40:58.058468: train_loss -0.6577\n","2024-07-18 05:40:58.058726: val_loss -0.6093\n","2024-07-18 05:40:58.058858: Pseudo dice [0.8911]\n","2024-07-18 05:40:58.059011: Epoch time: 101.84 s\n","2024-07-18 05:40:59.589678: \n","2024-07-18 05:40:59.590021: Epoch 216\n","2024-07-18 05:40:59.590171: Current learning rate: 0.00803\n","2024-07-18 05:42:41.252803: train_loss -0.6429\n","2024-07-18 05:42:41.253070: val_loss -0.6726\n","2024-07-18 05:42:41.253178: Pseudo dice [0.9527]\n","2024-07-18 05:42:41.253357: Epoch time: 101.67 s\n","2024-07-18 05:42:42.893080: \n","2024-07-18 05:42:42.893468: Epoch 217\n","2024-07-18 05:42:42.893613: Current learning rate: 0.00802\n","2024-07-18 05:44:25.214074: train_loss -0.633\n","2024-07-18 05:44:25.214373: val_loss -0.6877\n","2024-07-18 05:44:25.214539: Pseudo dice [0.9595]\n","2024-07-18 05:44:25.214646: Epoch time: 102.33 s\n","2024-07-18 05:44:26.730296: \n","2024-07-18 05:44:26.730643: Epoch 218\n","2024-07-18 05:44:26.730786: Current learning rate: 0.00801\n","2024-07-18 05:46:08.684520: train_loss -0.6511\n","2024-07-18 05:46:08.684782: val_loss -0.6505\n","2024-07-18 05:46:08.685063: Pseudo dice [0.9393]\n","2024-07-18 05:46:08.685170: Epoch time: 101.96 s\n","2024-07-18 05:46:10.310461: \n","2024-07-18 05:46:10.310886: Epoch 219\n","2024-07-18 05:46:10.311077: Current learning rate: 0.00801\n","2024-07-18 05:47:52.093698: train_loss -0.6706\n","2024-07-18 05:47:52.094016: val_loss -0.6083\n","2024-07-18 05:47:52.094141: Pseudo dice [0.9483]\n","2024-07-18 05:47:52.094253: Epoch time: 101.79 s\n","2024-07-18 05:47:53.588869: \n","2024-07-18 05:47:53.589253: Epoch 220\n","2024-07-18 05:47:53.589417: Current learning rate: 0.008\n","2024-07-18 05:49:35.379921: train_loss -0.6691\n","2024-07-18 05:49:35.380285: val_loss -0.5842\n","2024-07-18 05:49:35.380417: Pseudo dice [0.8758]\n","2024-07-18 05:49:35.380584: Epoch time: 101.79 s\n","2024-07-18 05:49:36.942484: \n","2024-07-18 05:49:36.942930: Epoch 221\n","2024-07-18 05:49:36.943121: Current learning rate: 0.00799\n","2024-07-18 05:51:18.835268: train_loss -0.6075\n","2024-07-18 05:51:18.835511: val_loss -0.6661\n","2024-07-18 05:51:18.835613: Pseudo dice [0.9454]\n","2024-07-18 05:51:18.835716: Epoch time: 101.9 s\n","2024-07-18 05:51:20.401802: \n","2024-07-18 05:51:20.402181: Epoch 222\n","2024-07-18 05:51:20.402322: Current learning rate: 0.00798\n","2024-07-18 05:53:02.157423: train_loss -0.6705\n","2024-07-18 05:53:02.157700: val_loss -0.7072\n","2024-07-18 05:53:02.157830: Pseudo dice [0.955]\n","2024-07-18 05:53:02.158004: Epoch time: 101.76 s\n","2024-07-18 05:53:03.718928: \n","2024-07-18 05:53:03.719370: Epoch 223\n","2024-07-18 05:53:03.719548: Current learning rate: 0.00797\n","2024-07-18 05:54:45.531724: train_loss -0.6653\n","2024-07-18 05:54:45.532264: val_loss -0.7723\n","2024-07-18 05:54:45.532394: Pseudo dice [0.9621]\n","2024-07-18 05:54:45.532496: Epoch time: 101.82 s\n","2024-07-18 05:54:47.052605: \n","2024-07-18 05:54:47.052955: Epoch 224\n","2024-07-18 05:54:47.053101: Current learning rate: 0.00796\n","2024-07-18 05:56:29.517468: train_loss -0.6594\n","2024-07-18 05:56:29.517845: val_loss -0.6485\n","2024-07-18 05:56:29.518004: Pseudo dice [0.9493]\n","2024-07-18 05:56:29.518142: Epoch time: 102.47 s\n","2024-07-18 05:56:31.081734: \n","2024-07-18 05:56:31.082197: Epoch 225\n","2024-07-18 05:56:31.082344: Current learning rate: 0.00795\n","2024-07-18 05:58:13.035602: train_loss -0.6739\n","2024-07-18 05:58:13.035855: val_loss -0.6474\n","2024-07-18 05:58:13.035968: Pseudo dice [0.9449]\n","2024-07-18 05:58:13.036070: Epoch time: 101.96 s\n","2024-07-18 05:58:14.525124: \n","2024-07-18 05:58:14.525474: Epoch 226\n","2024-07-18 05:58:14.525615: Current learning rate: 0.00794\n","2024-07-18 05:59:56.433172: train_loss -0.6417\n","2024-07-18 05:59:56.433509: val_loss -0.6411\n","2024-07-18 05:59:56.433620: Pseudo dice [0.9508]\n","2024-07-18 05:59:56.433761: Epoch time: 101.91 s\n","2024-07-18 05:59:57.973685: \n","2024-07-18 05:59:57.974126: Epoch 227\n","2024-07-18 05:59:57.974267: Current learning rate: 0.00793\n","2024-07-18 06:01:39.871344: train_loss -0.6706\n","2024-07-18 06:01:39.871600: val_loss -0.6838\n","2024-07-18 06:01:39.871702: Pseudo dice [0.942]\n","2024-07-18 06:01:39.871831: Epoch time: 101.9 s\n","2024-07-18 06:01:41.419745: \n","2024-07-18 06:01:41.420226: Epoch 228\n","2024-07-18 06:01:41.420381: Current learning rate: 0.00792\n","2024-07-18 06:03:23.421048: train_loss -0.6318\n","2024-07-18 06:03:23.421305: val_loss -0.6945\n","2024-07-18 06:03:23.421516: Pseudo dice [0.9241]\n","2024-07-18 06:03:23.421653: Epoch time: 102.01 s\n","2024-07-18 06:03:24.946281: \n","2024-07-18 06:03:24.946671: Epoch 229\n","2024-07-18 06:03:24.946840: Current learning rate: 0.00791\n","2024-07-18 06:05:06.928684: train_loss -0.6462\n","2024-07-18 06:05:06.929010: val_loss -0.7334\n","2024-07-18 06:05:06.929138: Pseudo dice [0.9631]\n","2024-07-18 06:05:06.929273: Epoch time: 101.99 s\n","2024-07-18 06:05:08.487709: \n","2024-07-18 06:05:08.488290: Epoch 230\n","2024-07-18 06:05:08.488496: Current learning rate: 0.0079\n","2024-07-18 06:06:50.273051: train_loss -0.6636\n","2024-07-18 06:06:50.273300: val_loss -0.6917\n","2024-07-18 06:06:50.273553: Pseudo dice [0.9579]\n","2024-07-18 06:06:50.273665: Epoch time: 101.79 s\n","2024-07-18 06:06:51.763579: \n","2024-07-18 06:06:51.764013: Epoch 231\n","2024-07-18 06:06:51.764154: Current learning rate: 0.00789\n","2024-07-18 06:08:34.170111: train_loss -0.664\n","2024-07-18 06:08:34.170372: val_loss -0.6809\n","2024-07-18 06:08:34.170474: Pseudo dice [0.9523]\n","2024-07-18 06:08:34.170577: Epoch time: 102.41 s\n","2024-07-18 06:08:34.170665: Yayy! New best EMA pseudo Dice: 0.9438\n","2024-07-18 06:08:37.557819: \n","2024-07-18 06:08:37.558195: Epoch 232\n","2024-07-18 06:08:37.558336: Current learning rate: 0.00789\n","2024-07-18 06:10:19.465800: train_loss -0.6436\n","2024-07-18 06:10:19.466062: val_loss -0.707\n","2024-07-18 06:10:19.466204: Pseudo dice [0.9602]\n","2024-07-18 06:10:19.466321: Epoch time: 101.91 s\n","2024-07-18 06:10:19.466531: Yayy! New best EMA pseudo Dice: 0.9454\n","2024-07-18 06:10:23.120697: \n","2024-07-18 06:10:23.121115: Epoch 233\n","2024-07-18 06:10:23.121287: Current learning rate: 0.00788\n","2024-07-18 06:12:05.068470: train_loss -0.6746\n","2024-07-18 06:12:05.068736: val_loss -0.6934\n","2024-07-18 06:12:05.068866: Pseudo dice [0.9583]\n","2024-07-18 06:12:05.069002: Epoch time: 101.95 s\n","2024-07-18 06:12:05.069093: Yayy! New best EMA pseudo Dice: 0.9467\n","2024-07-18 06:12:08.562879: \n","2024-07-18 06:12:08.563300: Epoch 234\n","2024-07-18 06:12:08.563447: Current learning rate: 0.00787\n","2024-07-18 06:13:50.706074: train_loss -0.6689\n","2024-07-18 06:13:50.706518: val_loss -0.7045\n","2024-07-18 06:13:50.706636: Pseudo dice [0.9462]\n","2024-07-18 06:13:50.706729: Epoch time: 102.15 s\n","2024-07-18 06:13:52.221847: \n","2024-07-18 06:13:52.222340: Epoch 235\n","2024-07-18 06:13:52.222491: Current learning rate: 0.00786\n","2024-07-18 06:15:34.571620: train_loss -0.6407\n","2024-07-18 06:15:34.571983: val_loss -0.6403\n","2024-07-18 06:15:34.572151: Pseudo dice [0.9402]\n","2024-07-18 06:15:34.572274: Epoch time: 102.35 s\n","2024-07-18 06:15:36.105798: \n","2024-07-18 06:15:36.106246: Epoch 236\n","2024-07-18 06:15:36.106387: Current learning rate: 0.00785\n","2024-07-18 06:17:18.200970: train_loss -0.6374\n","2024-07-18 06:17:18.201235: val_loss -0.6704\n","2024-07-18 06:17:18.201360: Pseudo dice [0.9492]\n","2024-07-18 06:17:18.201479: Epoch time: 102.1 s\n","2024-07-18 06:17:19.685940: \n","2024-07-18 06:17:19.686409: Epoch 237\n","2024-07-18 06:17:19.686564: Current learning rate: 0.00784\n","2024-07-18 06:19:01.832127: train_loss -0.6545\n","2024-07-18 06:19:01.832578: val_loss -0.6494\n","2024-07-18 06:19:01.832840: Pseudo dice [0.9324]\n","2024-07-18 06:19:01.833046: Epoch time: 102.15 s\n","2024-07-18 06:19:03.879666: \n","2024-07-18 06:19:03.880045: Epoch 238\n","2024-07-18 06:19:03.880188: Current learning rate: 0.00783\n","2024-07-18 06:20:46.052762: train_loss -0.6326\n","2024-07-18 06:20:46.053097: val_loss -0.7242\n","2024-07-18 06:20:46.053208: Pseudo dice [0.9174]\n","2024-07-18 06:20:46.053306: Epoch time: 102.18 s\n","2024-07-18 06:20:47.559071: \n","2024-07-18 06:20:47.559524: Epoch 239\n","2024-07-18 06:20:47.559676: Current learning rate: 0.00782\n","2024-07-18 06:22:29.663197: train_loss -0.629\n","2024-07-18 06:22:29.663440: val_loss -0.7022\n","2024-07-18 06:22:29.663553: Pseudo dice [0.9464]\n","2024-07-18 06:22:29.663647: Epoch time: 102.11 s\n","2024-07-18 06:22:31.197169: \n","2024-07-18 06:22:31.197586: Epoch 240\n","2024-07-18 06:22:31.197802: Current learning rate: 0.00781\n","2024-07-18 06:24:13.435755: train_loss -0.6399\n","2024-07-18 06:24:13.436059: val_loss -0.6244\n","2024-07-18 06:24:13.436243: Pseudo dice [0.9223]\n","2024-07-18 06:24:13.436395: Epoch time: 102.24 s\n","2024-07-18 06:24:15.162384: \n","2024-07-18 06:24:15.162709: Epoch 241\n","2024-07-18 06:24:15.162890: Current learning rate: 0.0078\n","2024-07-18 06:25:57.261142: train_loss -0.6576\n","2024-07-18 06:25:57.261382: val_loss -0.7338\n","2024-07-18 06:25:57.261482: Pseudo dice [0.9597]\n","2024-07-18 06:25:57.261637: Epoch time: 102.1 s\n","2024-07-18 06:25:58.795273: \n","2024-07-18 06:25:58.795619: Epoch 242\n","2024-07-18 06:25:58.795789: Current learning rate: 0.00779\n","2024-07-18 06:27:40.867588: train_loss -0.6181\n","2024-07-18 06:27:40.867844: val_loss -0.6265\n","2024-07-18 06:27:40.867975: Pseudo dice [0.912]\n","2024-07-18 06:27:40.868186: Epoch time: 102.08 s\n","2024-07-18 06:27:42.398141: \n","2024-07-18 06:27:42.398491: Epoch 243\n","2024-07-18 06:27:42.398637: Current learning rate: 0.00778\n","2024-07-18 06:29:24.511882: train_loss -0.634\n","2024-07-18 06:29:24.512168: val_loss -0.7242\n","2024-07-18 06:29:24.512278: Pseudo dice [0.9558]\n","2024-07-18 06:29:24.512375: Epoch time: 102.12 s\n","2024-07-18 06:29:26.073719: \n","2024-07-18 06:29:26.074128: Epoch 244\n","2024-07-18 06:29:26.074300: Current learning rate: 0.00777\n","2024-07-18 06:31:08.084551: train_loss -0.655\n","2024-07-18 06:31:08.084787: val_loss -0.6501\n","2024-07-18 06:31:08.084892: Pseudo dice [0.9266]\n","2024-07-18 06:31:08.085009: Epoch time: 102.01 s\n","2024-07-18 06:31:10.194048: \n","2024-07-18 06:31:10.194436: Epoch 245\n","2024-07-18 06:31:10.194582: Current learning rate: 0.00777\n","2024-07-18 06:32:52.075244: train_loss -0.6466\n","2024-07-18 06:32:52.075536: val_loss -0.6746\n","2024-07-18 06:32:52.075673: Pseudo dice [0.9377]\n","2024-07-18 06:32:52.075806: Epoch time: 101.89 s\n","2024-07-18 06:32:53.622150: \n","2024-07-18 06:32:53.622521: Epoch 246\n","2024-07-18 06:32:53.622692: Current learning rate: 0.00776\n","2024-07-18 06:34:35.634363: train_loss -0.6647\n","2024-07-18 06:34:35.634633: val_loss -0.674\n","2024-07-18 06:34:35.634738: Pseudo dice [0.9622]\n","2024-07-18 06:34:35.634837: Epoch time: 102.02 s\n","2024-07-18 06:34:37.237988: \n","2024-07-18 06:34:37.238375: Epoch 247\n","2024-07-18 06:34:37.238516: Current learning rate: 0.00775\n","2024-07-18 06:36:19.094486: train_loss -0.6401\n","2024-07-18 06:36:19.094724: val_loss -0.6565\n","2024-07-18 06:36:19.094822: Pseudo dice [0.9646]\n","2024-07-18 06:36:19.094916: Epoch time: 101.86 s\n","2024-07-18 06:36:20.670808: \n","2024-07-18 06:36:20.671179: Epoch 248\n","2024-07-18 06:36:20.671329: Current learning rate: 0.00774\n","2024-07-18 06:38:02.537618: train_loss -0.6241\n","2024-07-18 06:38:02.537937: val_loss -0.6093\n","2024-07-18 06:38:02.538051: Pseudo dice [0.9434]\n","2024-07-18 06:38:02.538164: Epoch time: 101.87 s\n","2024-07-18 06:38:04.038104: \n","2024-07-18 06:38:04.038453: Epoch 249\n","2024-07-18 06:38:04.038610: Current learning rate: 0.00773\n","2024-07-18 06:39:45.775014: train_loss -0.6829\n","2024-07-18 06:39:45.775266: val_loss -0.6919\n","2024-07-18 06:39:45.775405: Pseudo dice [0.9643]\n","2024-07-18 06:39:45.775522: Epoch time: 101.74 s\n","2024-07-18 06:39:50.307589: \n","2024-07-18 06:39:50.308020: Epoch 250\n","2024-07-18 06:39:50.308185: Current learning rate: 0.00772\n","2024-07-18 06:41:32.252008: train_loss -0.664\n","2024-07-18 06:41:32.252382: val_loss -0.6541\n","2024-07-18 06:41:32.252529: Pseudo dice [0.9584]\n","2024-07-18 06:41:32.252624: Epoch time: 101.95 s\n","2024-07-18 06:41:32.252702: Yayy! New best EMA pseudo Dice: 0.9472\n","2024-07-18 06:41:35.719484: \n","2024-07-18 06:41:35.719934: Epoch 251\n","2024-07-18 06:41:35.720085: Current learning rate: 0.00771\n","2024-07-18 06:43:17.541728: train_loss -0.6405\n","2024-07-18 06:43:17.542010: val_loss -0.7001\n","2024-07-18 06:43:17.542120: Pseudo dice [0.9544]\n","2024-07-18 06:43:17.542217: Epoch time: 101.83 s\n","2024-07-18 06:43:17.542303: Yayy! New best EMA pseudo Dice: 0.9479\n","2024-07-18 06:43:21.626719: \n","2024-07-18 06:43:21.627129: Epoch 252\n","2024-07-18 06:43:21.627306: Current learning rate: 0.0077\n","2024-07-18 06:45:03.622743: train_loss -0.6698\n","2024-07-18 06:45:03.623042: val_loss -0.6648\n","2024-07-18 06:45:03.623185: Pseudo dice [0.9582]\n","2024-07-18 06:45:03.623303: Epoch time: 102.0 s\n","2024-07-18 06:45:03.623401: Yayy! New best EMA pseudo Dice: 0.949\n","2024-07-18 06:45:07.177716: \n","2024-07-18 06:45:07.178159: Epoch 253\n","2024-07-18 06:45:07.178309: Current learning rate: 0.00769\n","2024-07-18 06:46:48.996692: train_loss -0.6696\n","2024-07-18 06:46:48.997013: val_loss -0.6302\n","2024-07-18 06:46:48.997150: Pseudo dice [0.9455]\n","2024-07-18 06:46:48.997260: Epoch time: 101.82 s\n","2024-07-18 06:46:50.561260: \n","2024-07-18 06:46:50.561684: Epoch 254\n","2024-07-18 06:46:50.561836: Current learning rate: 0.00768\n","2024-07-18 06:48:32.298531: train_loss -0.63\n","2024-07-18 06:48:32.298808: val_loss -0.6972\n","2024-07-18 06:48:32.298912: Pseudo dice [0.9509]\n","2024-07-18 06:48:32.299042: Epoch time: 101.74 s\n","2024-07-18 06:48:33.807451: \n","2024-07-18 06:48:33.807792: Epoch 255\n","2024-07-18 06:48:33.807947: Current learning rate: 0.00767\n","2024-07-18 06:50:15.529578: train_loss -0.6515\n","2024-07-18 06:50:15.529821: val_loss -0.675\n","2024-07-18 06:50:15.529982: Pseudo dice [0.9502]\n","2024-07-18 06:50:15.530162: Epoch time: 101.73 s\n","2024-07-18 06:50:15.530250: Yayy! New best EMA pseudo Dice: 0.949\n","2024-07-18 06:50:20.592788: \n","2024-07-18 06:50:20.593177: Epoch 256\n","2024-07-18 06:50:20.593321: Current learning rate: 0.00766\n","2024-07-18 06:52:02.273247: train_loss -0.6586\n","2024-07-18 06:52:02.273512: val_loss -0.6928\n","2024-07-18 06:52:02.273660: Pseudo dice [0.9453]\n","2024-07-18 06:52:02.273785: Epoch time: 101.68 s\n","2024-07-18 06:52:03.898587: \n","2024-07-18 06:52:03.899122: Epoch 257\n","2024-07-18 06:52:03.899279: Current learning rate: 0.00765\n","2024-07-18 06:53:45.764331: train_loss -0.6641\n","2024-07-18 06:53:45.764595: val_loss -0.652\n","2024-07-18 06:53:45.764693: Pseudo dice [0.9578]\n","2024-07-18 06:53:45.764786: Epoch time: 101.87 s\n","2024-07-18 06:53:45.764872: Yayy! New best EMA pseudo Dice: 0.9495\n","2024-07-18 06:53:50.315470: \n","2024-07-18 06:53:50.315844: Epoch 258\n","2024-07-18 06:53:50.316005: Current learning rate: 0.00764\n","2024-07-18 06:55:32.574711: train_loss -0.6585\n","2024-07-18 06:55:32.575054: val_loss -0.6333\n","2024-07-18 06:55:32.575159: Pseudo dice [0.9537]\n","2024-07-18 06:55:32.575252: Epoch time: 102.26 s\n","2024-07-18 06:55:32.575336: Yayy! New best EMA pseudo Dice: 0.95\n","2024-07-18 06:55:35.995827: \n","2024-07-18 06:55:35.996206: Epoch 259\n","2024-07-18 06:55:35.996356: Current learning rate: 0.00764\n","2024-07-18 06:57:17.874693: train_loss -0.6563\n","2024-07-18 06:57:17.874951: val_loss -0.5915\n","2024-07-18 06:57:17.875107: Pseudo dice [0.8742]\n","2024-07-18 06:57:17.875214: Epoch time: 101.88 s\n","2024-07-18 06:57:19.402322: \n","2024-07-18 06:57:19.402717: Epoch 260\n","2024-07-18 06:57:19.402863: Current learning rate: 0.00763\n","2024-07-18 06:59:01.312477: train_loss -0.6166\n","2024-07-18 06:59:01.312729: val_loss -0.6739\n","2024-07-18 06:59:01.312830: Pseudo dice [0.9442]\n","2024-07-18 06:59:01.312940: Epoch time: 101.91 s\n","2024-07-18 06:59:02.869768: \n","2024-07-18 06:59:02.870302: Epoch 261\n","2024-07-18 06:59:02.870461: Current learning rate: 0.00762\n","2024-07-18 07:00:44.665455: train_loss -0.6694\n","2024-07-18 07:00:44.665895: val_loss -0.6484\n","2024-07-18 07:00:44.666151: Pseudo dice [0.9281]\n","2024-07-18 07:00:44.666252: Epoch time: 101.8 s\n","2024-07-18 07:00:46.180126: \n","2024-07-18 07:00:46.180520: Epoch 262\n","2024-07-18 07:00:46.180681: Current learning rate: 0.00761\n","2024-07-18 07:02:27.995340: train_loss -0.6366\n","2024-07-18 07:02:27.995619: val_loss -0.6329\n","2024-07-18 07:02:27.995771: Pseudo dice [0.9403]\n","2024-07-18 07:02:27.995892: Epoch time: 101.82 s\n","2024-07-18 07:02:29.559813: \n","2024-07-18 07:02:29.560215: Epoch 263\n","2024-07-18 07:02:29.560377: Current learning rate: 0.0076\n","2024-07-18 07:04:11.524919: train_loss -0.6657\n","2024-07-18 07:04:11.525397: val_loss -0.6557\n","2024-07-18 07:04:11.525605: Pseudo dice [0.9567]\n","2024-07-18 07:04:11.525713: Epoch time: 101.97 s\n","2024-07-18 07:04:13.058010: \n","2024-07-18 07:04:13.058370: Epoch 264\n","2024-07-18 07:04:13.058632: Current learning rate: 0.00759\n","2024-07-18 07:05:54.826770: train_loss -0.6799\n","2024-07-18 07:05:54.827046: val_loss -0.6786\n","2024-07-18 07:05:54.827154: Pseudo dice [0.9607]\n","2024-07-18 07:05:54.827265: Epoch time: 101.77 s\n","2024-07-18 07:05:56.975603: \n","2024-07-18 07:05:56.975951: Epoch 265\n","2024-07-18 07:05:56.976114: Current learning rate: 0.00758\n","2024-07-18 07:07:38.654295: train_loss -0.6959\n","2024-07-18 07:07:38.654547: val_loss -0.6617\n","2024-07-18 07:07:38.654786: Pseudo dice [0.9547]\n","2024-07-18 07:07:38.654902: Epoch time: 101.68 s\n","2024-07-18 07:07:40.353798: \n","2024-07-18 07:07:40.354251: Epoch 266\n","2024-07-18 07:07:40.354420: Current learning rate: 0.00757\n","2024-07-18 07:09:22.059628: train_loss -0.6846\n","2024-07-18 07:09:22.059868: val_loss -0.6626\n","2024-07-18 07:09:22.060023: Pseudo dice [0.9583]\n","2024-07-18 07:09:22.060189: Epoch time: 101.71 s\n","2024-07-18 07:09:23.599404: \n","2024-07-18 07:09:23.599741: Epoch 267\n","2024-07-18 07:09:23.599906: Current learning rate: 0.00756\n","2024-07-18 07:11:05.273192: train_loss -0.6802\n","2024-07-18 07:11:05.273441: val_loss -0.6476\n","2024-07-18 07:11:05.273544: Pseudo dice [0.9414]\n","2024-07-18 07:11:05.273649: Epoch time: 101.68 s\n","2024-07-18 07:11:06.872696: \n","2024-07-18 07:11:06.873038: Epoch 268\n","2024-07-18 07:11:06.873179: Current learning rate: 0.00755\n","2024-07-18 07:12:48.669468: train_loss -0.6386\n","2024-07-18 07:12:48.669714: val_loss -0.6721\n","2024-07-18 07:12:48.669819: Pseudo dice [0.9443]\n","2024-07-18 07:12:48.669949: Epoch time: 101.8 s\n","2024-07-18 07:12:50.264998: \n","2024-07-18 07:12:50.265521: Epoch 269\n","2024-07-18 07:12:50.265717: Current learning rate: 0.00754\n","2024-07-18 07:14:32.116449: train_loss -0.6632\n","2024-07-18 07:14:32.116697: val_loss -0.6964\n","2024-07-18 07:14:32.116793: Pseudo dice [0.9415]\n","2024-07-18 07:14:32.116883: Epoch time: 101.86 s\n","2024-07-18 07:14:33.601047: \n","2024-07-18 07:14:33.601487: Epoch 270\n","2024-07-18 07:14:33.601629: Current learning rate: 0.00753\n","2024-07-18 07:16:15.452816: train_loss -0.6396\n","2024-07-18 07:16:15.453082: val_loss -0.7069\n","2024-07-18 07:16:15.453232: Pseudo dice [0.9611]\n","2024-07-18 07:16:15.453347: Epoch time: 101.86 s\n","2024-07-18 07:16:17.045831: \n","2024-07-18 07:16:17.046142: Epoch 271\n","2024-07-18 07:16:17.046282: Current learning rate: 0.00752\n","2024-07-18 07:17:58.811411: train_loss -0.6721\n","2024-07-18 07:17:58.811741: val_loss -0.6478\n","2024-07-18 07:17:58.811890: Pseudo dice [0.9508]\n","2024-07-18 07:17:58.812050: Epoch time: 101.77 s\n","2024-07-18 07:18:00.340349: \n","2024-07-18 07:18:00.340738: Epoch 272\n","2024-07-18 07:18:00.340882: Current learning rate: 0.00751\n","2024-07-18 07:19:42.654791: train_loss -0.6726\n","2024-07-18 07:19:42.655098: val_loss -0.7336\n","2024-07-18 07:19:42.655204: Pseudo dice [0.9592]\n","2024-07-18 07:19:42.655298: Epoch time: 102.32 s\n","2024-07-18 07:19:44.170419: \n","2024-07-18 07:19:44.170803: Epoch 273\n","2024-07-18 07:19:44.170961: Current learning rate: 0.00751\n","2024-07-18 07:21:25.903707: train_loss -0.6829\n","2024-07-18 07:21:25.904194: val_loss -0.6928\n","2024-07-18 07:21:25.904368: Pseudo dice [0.9578]\n","2024-07-18 07:21:25.904479: Epoch time: 101.74 s\n","2024-07-18 07:21:27.450557: \n","2024-07-18 07:21:27.451017: Epoch 274\n","2024-07-18 07:21:27.451165: Current learning rate: 0.0075\n","2024-07-18 07:23:09.260923: train_loss -0.6742\n","2024-07-18 07:23:09.261184: val_loss -0.6373\n","2024-07-18 07:23:09.261282: Pseudo dice [0.9122]\n","2024-07-18 07:23:09.261386: Epoch time: 101.81 s\n","2024-07-18 07:23:10.768663: \n","2024-07-18 07:23:10.769002: Epoch 275\n","2024-07-18 07:23:10.769158: Current learning rate: 0.00749\n","2024-07-18 07:24:52.624593: train_loss -0.6582\n","2024-07-18 07:24:52.624829: val_loss -0.5663\n","2024-07-18 07:24:52.624954: Pseudo dice [0.9301]\n","2024-07-18 07:24:52.625079: Epoch time: 101.86 s\n","2024-07-18 07:24:54.147773: \n","2024-07-18 07:24:54.148150: Epoch 276\n","2024-07-18 07:24:54.148299: Current learning rate: 0.00748\n","2024-07-18 07:26:35.989784: train_loss -0.6358\n","2024-07-18 07:26:35.990149: val_loss -0.5564\n","2024-07-18 07:26:35.990284: Pseudo dice [0.8615]\n","2024-07-18 07:26:35.990412: Epoch time: 101.85 s\n","2024-07-18 07:26:37.568433: \n","2024-07-18 07:26:37.568828: Epoch 277\n","2024-07-18 07:26:37.569023: Current learning rate: 0.00747\n","2024-07-18 07:28:19.359045: train_loss -0.6614\n","2024-07-18 07:28:19.359299: val_loss -0.6874\n","2024-07-18 07:28:19.359397: Pseudo dice [0.9216]\n","2024-07-18 07:28:19.359488: Epoch time: 101.79 s\n","2024-07-18 07:28:20.880900: \n","2024-07-18 07:28:20.881248: Epoch 278\n","2024-07-18 07:28:20.881475: Current learning rate: 0.00746\n","2024-07-18 07:30:02.752491: train_loss -0.6517\n","2024-07-18 07:30:02.752743: val_loss -0.6862\n","2024-07-18 07:30:02.752841: Pseudo dice [0.9328]\n","2024-07-18 07:30:02.752961: Epoch time: 101.88 s\n","2024-07-18 07:30:04.261552: \n","2024-07-18 07:30:04.261955: Epoch 279\n","2024-07-18 07:30:04.262124: Current learning rate: 0.00745\n","2024-07-18 07:31:46.575253: train_loss -0.6465\n","2024-07-18 07:31:46.575496: val_loss -0.5232\n","2024-07-18 07:31:46.575596: Pseudo dice [0.8249]\n","2024-07-18 07:31:46.575695: Epoch time: 102.32 s\n","2024-07-18 07:31:48.158245: \n","2024-07-18 07:31:48.158709: Epoch 280\n","2024-07-18 07:31:48.158849: Current learning rate: 0.00744\n","2024-07-18 07:33:29.917822: train_loss -0.6694\n","2024-07-18 07:33:29.918144: val_loss -0.6851\n","2024-07-18 07:33:29.918252: Pseudo dice [0.9407]\n","2024-07-18 07:33:29.918347: Epoch time: 101.76 s\n","2024-07-18 07:33:31.432270: \n","2024-07-18 07:33:31.432627: Epoch 281\n","2024-07-18 07:33:31.432775: Current learning rate: 0.00743\n","2024-07-18 07:35:13.161754: train_loss -0.671\n","2024-07-18 07:35:13.162011: val_loss -0.7383\n","2024-07-18 07:35:13.162115: Pseudo dice [0.9593]\n","2024-07-18 07:35:13.162211: Epoch time: 101.73 s\n","2024-07-18 07:35:14.700439: \n","2024-07-18 07:35:14.700817: Epoch 282\n","2024-07-18 07:35:14.700975: Current learning rate: 0.00742\n","2024-07-18 07:36:56.437733: train_loss -0.6612\n","2024-07-18 07:36:56.437992: val_loss -0.7254\n","2024-07-18 07:36:56.438131: Pseudo dice [0.9565]\n","2024-07-18 07:36:56.438236: Epoch time: 101.74 s\n","2024-07-18 07:36:58.125760: \n","2024-07-18 07:36:58.126229: Epoch 283\n","2024-07-18 07:36:58.126385: Current learning rate: 0.00741\n","2024-07-18 07:38:39.886973: train_loss -0.6686\n","2024-07-18 07:38:39.887558: val_loss -0.7245\n","2024-07-18 07:38:39.887686: Pseudo dice [0.9614]\n","2024-07-18 07:38:39.887782: Epoch time: 101.77 s\n","2024-07-18 07:38:41.429302: \n","2024-07-18 07:38:41.429703: Epoch 284\n","2024-07-18 07:38:41.429844: Current learning rate: 0.0074\n","2024-07-18 07:40:23.219360: train_loss -0.6674\n","2024-07-18 07:40:23.219619: val_loss -0.657\n","2024-07-18 07:40:23.219849: Pseudo dice [0.9561]\n","2024-07-18 07:40:23.219997: Epoch time: 101.79 s\n","2024-07-18 07:40:24.782908: \n","2024-07-18 07:40:24.783285: Epoch 285\n","2024-07-18 07:40:24.783430: Current learning rate: 0.00739\n","2024-07-18 07:42:06.464543: train_loss -0.6609\n","2024-07-18 07:42:06.464810: val_loss -0.6854\n","2024-07-18 07:42:06.464912: Pseudo dice [0.9421]\n","2024-07-18 07:42:06.465032: Epoch time: 101.69 s\n","2024-07-18 07:42:08.007244: \n","2024-07-18 07:42:08.007606: Epoch 286\n","2024-07-18 07:42:08.007748: Current learning rate: 0.00738\n","2024-07-18 07:43:50.431963: train_loss -0.6655\n","2024-07-18 07:43:50.432256: val_loss -0.6856\n","2024-07-18 07:43:50.432394: Pseudo dice [0.9551]\n","2024-07-18 07:43:50.432529: Epoch time: 102.43 s\n","2024-07-18 07:43:51.972875: \n","2024-07-18 07:43:51.973270: Epoch 287\n","2024-07-18 07:43:51.973420: Current learning rate: 0.00738\n","2024-07-18 07:45:33.802159: train_loss -0.6793\n","2024-07-18 07:45:33.802624: val_loss -0.7041\n","2024-07-18 07:45:33.802748: Pseudo dice [0.9587]\n","2024-07-18 07:45:33.802946: Epoch time: 101.83 s\n","2024-07-18 07:45:35.396530: \n","2024-07-18 07:45:35.396858: Epoch 288\n","2024-07-18 07:45:35.397008: Current learning rate: 0.00737\n","2024-07-18 07:47:17.249007: train_loss -0.6684\n","2024-07-18 07:47:17.249255: val_loss -0.604\n","2024-07-18 07:47:17.249419: Pseudo dice [0.9097]\n","2024-07-18 07:47:17.249561: Epoch time: 101.86 s\n","2024-07-18 07:47:18.902227: \n","2024-07-18 07:47:18.902621: Epoch 289\n","2024-07-18 07:47:18.902775: Current learning rate: 0.00736\n","2024-07-18 07:49:00.743714: train_loss -0.6523\n","2024-07-18 07:49:00.744042: val_loss -0.6852\n","2024-07-18 07:49:00.744197: Pseudo dice [0.9547]\n","2024-07-18 07:49:00.744323: Epoch time: 101.85 s\n","2024-07-18 07:49:02.312538: \n","2024-07-18 07:49:02.313041: Epoch 290\n","2024-07-18 07:49:02.313198: Current learning rate: 0.00735\n","2024-07-18 07:50:44.289099: train_loss -0.6576\n","2024-07-18 07:50:44.289439: val_loss -0.6465\n","2024-07-18 07:50:44.289546: Pseudo dice [0.9416]\n","2024-07-18 07:50:44.289658: Epoch time: 101.98 s\n","2024-07-18 07:50:45.854690: \n","2024-07-18 07:50:45.855088: Epoch 291\n","2024-07-18 07:50:45.855228: Current learning rate: 0.00734\n","2024-07-18 07:52:27.573143: train_loss -0.6476\n","2024-07-18 07:52:27.573414: val_loss -0.6908\n","2024-07-18 07:52:27.573526: Pseudo dice [0.9484]\n","2024-07-18 07:52:27.573622: Epoch time: 101.72 s\n","2024-07-18 07:52:29.156263: \n","2024-07-18 07:52:29.156749: Epoch 292\n","2024-07-18 07:52:29.156909: Current learning rate: 0.00733\n","2024-07-18 07:54:10.792865: train_loss -0.6746\n","2024-07-18 07:54:10.793167: val_loss -0.51\n","2024-07-18 07:54:10.793319: Pseudo dice [0.8278]\n","2024-07-18 07:54:10.793465: Epoch time: 101.64 s\n","2024-07-18 07:54:12.379656: \n","2024-07-18 07:54:12.380023: Epoch 293\n","2024-07-18 07:54:12.380172: Current learning rate: 0.00732\n","2024-07-18 07:55:54.899610: train_loss -0.6291\n","2024-07-18 07:55:54.899884: val_loss -0.6868\n","2024-07-18 07:55:54.899998: Pseudo dice [0.9459]\n","2024-07-18 07:55:54.900090: Epoch time: 102.52 s\n","2024-07-18 07:55:56.498535: \n","2024-07-18 07:55:56.498930: Epoch 294\n","2024-07-18 07:55:56.499072: Current learning rate: 0.00731\n","2024-07-18 07:57:38.321194: train_loss -0.6604\n","2024-07-18 07:57:38.321427: val_loss -0.6959\n","2024-07-18 07:57:38.321527: Pseudo dice [0.9415]\n","2024-07-18 07:57:38.321631: Epoch time: 101.83 s\n","2024-07-18 07:57:39.893681: \n","2024-07-18 07:57:39.894040: Epoch 295\n","2024-07-18 07:57:39.894203: Current learning rate: 0.0073\n","2024-07-18 07:59:21.914172: train_loss -0.6766\n","2024-07-18 07:59:21.914447: val_loss -0.6748\n","2024-07-18 07:59:21.914586: Pseudo dice [0.9458]\n","2024-07-18 07:59:21.914744: Epoch time: 102.02 s\n","2024-07-18 07:59:23.454786: \n","2024-07-18 07:59:23.455167: Epoch 296\n","2024-07-18 07:59:23.455324: Current learning rate: 0.00729\n","2024-07-18 08:01:05.220258: train_loss -0.6478\n","2024-07-18 08:01:05.220547: val_loss -0.644\n","2024-07-18 08:01:05.220668: Pseudo dice [0.9443]\n","2024-07-18 08:01:05.220768: Epoch time: 101.77 s\n","2024-07-18 08:01:06.790172: \n","2024-07-18 08:01:06.790553: Epoch 297\n","2024-07-18 08:01:06.790689: Current learning rate: 0.00728\n","2024-07-18 08:02:48.546054: train_loss -0.6795\n","2024-07-18 08:02:48.546706: val_loss -0.7471\n","2024-07-18 08:02:48.546878: Pseudo dice [0.956]\n","2024-07-18 08:02:48.547013: Epoch time: 101.76 s\n","2024-07-18 08:02:50.275993: \n","2024-07-18 08:02:50.276409: Epoch 298\n","2024-07-18 08:02:50.276573: Current learning rate: 0.00727\n","2024-07-18 08:04:32.192828: train_loss -0.6868\n","2024-07-18 08:04:32.193198: val_loss -0.6418\n","2024-07-18 08:04:32.193374: Pseudo dice [0.9387]\n","2024-07-18 08:04:32.193482: Epoch time: 101.92 s\n","2024-07-18 08:04:33.718036: \n","2024-07-18 08:04:33.718395: Epoch 299\n","2024-07-18 08:04:33.718531: Current learning rate: 0.00726\n","2024-07-18 08:06:15.607892: train_loss -0.6455\n","2024-07-18 08:06:15.608170: val_loss -0.6823\n","2024-07-18 08:06:15.608279: Pseudo dice [0.929]\n","2024-07-18 08:06:15.608373: Epoch time: 101.89 s\n","2024-07-18 08:06:19.035295: \n","2024-07-18 08:06:19.035728: Epoch 300\n","2024-07-18 08:06:19.035910: Current learning rate: 0.00725\n","2024-07-18 08:08:01.482721: train_loss -0.6397\n","2024-07-18 08:08:01.483022: val_loss -0.6514\n","2024-07-18 08:08:01.483155: Pseudo dice [0.9475]\n","2024-07-18 08:08:01.483288: Epoch time: 102.45 s\n","2024-07-18 08:08:03.088383: \n","2024-07-18 08:08:03.088792: Epoch 301\n","2024-07-18 08:08:03.088968: Current learning rate: 0.00724\n","2024-07-18 08:09:44.943031: train_loss -0.6619\n","2024-07-18 08:09:44.943376: val_loss -0.6553\n","2024-07-18 08:09:44.943497: Pseudo dice [0.9227]\n","2024-07-18 08:09:44.943602: Epoch time: 101.86 s\n","2024-07-18 08:09:46.504200: \n","2024-07-18 08:09:46.504640: Epoch 302\n","2024-07-18 08:09:46.504781: Current learning rate: 0.00724\n","2024-07-18 08:11:28.419987: train_loss -0.6476\n","2024-07-18 08:11:28.420405: val_loss -0.6612\n","2024-07-18 08:11:28.420567: Pseudo dice [0.9498]\n","2024-07-18 08:11:28.420667: Epoch time: 101.92 s\n","2024-07-18 08:11:29.965801: \n","2024-07-18 08:11:29.966177: Epoch 303\n","2024-07-18 08:11:29.966318: Current learning rate: 0.00723\n","2024-07-18 08:13:11.708131: train_loss -0.6483\n","2024-07-18 08:13:11.708694: val_loss -0.6731\n","2024-07-18 08:13:11.708838: Pseudo dice [0.9393]\n","2024-07-18 08:13:11.708980: Epoch time: 101.75 s\n","2024-07-18 08:13:13.315616: \n","2024-07-18 08:13:13.316001: Epoch 304\n","2024-07-18 08:13:13.316275: Current learning rate: 0.00722\n","2024-07-18 08:14:55.138890: train_loss -0.6457\n","2024-07-18 08:14:55.139162: val_loss -0.6646\n","2024-07-18 08:14:55.139301: Pseudo dice [0.9392]\n","2024-07-18 08:14:55.139409: Epoch time: 101.83 s\n","2024-07-18 08:14:56.685223: \n","2024-07-18 08:14:56.685670: Epoch 305\n","2024-07-18 08:14:56.685881: Current learning rate: 0.00721\n","2024-07-18 08:16:38.489693: train_loss -0.6711\n","2024-07-18 08:16:38.489990: val_loss -0.6264\n","2024-07-18 08:16:38.490126: Pseudo dice [0.9316]\n","2024-07-18 08:16:38.490225: Epoch time: 101.81 s\n","2024-07-18 08:16:40.171028: \n","2024-07-18 08:16:40.171391: Epoch 306\n","2024-07-18 08:16:40.171543: Current learning rate: 0.0072\n","2024-07-18 08:18:21.886391: train_loss -0.6844\n","2024-07-18 08:18:21.886672: val_loss -0.6684\n","2024-07-18 08:18:21.886822: Pseudo dice [0.9358]\n","2024-07-18 08:18:21.886965: Epoch time: 101.72 s\n","2024-07-18 08:18:23.527620: \n","2024-07-18 08:18:23.528013: Epoch 307\n","2024-07-18 08:18:23.528187: Current learning rate: 0.00719\n","2024-07-18 08:20:05.862644: train_loss -0.6453\n","2024-07-18 08:20:05.862893: val_loss -0.6244\n","2024-07-18 08:20:05.863014: Pseudo dice [0.9251]\n","2024-07-18 08:20:05.863113: Epoch time: 102.34 s\n","2024-07-18 08:20:07.399530: \n","2024-07-18 08:20:07.399950: Epoch 308\n","2024-07-18 08:20:07.400107: Current learning rate: 0.00718\n","2024-07-18 08:21:49.219237: train_loss -0.6759\n","2024-07-18 08:21:49.219472: val_loss -0.6407\n","2024-07-18 08:21:49.219602: Pseudo dice [0.9337]\n","2024-07-18 08:21:49.219800: Epoch time: 101.82 s\n","2024-07-18 08:21:50.772830: \n","2024-07-18 08:21:50.773276: Epoch 309\n","2024-07-18 08:21:50.773421: Current learning rate: 0.00717\n","2024-07-18 08:23:32.609844: train_loss -0.7009\n","2024-07-18 08:23:32.610187: val_loss -0.7193\n","2024-07-18 08:23:32.610300: Pseudo dice [0.94]\n","2024-07-18 08:23:32.610408: Epoch time: 101.84 s\n","2024-07-18 08:23:34.175485: \n","2024-07-18 08:23:34.175871: Epoch 310\n","2024-07-18 08:23:34.176054: Current learning rate: 0.00716\n","2024-07-18 08:25:15.904325: train_loss -0.6667\n","2024-07-18 08:25:15.904644: val_loss -0.6916\n","2024-07-18 08:25:15.904761: Pseudo dice [0.9654]\n","2024-07-18 08:25:15.904867: Epoch time: 101.73 s\n","2024-07-18 08:25:17.489632: \n","2024-07-18 08:25:17.490093: Epoch 311\n","2024-07-18 08:25:17.490238: Current learning rate: 0.00715\n","2024-07-18 08:26:59.403445: train_loss -0.6948\n","2024-07-18 08:26:59.403736: val_loss -0.7179\n","2024-07-18 08:26:59.403894: Pseudo dice [0.9503]\n","2024-07-18 08:26:59.404067: Epoch time: 101.92 s\n","2024-07-18 08:27:00.967073: \n","2024-07-18 08:27:00.967535: Epoch 312\n","2024-07-18 08:27:00.967702: Current learning rate: 0.00714\n","2024-07-18 08:28:42.836351: train_loss -0.654\n","2024-07-18 08:28:42.836638: val_loss -0.7078\n","2024-07-18 08:28:42.836793: Pseudo dice [0.9461]\n","2024-07-18 08:28:42.836902: Epoch time: 101.87 s\n","2024-07-18 08:28:44.456477: \n","2024-07-18 08:28:44.456832: Epoch 313\n","2024-07-18 08:28:44.456982: Current learning rate: 0.00713\n","2024-07-18 08:30:26.280038: train_loss -0.6408\n","2024-07-18 08:30:26.280274: val_loss -0.7113\n","2024-07-18 08:30:26.280383: Pseudo dice [0.9613]\n","2024-07-18 08:30:26.280486: Epoch time: 101.83 s\n","2024-07-18 08:30:27.929899: \n","2024-07-18 08:30:27.930298: Epoch 314\n","2024-07-18 08:30:27.930484: Current learning rate: 0.00712\n","2024-07-18 08:32:10.318856: train_loss -0.6656\n","2024-07-18 08:32:10.319197: val_loss -0.6907\n","2024-07-18 08:32:10.319349: Pseudo dice [0.9425]\n","2024-07-18 08:32:10.319499: Epoch time: 102.39 s\n","2024-07-18 08:32:11.876088: \n","2024-07-18 08:32:11.876573: Epoch 315\n","2024-07-18 08:32:11.876725: Current learning rate: 0.00711\n","2024-07-18 08:33:53.775476: train_loss -0.6483\n","2024-07-18 08:33:53.775723: val_loss -0.6778\n","2024-07-18 08:33:53.775840: Pseudo dice [0.9496]\n","2024-07-18 08:33:53.775955: Epoch time: 101.9 s\n","2024-07-18 08:33:55.334266: \n","2024-07-18 08:33:55.334650: Epoch 316\n","2024-07-18 08:33:55.334796: Current learning rate: 0.0071\n","2024-07-18 08:35:37.184454: train_loss -0.6682\n","2024-07-18 08:35:37.184791: val_loss -0.7074\n","2024-07-18 08:35:37.184891: Pseudo dice [0.9624]\n","2024-07-18 08:35:37.185015: Epoch time: 101.85 s\n","2024-07-18 08:35:38.768909: \n","2024-07-18 08:35:38.769312: Epoch 317\n","2024-07-18 08:35:38.769457: Current learning rate: 0.0071\n","2024-07-18 08:37:20.737356: train_loss -0.6454\n","2024-07-18 08:37:20.737799: val_loss -0.7391\n","2024-07-18 08:37:20.737918: Pseudo dice [0.9585]\n","2024-07-18 08:37:20.738029: Epoch time: 101.97 s\n","2024-07-18 08:37:22.281264: \n","2024-07-18 08:37:22.281712: Epoch 318\n","2024-07-18 08:37:22.281851: Current learning rate: 0.00709\n","2024-07-18 08:39:04.148326: train_loss -0.674\n","2024-07-18 08:39:04.148628: val_loss -0.6772\n","2024-07-18 08:39:04.148780: Pseudo dice [0.9438]\n","2024-07-18 08:39:04.149037: Epoch time: 101.87 s\n","2024-07-18 08:39:05.741728: \n","2024-07-18 08:39:05.742134: Epoch 319\n","2024-07-18 08:39:05.742272: Current learning rate: 0.00708\n","2024-07-18 08:40:47.591149: train_loss -0.6609\n","2024-07-18 08:40:47.591396: val_loss -0.6565\n","2024-07-18 08:40:47.591495: Pseudo dice [0.9606]\n","2024-07-18 08:40:47.591590: Epoch time: 101.85 s\n","2024-07-18 08:40:49.174455: \n","2024-07-18 08:40:49.174859: Epoch 320\n","2024-07-18 08:40:49.175036: Current learning rate: 0.00707\n","2024-07-18 08:42:30.971904: train_loss -0.6761\n","2024-07-18 08:42:30.972247: val_loss -0.7215\n","2024-07-18 08:42:30.972377: Pseudo dice [0.9512]\n","2024-07-18 08:42:30.972522: Epoch time: 101.8 s\n","2024-07-18 08:42:32.530525: \n","2024-07-18 08:42:32.530849: Epoch 321\n","2024-07-18 08:42:32.531002: Current learning rate: 0.00706\n","2024-07-18 08:44:15.019904: train_loss -0.6655\n","2024-07-18 08:44:15.020187: val_loss -0.6073\n","2024-07-18 08:44:15.020292: Pseudo dice [0.923]\n","2024-07-18 08:44:15.020393: Epoch time: 102.49 s\n","2024-07-18 08:44:16.624294: \n","2024-07-18 08:44:16.624669: Epoch 322\n","2024-07-18 08:44:16.624857: Current learning rate: 0.00705\n","2024-07-18 08:45:58.524595: train_loss -0.698\n","2024-07-18 08:45:58.525075: val_loss -0.6724\n","2024-07-18 08:45:58.525211: Pseudo dice [0.9661]\n","2024-07-18 08:45:58.525340: Epoch time: 101.9 s\n","2024-07-18 08:46:00.189268: \n","2024-07-18 08:46:00.189697: Epoch 323\n","2024-07-18 08:46:00.189876: Current learning rate: 0.00704\n","2024-07-18 08:47:41.973425: train_loss -0.6738\n","2024-07-18 08:47:41.973665: val_loss -0.6534\n","2024-07-18 08:47:41.973765: Pseudo dice [0.921]\n","2024-07-18 08:47:41.973862: Epoch time: 101.79 s\n","2024-07-18 08:47:43.491108: \n","2024-07-18 08:47:43.491551: Epoch 324\n","2024-07-18 08:47:43.491690: Current learning rate: 0.00703\n","2024-07-18 08:49:25.381588: train_loss -0.6702\n","2024-07-18 08:49:25.381823: val_loss -0.6761\n","2024-07-18 08:49:25.381937: Pseudo dice [0.946]\n","2024-07-18 08:49:25.382111: Epoch time: 101.89 s\n","2024-07-18 08:49:26.988756: \n","2024-07-18 08:49:26.989168: Epoch 325\n","2024-07-18 08:49:26.989307: Current learning rate: 0.00702\n","2024-07-18 08:51:08.764235: train_loss -0.666\n","2024-07-18 08:51:08.764587: val_loss -0.6495\n","2024-07-18 08:51:08.764694: Pseudo dice [0.899]\n","2024-07-18 08:51:08.764796: Epoch time: 101.78 s\n","2024-07-18 08:51:10.347797: \n","2024-07-18 08:51:10.348208: Epoch 326\n","2024-07-18 08:51:10.348348: Current learning rate: 0.00701\n","2024-07-18 08:52:52.157959: train_loss -0.6475\n","2024-07-18 08:52:52.158211: val_loss -0.7459\n","2024-07-18 08:52:52.158343: Pseudo dice [0.9581]\n","2024-07-18 08:52:52.158476: Epoch time: 101.81 s\n","2024-07-18 08:52:53.703765: \n","2024-07-18 08:52:53.704172: Epoch 327\n","2024-07-18 08:52:53.704317: Current learning rate: 0.007\n","2024-07-18 08:54:35.700241: train_loss -0.6732\n","2024-07-18 08:54:35.700693: val_loss -0.6704\n","2024-07-18 08:54:35.700817: Pseudo dice [0.9425]\n","2024-07-18 08:54:35.700950: Epoch time: 102.0 s\n","2024-07-18 08:54:37.848553: \n","2024-07-18 08:54:37.849003: Epoch 328\n","2024-07-18 08:54:37.849156: Current learning rate: 0.00699\n","2024-07-18 08:56:19.929182: train_loss -0.6525\n","2024-07-18 08:56:19.929437: val_loss -0.6959\n","2024-07-18 08:56:19.929538: Pseudo dice [0.912]\n","2024-07-18 08:56:19.929633: Epoch time: 102.08 s\n","2024-07-18 08:56:21.536829: \n","2024-07-18 08:56:21.537246: Epoch 329\n","2024-07-18 08:56:21.537389: Current learning rate: 0.00698\n","2024-07-18 08:58:03.371484: train_loss -0.6588\n","2024-07-18 08:58:03.371746: val_loss -0.7026\n","2024-07-18 08:58:03.371846: Pseudo dice [0.9614]\n","2024-07-18 08:58:03.371955: Epoch time: 101.84 s\n","2024-07-18 08:58:04.948457: \n","2024-07-18 08:58:04.948853: Epoch 330\n","2024-07-18 08:58:04.949010: Current learning rate: 0.00697\n","2024-07-18 08:59:46.865561: train_loss -0.6668\n","2024-07-18 08:59:46.865910: val_loss -0.6937\n","2024-07-18 08:59:46.866149: Pseudo dice [0.956]\n","2024-07-18 08:59:46.866255: Epoch time: 101.92 s\n","2024-07-18 08:59:48.553879: \n","2024-07-18 08:59:48.554280: Epoch 331\n","2024-07-18 08:59:48.554461: Current learning rate: 0.00696\n","2024-07-18 09:01:30.321322: train_loss -0.6499\n","2024-07-18 09:01:30.321584: val_loss -0.6594\n","2024-07-18 09:01:30.321687: Pseudo dice [0.9506]\n","2024-07-18 09:01:30.321783: Epoch time: 101.77 s\n","2024-07-18 09:01:31.903081: \n","2024-07-18 09:01:31.903434: Epoch 332\n","2024-07-18 09:01:31.903588: Current learning rate: 0.00696\n","2024-07-18 09:03:13.812081: train_loss -0.6656\n","2024-07-18 09:03:13.812369: val_loss -0.6785\n","2024-07-18 09:03:13.812478: Pseudo dice [0.9586]\n","2024-07-18 09:03:13.812577: Epoch time: 101.91 s\n","2024-07-18 09:03:15.375368: \n","2024-07-18 09:03:15.375704: Epoch 333\n","2024-07-18 09:03:15.375850: Current learning rate: 0.00695\n","2024-07-18 09:04:57.171411: train_loss -0.6797\n","2024-07-18 09:04:57.171714: val_loss -0.6685\n","2024-07-18 09:04:57.172004: Pseudo dice [0.9444]\n","2024-07-18 09:04:57.172196: Epoch time: 101.8 s\n","2024-07-18 09:04:58.761443: \n","2024-07-18 09:04:58.761782: Epoch 334\n","2024-07-18 09:04:58.761962: Current learning rate: 0.00694\n","2024-07-18 09:06:40.398262: train_loss -0.6472\n","2024-07-18 09:06:40.398501: val_loss -0.6363\n","2024-07-18 09:06:40.398600: Pseudo dice [0.9202]\n","2024-07-18 09:06:40.398704: Epoch time: 101.64 s\n","2024-07-18 09:06:42.584628: \n","2024-07-18 09:06:42.585054: Epoch 335\n","2024-07-18 09:06:42.585221: Current learning rate: 0.00693\n","2024-07-18 09:08:24.464556: train_loss -0.6538\n","2024-07-18 09:08:24.464827: val_loss -0.6624\n","2024-07-18 09:08:24.464954: Pseudo dice [0.9344]\n","2024-07-18 09:08:24.465058: Epoch time: 101.88 s\n","2024-07-18 09:08:26.067622: \n","2024-07-18 09:08:26.068114: Epoch 336\n","2024-07-18 09:08:26.068257: Current learning rate: 0.00692\n","2024-07-18 09:10:07.960377: train_loss -0.6419\n","2024-07-18 09:10:07.960653: val_loss -0.7483\n","2024-07-18 09:10:07.960830: Pseudo dice [0.9462]\n","2024-07-18 09:10:07.960984: Epoch time: 101.9 s\n","2024-07-18 09:10:09.606480: \n","2024-07-18 09:10:09.606827: Epoch 337\n","2024-07-18 09:10:09.606994: Current learning rate: 0.00691\n","2024-07-18 09:11:51.384411: train_loss -0.6768\n","2024-07-18 09:11:51.384692: val_loss -0.7025\n","2024-07-18 09:11:51.384840: Pseudo dice [0.9397]\n","2024-07-18 09:11:51.384982: Epoch time: 101.78 s\n","2024-07-18 09:11:53.033358: \n","2024-07-18 09:11:53.033680: Epoch 338\n","2024-07-18 09:11:53.033837: Current learning rate: 0.0069\n","2024-07-18 09:13:34.801787: train_loss -0.6319\n","2024-07-18 09:13:34.802068: val_loss -0.6604\n","2024-07-18 09:13:34.802212: Pseudo dice [0.92]\n","2024-07-18 09:13:34.802329: Epoch time: 101.77 s\n","2024-07-18 09:13:36.402333: \n","2024-07-18 09:13:36.402830: Epoch 339\n","2024-07-18 09:13:36.402982: Current learning rate: 0.00689\n","2024-07-18 09:15:18.204871: train_loss -0.664\n","2024-07-18 09:15:18.205173: val_loss -0.6778\n","2024-07-18 09:15:18.205282: Pseudo dice [0.9464]\n","2024-07-18 09:15:18.205377: Epoch time: 101.81 s\n","2024-07-18 09:15:19.794755: \n","2024-07-18 09:15:19.795134: Epoch 340\n","2024-07-18 09:15:19.795291: Current learning rate: 0.00688\n","2024-07-18 09:17:01.438863: train_loss -0.6671\n","2024-07-18 09:17:01.439182: val_loss -0.6953\n","2024-07-18 09:17:01.439329: Pseudo dice [0.9536]\n","2024-07-18 09:17:01.439462: Epoch time: 101.65 s\n","2024-07-18 09:17:03.043676: \n","2024-07-18 09:17:03.044119: Epoch 341\n","2024-07-18 09:17:03.044265: Current learning rate: 0.00687\n","2024-07-18 09:18:44.827267: train_loss -0.6821\n","2024-07-18 09:18:44.827521: val_loss -0.664\n","2024-07-18 09:18:44.827718: Pseudo dice [0.9156]\n","2024-07-18 09:18:44.827847: Epoch time: 101.79 s\n","2024-07-18 09:18:47.008808: \n","2024-07-18 09:18:47.009309: Epoch 342\n","2024-07-18 09:18:47.009457: Current learning rate: 0.00686\n","2024-07-18 09:20:28.887169: train_loss -0.6766\n","2024-07-18 09:20:28.887477: val_loss -0.6606\n","2024-07-18 09:20:28.887737: Pseudo dice [0.9385]\n","2024-07-18 09:20:28.887867: Epoch time: 101.88 s\n","2024-07-18 09:20:30.469370: \n","2024-07-18 09:20:30.469727: Epoch 343\n","2024-07-18 09:20:30.469870: Current learning rate: 0.00685\n","2024-07-18 09:22:12.322705: train_loss -0.6737\n","2024-07-18 09:22:12.323282: val_loss -0.7152\n","2024-07-18 09:22:12.323437: Pseudo dice [0.9491]\n","2024-07-18 09:22:12.323543: Epoch time: 101.86 s\n","2024-07-18 09:22:13.941242: \n","2024-07-18 09:22:13.941578: Epoch 344\n","2024-07-18 09:22:13.941715: Current learning rate: 0.00684\n","2024-07-18 09:23:55.688838: train_loss -0.6553\n","2024-07-18 09:23:55.689149: val_loss -0.6557\n","2024-07-18 09:23:55.689269: Pseudo dice [0.9544]\n","2024-07-18 09:23:55.689391: Epoch time: 101.75 s\n","2024-07-18 09:23:57.319991: \n","2024-07-18 09:23:57.320376: Epoch 345\n","2024-07-18 09:23:57.320525: Current learning rate: 0.00683\n","2024-07-18 09:25:39.243027: train_loss -0.6574\n","2024-07-18 09:25:39.243272: val_loss -0.6282\n","2024-07-18 09:25:39.243377: Pseudo dice [0.9236]\n","2024-07-18 09:25:39.243473: Epoch time: 101.93 s\n","2024-07-18 09:25:40.844399: \n","2024-07-18 09:25:40.844796: Epoch 346\n","2024-07-18 09:25:40.844952: Current learning rate: 0.00682\n","2024-07-18 09:27:22.823691: train_loss -0.6402\n","2024-07-18 09:27:22.824020: val_loss -0.7103\n","2024-07-18 09:27:22.824250: Pseudo dice [0.9492]\n","2024-07-18 09:27:22.824354: Epoch time: 101.98 s\n","2024-07-18 09:27:24.527365: \n","2024-07-18 09:27:24.527827: Epoch 347\n","2024-07-18 09:27:24.527994: Current learning rate: 0.00681\n","2024-07-18 09:29:06.400357: train_loss -0.6398\n","2024-07-18 09:29:06.400620: val_loss -0.7374\n","2024-07-18 09:29:06.400795: Pseudo dice [0.955]\n","2024-07-18 09:29:06.400908: Epoch time: 101.88 s\n","2024-07-18 09:29:08.016564: \n","2024-07-18 09:29:08.016953: Epoch 348\n","2024-07-18 09:29:08.017159: Current learning rate: 0.0068\n","2024-07-18 09:30:49.706403: train_loss -0.6628\n","2024-07-18 09:30:49.706667: val_loss -0.658\n","2024-07-18 09:30:49.706778: Pseudo dice [0.9405]\n","2024-07-18 09:30:49.706916: Epoch time: 101.69 s\n","2024-07-18 09:30:51.863587: \n","2024-07-18 09:30:51.864080: Epoch 349\n","2024-07-18 09:30:51.864249: Current learning rate: 0.0068\n","2024-07-18 09:32:33.695522: train_loss -0.6555\n","2024-07-18 09:32:33.695813: val_loss -0.6803\n","2024-07-18 09:32:33.695932: Pseudo dice [0.9447]\n","2024-07-18 09:32:33.696036: Epoch time: 101.84 s\n","2024-07-18 09:32:37.219857: \n","2024-07-18 09:32:37.220351: Epoch 350\n","2024-07-18 09:32:37.220510: Current learning rate: 0.00679\n","2024-07-18 09:34:19.224076: train_loss -0.6463\n","2024-07-18 09:34:19.224403: val_loss -0.6641\n","2024-07-18 09:34:19.224508: Pseudo dice [0.9299]\n","2024-07-18 09:34:19.224611: Epoch time: 102.01 s\n","2024-07-18 09:34:20.940210: \n","2024-07-18 09:34:20.940605: Epoch 351\n","2024-07-18 09:34:20.940758: Current learning rate: 0.00678\n","2024-07-18 09:36:02.775996: train_loss -0.6718\n","2024-07-18 09:36:02.776330: val_loss -0.688\n","2024-07-18 09:36:02.776497: Pseudo dice [0.9406]\n","2024-07-18 09:36:02.776609: Epoch time: 101.84 s\n","2024-07-18 09:36:04.421361: \n","2024-07-18 09:36:04.421736: Epoch 352\n","2024-07-18 09:36:04.421988: Current learning rate: 0.00677\n","2024-07-18 09:37:46.309598: train_loss -0.6465\n","2024-07-18 09:37:46.309855: val_loss -0.547\n","2024-07-18 09:37:46.309986: Pseudo dice [0.8991]\n","2024-07-18 09:37:46.310089: Epoch time: 101.89 s\n","2024-07-18 09:37:47.897848: \n","2024-07-18 09:37:47.898292: Epoch 353\n","2024-07-18 09:37:47.898463: Current learning rate: 0.00676\n","2024-07-18 09:39:29.855964: train_loss -0.653\n","2024-07-18 09:39:29.856206: val_loss -0.6218\n","2024-07-18 09:39:29.856372: Pseudo dice [0.9315]\n","2024-07-18 09:39:29.856566: Epoch time: 101.96 s\n","2024-07-18 09:39:31.449141: \n","2024-07-18 09:39:31.449528: Epoch 354\n","2024-07-18 09:39:31.449680: Current learning rate: 0.00675\n","2024-07-18 09:41:13.282473: train_loss -0.6682\n","2024-07-18 09:41:13.282800: val_loss -0.673\n","2024-07-18 09:41:13.282907: Pseudo dice [0.9517]\n","2024-07-18 09:41:13.283074: Epoch time: 101.84 s\n","2024-07-18 09:41:14.949336: \n","2024-07-18 09:41:14.949704: Epoch 355\n","2024-07-18 09:41:14.949842: Current learning rate: 0.00674\n","2024-07-18 09:42:56.644813: train_loss -0.6541\n","2024-07-18 09:42:56.645088: val_loss -0.6464\n","2024-07-18 09:42:56.645302: Pseudo dice [0.9469]\n","2024-07-18 09:42:56.645409: Epoch time: 101.7 s\n","2024-07-18 09:42:58.849551: \n","2024-07-18 09:42:58.849916: Epoch 356\n","2024-07-18 09:42:58.850100: Current learning rate: 0.00673\n","2024-07-18 09:44:40.772964: train_loss -0.6705\n","2024-07-18 09:44:40.773211: val_loss -0.6352\n","2024-07-18 09:44:40.773311: Pseudo dice [0.9543]\n","2024-07-18 09:44:40.773408: Epoch time: 101.93 s\n","2024-07-18 09:44:42.424314: \n","2024-07-18 09:44:42.424725: Epoch 357\n","2024-07-18 09:44:42.424882: Current learning rate: 0.00672\n","2024-07-18 09:46:24.274243: train_loss -0.666\n","2024-07-18 09:46:24.274493: val_loss -0.6474\n","2024-07-18 09:46:24.274589: Pseudo dice [0.9161]\n","2024-07-18 09:46:24.274682: Epoch time: 101.85 s\n","2024-07-18 09:46:25.865354: \n","2024-07-18 09:46:25.865731: Epoch 358\n","2024-07-18 09:46:25.865896: Current learning rate: 0.00671\n","2024-07-18 09:48:07.604749: train_loss -0.659\n","2024-07-18 09:48:07.605029: val_loss -0.6661\n","2024-07-18 09:48:07.605145: Pseudo dice [0.9572]\n","2024-07-18 09:48:07.605242: Epoch time: 101.74 s\n","2024-07-18 09:48:09.181079: \n","2024-07-18 09:48:09.181494: Epoch 359\n","2024-07-18 09:48:09.181640: Current learning rate: 0.0067\n","2024-07-18 09:49:51.201641: train_loss -0.6909\n","2024-07-18 09:49:51.201955: val_loss -0.6744\n","2024-07-18 09:49:51.202094: Pseudo dice [0.9505]\n","2024-07-18 09:49:51.202224: Epoch time: 102.02 s\n","2024-07-18 09:49:52.897757: \n","2024-07-18 09:49:52.898197: Epoch 360\n","2024-07-18 09:49:52.898391: Current learning rate: 0.00669\n","2024-07-18 09:51:34.597562: train_loss -0.6703\n","2024-07-18 09:51:34.597861: val_loss -0.7267\n","2024-07-18 09:51:34.597998: Pseudo dice [0.9612]\n","2024-07-18 09:51:34.598129: Epoch time: 101.7 s\n","2024-07-18 09:51:36.217448: \n","2024-07-18 09:51:36.217871: Epoch 361\n","2024-07-18 09:51:36.218073: Current learning rate: 0.00668\n","2024-07-18 09:53:18.083326: train_loss -0.6621\n","2024-07-18 09:53:18.083575: val_loss -0.672\n","2024-07-18 09:53:18.083778: Pseudo dice [0.9591]\n","2024-07-18 09:53:18.083898: Epoch time: 101.87 s\n","2024-07-18 09:53:19.696181: \n","2024-07-18 09:53:19.696502: Epoch 362\n","2024-07-18 09:53:19.696672: Current learning rate: 0.00667\n","2024-07-18 09:55:01.385534: train_loss -0.6902\n","2024-07-18 09:55:01.385785: val_loss -0.7115\n","2024-07-18 09:55:01.385888: Pseudo dice [0.9597]\n","2024-07-18 09:55:01.386006: Epoch time: 101.69 s\n","2024-07-18 09:55:03.630423: \n","2024-07-18 09:55:03.630729: Epoch 363\n","2024-07-18 09:55:03.630868: Current learning rate: 0.00666\n","2024-07-18 09:56:45.491469: train_loss -0.6322\n","2024-07-18 09:56:45.491725: val_loss -0.6369\n","2024-07-18 09:56:45.491849: Pseudo dice [0.9077]\n","2024-07-18 09:56:45.492651: Epoch time: 101.87 s\n","2024-07-18 09:56:47.140875: \n","2024-07-18 09:56:47.141254: Epoch 364\n","2024-07-18 09:56:47.141426: Current learning rate: 0.00665\n","2024-07-18 09:58:29.034159: train_loss -0.6519\n","2024-07-18 09:58:29.034432: val_loss -0.6836\n","2024-07-18 09:58:29.034544: Pseudo dice [0.9412]\n","2024-07-18 09:58:29.034647: Epoch time: 101.9 s\n","2024-07-18 09:58:30.632232: \n","2024-07-18 09:58:30.632618: Epoch 365\n","2024-07-18 09:58:30.632790: Current learning rate: 0.00665\n","2024-07-18 10:00:12.452792: train_loss -0.6628\n","2024-07-18 10:00:12.453096: val_loss -0.6994\n","2024-07-18 10:00:12.453324: Pseudo dice [0.9578]\n","2024-07-18 10:00:12.453437: Epoch time: 101.82 s\n","2024-07-18 10:00:14.069463: \n","2024-07-18 10:00:14.069896: Epoch 366\n","2024-07-18 10:00:14.070059: Current learning rate: 0.00664\n","2024-07-18 10:01:56.031647: train_loss -0.6583\n","2024-07-18 10:01:56.031944: val_loss -0.7097\n","2024-07-18 10:01:56.032127: Pseudo dice [0.9481]\n","2024-07-18 10:01:56.032238: Epoch time: 101.97 s\n","2024-07-18 10:01:57.643173: \n","2024-07-18 10:01:57.643622: Epoch 367\n","2024-07-18 10:01:57.643790: Current learning rate: 0.00663\n","2024-07-18 10:03:39.457712: train_loss -0.6716\n","2024-07-18 10:03:39.458006: val_loss -0.6773\n","2024-07-18 10:03:39.458118: Pseudo dice [0.9569]\n","2024-07-18 10:03:39.458226: Epoch time: 101.82 s\n","2024-07-18 10:03:41.049060: \n","2024-07-18 10:03:41.049518: Epoch 368\n","2024-07-18 10:03:41.049668: Current learning rate: 0.00662\n","2024-07-18 10:05:22.960943: train_loss -0.6717\n","2024-07-18 10:05:22.961194: val_loss -0.7365\n","2024-07-18 10:05:22.961292: Pseudo dice [0.9574]\n","2024-07-18 10:05:22.961387: Epoch time: 101.92 s\n","2024-07-18 10:05:24.564387: \n","2024-07-18 10:05:24.564814: Epoch 369\n","2024-07-18 10:05:24.564999: Current learning rate: 0.00661\n","2024-07-18 10:07:06.334863: train_loss -0.6712\n","2024-07-18 10:07:06.335343: val_loss -0.7081\n","2024-07-18 10:07:06.335480: Pseudo dice [0.9544]\n","2024-07-18 10:07:06.335575: Epoch time: 101.77 s\n","2024-07-18 10:07:08.551859: \n","2024-07-18 10:07:08.552275: Epoch 370\n","2024-07-18 10:07:08.552439: Current learning rate: 0.0066\n","2024-07-18 10:08:50.254959: train_loss -0.6857\n","2024-07-18 10:08:50.255225: val_loss -0.703\n","2024-07-18 10:08:50.255319: Pseudo dice [0.939]\n","2024-07-18 10:08:50.255413: Epoch time: 101.71 s\n","2024-07-18 10:08:51.828142: \n","2024-07-18 10:08:51.828577: Epoch 371\n","2024-07-18 10:08:51.828725: Current learning rate: 0.00659\n","2024-07-18 10:10:33.591171: train_loss -0.6559\n","2024-07-18 10:10:33.591460: val_loss -0.6598\n","2024-07-18 10:10:33.591571: Pseudo dice [0.9436]\n","2024-07-18 10:10:33.591668: Epoch time: 101.77 s\n","2024-07-18 10:10:35.154550: \n","2024-07-18 10:10:35.154931: Epoch 372\n","2024-07-18 10:10:35.155076: Current learning rate: 0.00658\n","2024-07-18 10:12:16.950716: train_loss -0.6605\n","2024-07-18 10:12:16.950984: val_loss -0.6542\n","2024-07-18 10:12:16.951106: Pseudo dice [0.9619]\n","2024-07-18 10:12:16.951204: Epoch time: 101.8 s\n","2024-07-18 10:12:18.573817: \n","2024-07-18 10:12:18.574196: Epoch 373\n","2024-07-18 10:12:18.574378: Current learning rate: 0.00657\n","2024-07-18 10:14:00.395755: train_loss -0.6873\n","2024-07-18 10:14:00.396044: val_loss -0.6739\n","2024-07-18 10:14:00.396166: Pseudo dice [0.9584]\n","2024-07-18 10:14:00.396265: Epoch time: 101.83 s\n","2024-07-18 10:14:01.995340: \n","2024-07-18 10:14:01.995767: Epoch 374\n","2024-07-18 10:14:01.995911: Current learning rate: 0.00656\n","2024-07-18 10:15:43.844201: train_loss -0.6764\n","2024-07-18 10:15:43.844476: val_loss -0.7468\n","2024-07-18 10:15:43.844626: Pseudo dice [0.9555]\n","2024-07-18 10:15:43.844766: Epoch time: 101.85 s\n","2024-07-18 10:15:45.439487: \n","2024-07-18 10:15:45.439990: Epoch 375\n","2024-07-18 10:15:45.440150: Current learning rate: 0.00655\n","2024-07-18 10:17:27.219302: train_loss -0.6332\n","2024-07-18 10:17:27.219667: val_loss -0.635\n","2024-07-18 10:17:27.219822: Pseudo dice [0.8601]\n","2024-07-18 10:17:27.219974: Epoch time: 101.78 s\n","2024-07-18 10:17:29.019763: \n","2024-07-18 10:17:29.020157: Epoch 376\n","2024-07-18 10:17:29.020296: Current learning rate: 0.00654\n","2024-07-18 10:19:11.489698: train_loss -0.6658\n","2024-07-18 10:19:11.490010: val_loss -0.7411\n","2024-07-18 10:19:11.490142: Pseudo dice [0.9568]\n","2024-07-18 10:19:11.490249: Epoch time: 102.47 s\n","2024-07-18 10:19:13.214845: \n","2024-07-18 10:19:13.215265: Epoch 377\n","2024-07-18 10:19:13.215432: Current learning rate: 0.00653\n","2024-07-18 10:20:55.067756: train_loss -0.6491\n","2024-07-18 10:20:55.068120: val_loss -0.6926\n","2024-07-18 10:20:55.068217: Pseudo dice [0.9615]\n","2024-07-18 10:20:55.068309: Epoch time: 101.86 s\n","2024-07-18 10:20:56.701725: \n","2024-07-18 10:20:56.702109: Epoch 378\n","2024-07-18 10:20:56.702251: Current learning rate: 0.00652\n","2024-07-18 10:22:38.571256: train_loss -0.6801\n","2024-07-18 10:22:38.571520: val_loss -0.7237\n","2024-07-18 10:22:38.571632: Pseudo dice [0.9464]\n","2024-07-18 10:22:38.571731: Epoch time: 101.87 s\n","2024-07-18 10:22:40.228727: \n","2024-07-18 10:22:40.229094: Epoch 379\n","2024-07-18 10:22:40.229271: Current learning rate: 0.00651\n","2024-07-18 10:24:22.155748: train_loss -0.6463\n","2024-07-18 10:24:22.156040: val_loss -0.6693\n","2024-07-18 10:24:22.156147: Pseudo dice [0.9603]\n","2024-07-18 10:24:22.156250: Epoch time: 101.93 s\n","2024-07-18 10:24:23.779456: \n","2024-07-18 10:24:23.779815: Epoch 380\n","2024-07-18 10:24:23.779971: Current learning rate: 0.0065\n","2024-07-18 10:26:05.739778: train_loss -0.6886\n","2024-07-18 10:26:05.740074: val_loss -0.7207\n","2024-07-18 10:26:05.740178: Pseudo dice [0.9619]\n","2024-07-18 10:26:05.740277: Epoch time: 101.96 s\n","2024-07-18 10:26:07.351254: \n","2024-07-18 10:26:07.351616: Epoch 381\n","2024-07-18 10:26:07.351780: Current learning rate: 0.00649\n","2024-07-18 10:27:49.219276: train_loss -0.6274\n","2024-07-18 10:27:49.219518: val_loss -0.6751\n","2024-07-18 10:27:49.219626: Pseudo dice [0.947]\n","2024-07-18 10:27:49.219726: Epoch time: 101.87 s\n","2024-07-18 10:27:50.802322: \n","2024-07-18 10:27:50.802620: Epoch 382\n","2024-07-18 10:27:50.802761: Current learning rate: 0.00648\n","2024-07-18 10:29:32.626547: train_loss -0.6604\n","2024-07-18 10:29:32.626801: val_loss -0.6732\n","2024-07-18 10:29:32.626904: Pseudo dice [0.9478]\n","2024-07-18 10:29:32.627017: Epoch time: 101.83 s\n","2024-07-18 10:29:34.298647: \n","2024-07-18 10:29:34.299073: Epoch 383\n","2024-07-18 10:29:34.299214: Current learning rate: 0.00648\n","2024-07-18 10:31:16.716122: train_loss -0.6746\n","2024-07-18 10:31:16.716507: val_loss -0.676\n","2024-07-18 10:31:16.716733: Pseudo dice [0.9346]\n","2024-07-18 10:31:16.716852: Epoch time: 102.42 s\n","2024-07-18 10:31:18.374400: \n","2024-07-18 10:31:18.374843: Epoch 384\n","2024-07-18 10:31:18.375028: Current learning rate: 0.00647\n","2024-07-18 10:33:00.084783: train_loss -0.6616\n","2024-07-18 10:33:00.085088: val_loss -0.697\n","2024-07-18 10:33:00.085191: Pseudo dice [0.9465]\n","2024-07-18 10:33:00.085282: Epoch time: 101.71 s\n","2024-07-18 10:33:01.717378: \n","2024-07-18 10:33:01.717828: Epoch 385\n","2024-07-18 10:33:01.718010: Current learning rate: 0.00646\n","2024-07-18 10:34:43.621688: train_loss -0.6684\n","2024-07-18 10:34:43.622034: val_loss -0.5736\n","2024-07-18 10:34:43.622151: Pseudo dice [0.9116]\n","2024-07-18 10:34:43.622257: Epoch time: 101.91 s\n","2024-07-18 10:34:45.260819: \n","2024-07-18 10:34:45.261148: Epoch 386\n","2024-07-18 10:34:45.261290: Current learning rate: 0.00645\n","2024-07-18 10:36:27.031218: train_loss -0.6479\n","2024-07-18 10:36:27.031495: val_loss -0.6681\n","2024-07-18 10:36:27.031605: Pseudo dice [0.9632]\n","2024-07-18 10:36:27.031704: Epoch time: 101.77 s\n","2024-07-18 10:36:28.725325: \n","2024-07-18 10:36:28.725704: Epoch 387\n","2024-07-18 10:36:28.725870: Current learning rate: 0.00644\n","2024-07-18 10:38:10.487555: train_loss -0.6702\n","2024-07-18 10:38:10.487842: val_loss -0.6905\n","2024-07-18 10:38:10.487998: Pseudo dice [0.9569]\n","2024-07-18 10:38:10.488135: Epoch time: 101.77 s\n","2024-07-18 10:38:12.135632: \n","2024-07-18 10:38:12.135999: Epoch 388\n","2024-07-18 10:38:12.136149: Current learning rate: 0.00643\n","2024-07-18 10:39:53.878990: train_loss -0.6738\n","2024-07-18 10:39:53.879280: val_loss -0.6945\n","2024-07-18 10:39:53.879410: Pseudo dice [0.9567]\n","2024-07-18 10:39:53.879547: Epoch time: 101.75 s\n","2024-07-18 10:39:55.519265: \n","2024-07-18 10:39:55.519658: Epoch 389\n","2024-07-18 10:39:55.519805: Current learning rate: 0.00642\n","2024-07-18 10:41:37.373260: train_loss -0.6654\n","2024-07-18 10:41:37.373547: val_loss -0.7519\n","2024-07-18 10:41:37.373652: Pseudo dice [0.9563]\n","2024-07-18 10:41:37.373868: Epoch time: 101.86 s\n","2024-07-18 10:41:38.997018: \n","2024-07-18 10:41:38.997386: Epoch 390\n","2024-07-18 10:41:38.997525: Current learning rate: 0.00641\n","2024-07-18 10:43:21.350784: train_loss -0.6418\n","2024-07-18 10:43:21.351075: val_loss -0.5791\n","2024-07-18 10:43:21.351180: Pseudo dice [0.914]\n","2024-07-18 10:43:21.351274: Epoch time: 102.36 s\n","2024-07-18 10:43:22.945196: \n","2024-07-18 10:43:22.945677: Epoch 391\n","2024-07-18 10:43:22.945829: Current learning rate: 0.0064\n","2024-07-18 10:45:04.738565: train_loss -0.6778\n","2024-07-18 10:45:04.738812: val_loss -0.6566\n","2024-07-18 10:45:04.738913: Pseudo dice [0.9416]\n","2024-07-18 10:45:04.739064: Epoch time: 101.8 s\n","2024-07-18 10:45:06.357853: \n","2024-07-18 10:45:06.358262: Epoch 392\n","2024-07-18 10:45:06.358407: Current learning rate: 0.00639\n","2024-07-18 10:46:48.035328: train_loss -0.6577\n","2024-07-18 10:46:48.035714: val_loss -0.6508\n","2024-07-18 10:46:48.035842: Pseudo dice [0.9526]\n","2024-07-18 10:46:48.036007: Epoch time: 101.68 s\n","2024-07-18 10:46:49.694979: \n","2024-07-18 10:46:49.695459: Epoch 393\n","2024-07-18 10:46:49.695631: Current learning rate: 0.00638\n","2024-07-18 10:48:31.571217: train_loss -0.6491\n","2024-07-18 10:48:31.571462: val_loss -0.6921\n","2024-07-18 10:48:31.571561: Pseudo dice [0.9614]\n","2024-07-18 10:48:31.571667: Epoch time: 101.88 s\n","2024-07-18 10:48:33.219575: \n","2024-07-18 10:48:33.219891: Epoch 394\n","2024-07-18 10:48:33.220067: Current learning rate: 0.00637\n","2024-07-18 10:50:15.041981: train_loss -0.6755\n","2024-07-18 10:50:15.042236: val_loss -0.6928\n","2024-07-18 10:50:15.042368: Pseudo dice [0.9595]\n","2024-07-18 10:50:15.042554: Epoch time: 101.83 s\n","2024-07-18 10:50:16.685884: \n","2024-07-18 10:50:16.686340: Epoch 395\n","2024-07-18 10:50:16.686482: Current learning rate: 0.00636\n","2024-07-18 10:51:58.527071: train_loss -0.6754\n","2024-07-18 10:51:58.527349: val_loss -0.6252\n","2024-07-18 10:51:58.527487: Pseudo dice [0.9006]\n","2024-07-18 10:51:58.527619: Epoch time: 101.85 s\n","2024-07-18 10:52:00.180180: \n","2024-07-18 10:52:00.180590: Epoch 396\n","2024-07-18 10:52:00.180733: Current learning rate: 0.00635\n","2024-07-18 10:53:41.962647: train_loss -0.6714\n","2024-07-18 10:53:41.963033: val_loss -0.6808\n","2024-07-18 10:53:41.963161: Pseudo dice [0.9422]\n","2024-07-18 10:53:41.963264: Epoch time: 101.79 s\n","2024-07-18 10:53:43.618135: \n","2024-07-18 10:53:43.618449: Epoch 397\n","2024-07-18 10:53:43.618609: Current learning rate: 0.00634\n","2024-07-18 10:55:25.972302: train_loss -0.648\n","2024-07-18 10:55:25.972577: val_loss -0.6984\n","2024-07-18 10:55:25.972678: Pseudo dice [0.9534]\n","2024-07-18 10:55:25.972772: Epoch time: 102.36 s\n","2024-07-18 10:55:27.626230: \n","2024-07-18 10:55:27.626732: Epoch 398\n","2024-07-18 10:55:27.626936: Current learning rate: 0.00633\n","2024-07-18 10:57:09.420548: train_loss -0.6812\n","2024-07-18 10:57:09.420893: val_loss -0.6761\n","2024-07-18 10:57:09.421091: Pseudo dice [0.9027]\n","2024-07-18 10:57:09.421215: Epoch time: 101.8 s\n","2024-07-18 10:57:11.136061: \n","2024-07-18 10:57:11.136479: Epoch 399\n","2024-07-18 10:57:11.136629: Current learning rate: 0.00632\n","2024-07-18 10:58:52.812050: train_loss -0.6572\n","2024-07-18 10:58:52.812314: val_loss -0.6826\n","2024-07-18 10:58:52.812556: Pseudo dice [0.9541]\n","2024-07-18 10:58:52.812772: Epoch time: 101.68 s\n","2024-07-18 10:58:56.283515: \n","2024-07-18 10:58:56.283841: Epoch 400\n","2024-07-18 10:58:56.283998: Current learning rate: 0.00631\n","2024-07-18 11:00:38.036123: train_loss -0.6781\n","2024-07-18 11:00:38.036341: val_loss -0.6921\n","2024-07-18 11:00:38.036451: Pseudo dice [0.9446]\n","2024-07-18 11:00:38.036547: Epoch time: 101.76 s\n","2024-07-18 11:00:39.618949: \n","2024-07-18 11:00:39.619415: Epoch 401\n","2024-07-18 11:00:39.619555: Current learning rate: 0.0063\n","2024-07-18 11:02:21.437085: train_loss -0.6667\n","2024-07-18 11:02:21.437340: val_loss -0.7581\n","2024-07-18 11:02:21.437534: Pseudo dice [0.9596]\n","2024-07-18 11:02:21.437742: Epoch time: 101.82 s\n","2024-07-18 11:02:23.131586: \n","2024-07-18 11:02:23.131985: Epoch 402\n","2024-07-18 11:02:23.132141: Current learning rate: 0.0063\n","2024-07-18 11:04:05.045319: train_loss -0.6778\n","2024-07-18 11:04:05.045554: val_loss -0.6638\n","2024-07-18 11:04:05.045655: Pseudo dice [0.9475]\n","2024-07-18 11:04:05.045762: Epoch time: 101.92 s\n","2024-07-18 11:04:06.711537: \n","2024-07-18 11:04:06.712039: Epoch 403\n","2024-07-18 11:04:06.712235: Current learning rate: 0.00629\n","2024-07-18 11:05:48.337359: train_loss -0.6772\n","2024-07-18 11:05:48.337643: val_loss -0.6995\n","2024-07-18 11:05:48.337744: Pseudo dice [0.9506]\n","2024-07-18 11:05:48.337835: Epoch time: 101.63 s\n","2024-07-18 11:05:50.569868: \n","2024-07-18 11:05:50.570273: Epoch 404\n","2024-07-18 11:05:50.570415: Current learning rate: 0.00628\n","2024-07-18 11:07:32.593110: train_loss -0.6382\n","2024-07-18 11:07:32.593385: val_loss -0.7226\n","2024-07-18 11:07:32.593557: Pseudo dice [0.9349]\n","2024-07-18 11:07:32.593683: Epoch time: 102.03 s\n","2024-07-18 11:07:34.281602: \n","2024-07-18 11:07:34.282027: Epoch 405\n","2024-07-18 11:07:34.282170: Current learning rate: 0.00627\n","2024-07-18 11:09:16.046185: train_loss -0.622\n","2024-07-18 11:09:16.046533: val_loss -0.6509\n","2024-07-18 11:09:16.046640: Pseudo dice [0.9378]\n","2024-07-18 11:09:16.046745: Epoch time: 101.77 s\n","2024-07-18 11:09:17.722534: \n","2024-07-18 11:09:17.722979: Epoch 406\n","2024-07-18 11:09:17.723137: Current learning rate: 0.00626\n","2024-07-18 11:10:59.453397: train_loss -0.6623\n","2024-07-18 11:10:59.453691: val_loss -0.6989\n","2024-07-18 11:10:59.453850: Pseudo dice [0.9569]\n","2024-07-18 11:10:59.454077: Epoch time: 101.73 s\n","2024-07-18 11:11:01.130400: \n","2024-07-18 11:11:01.130802: Epoch 407\n","2024-07-18 11:11:01.130966: Current learning rate: 0.00625\n","2024-07-18 11:12:42.827436: train_loss -0.6795\n","2024-07-18 11:12:42.827684: val_loss -0.7436\n","2024-07-18 11:12:42.827786: Pseudo dice [0.9551]\n","2024-07-18 11:12:42.827881: Epoch time: 101.7 s\n","2024-07-18 11:12:44.458591: \n","2024-07-18 11:12:44.458859: Epoch 408\n","2024-07-18 11:12:44.459011: Current learning rate: 0.00624\n","2024-07-18 11:14:26.166264: train_loss -0.6555\n","2024-07-18 11:14:26.166508: val_loss -0.7288\n","2024-07-18 11:14:26.166605: Pseudo dice [0.96]\n","2024-07-18 11:14:26.166698: Epoch time: 101.71 s\n","2024-07-18 11:14:27.822180: \n","2024-07-18 11:14:27.822596: Epoch 409\n","2024-07-18 11:14:27.822793: Current learning rate: 0.00623\n","2024-07-18 11:16:09.663552: train_loss -0.6967\n","2024-07-18 11:16:09.663970: val_loss -0.6591\n","2024-07-18 11:16:09.664156: Pseudo dice [0.9551]\n","2024-07-18 11:16:09.664258: Epoch time: 101.85 s\n","2024-07-18 11:16:11.303910: \n","2024-07-18 11:16:11.304316: Epoch 410\n","2024-07-18 11:16:11.304476: Current learning rate: 0.00622\n","2024-07-18 11:17:53.122477: train_loss -0.6584\n","2024-07-18 11:17:53.122719: val_loss -0.6113\n","2024-07-18 11:17:53.122820: Pseudo dice [0.9366]\n","2024-07-18 11:17:53.122915: Epoch time: 101.82 s\n","2024-07-18 11:17:55.236460: \n","2024-07-18 11:17:55.236813: Epoch 411\n","2024-07-18 11:17:55.236966: Current learning rate: 0.00621\n","2024-07-18 11:19:37.016376: train_loss -0.6891\n","2024-07-18 11:19:37.016639: val_loss -0.6706\n","2024-07-18 11:19:37.016743: Pseudo dice [0.9431]\n","2024-07-18 11:19:37.016852: Epoch time: 101.78 s\n","2024-07-18 11:19:38.624006: \n","2024-07-18 11:19:38.624432: Epoch 412\n","2024-07-18 11:19:38.624588: Current learning rate: 0.0062\n","2024-07-18 11:21:20.379694: train_loss -0.6896\n","2024-07-18 11:21:20.380033: val_loss -0.6909\n","2024-07-18 11:21:20.380143: Pseudo dice [0.9323]\n","2024-07-18 11:21:20.380247: Epoch time: 101.76 s\n","2024-07-18 11:21:21.864241: \n","2024-07-18 11:21:21.864596: Epoch 413\n","2024-07-18 11:21:21.864766: Current learning rate: 0.00619\n","2024-07-18 11:23:03.703336: train_loss -0.6507\n","2024-07-18 11:23:03.703575: val_loss -0.6852\n","2024-07-18 11:23:03.703674: Pseudo dice [0.9617]\n","2024-07-18 11:23:03.703772: Epoch time: 101.84 s\n","2024-07-18 11:23:05.402608: \n","2024-07-18 11:23:05.403017: Epoch 414\n","2024-07-18 11:23:05.403172: Current learning rate: 0.00618\n","2024-07-18 11:24:47.117659: train_loss -0.6715\n","2024-07-18 11:24:47.118002: val_loss -0.7105\n","2024-07-18 11:24:47.118136: Pseudo dice [0.9671]\n","2024-07-18 11:24:47.118272: Epoch time: 101.72 s\n","2024-07-18 11:24:48.724239: \n","2024-07-18 11:24:48.724605: Epoch 415\n","2024-07-18 11:24:48.724771: Current learning rate: 0.00617\n","2024-07-18 11:26:30.516383: train_loss -0.635\n","2024-07-18 11:26:30.516639: val_loss -0.6672\n","2024-07-18 11:26:30.516743: Pseudo dice [0.92]\n","2024-07-18 11:26:30.516866: Epoch time: 101.8 s\n","2024-07-18 11:26:32.013855: \n","2024-07-18 11:26:32.014258: Epoch 416\n","2024-07-18 11:26:32.014402: Current learning rate: 0.00616\n","2024-07-18 11:28:13.958800: train_loss -0.6554\n","2024-07-18 11:28:13.959177: val_loss -0.6727\n","2024-07-18 11:28:13.959308: Pseudo dice [0.9122]\n","2024-07-18 11:28:13.959412: Epoch time: 101.95 s\n","2024-07-18 11:28:15.465880: \n","2024-07-18 11:28:15.466314: Epoch 417\n","2024-07-18 11:28:15.466448: Current learning rate: 0.00615\n","2024-07-18 11:29:57.469114: train_loss -0.6257\n","2024-07-18 11:29:57.469544: val_loss -0.6499\n","2024-07-18 11:29:57.469679: Pseudo dice [0.9172]\n","2024-07-18 11:29:57.469773: Epoch time: 102.01 s\n","2024-07-18 11:29:59.581339: \n","2024-07-18 11:29:59.581690: Epoch 418\n","2024-07-18 11:29:59.581872: Current learning rate: 0.00614\n","2024-07-18 11:31:41.375835: train_loss -0.6282\n","2024-07-18 11:31:41.376095: val_loss -0.7266\n","2024-07-18 11:31:41.376195: Pseudo dice [0.9579]\n","2024-07-18 11:31:41.376289: Epoch time: 101.8 s\n","2024-07-18 11:31:42.911482: \n","2024-07-18 11:31:42.911988: Epoch 419\n","2024-07-18 11:31:42.912155: Current learning rate: 0.00613\n","2024-07-18 11:33:24.578521: train_loss -0.6655\n","2024-07-18 11:33:24.578780: val_loss -0.6454\n","2024-07-18 11:33:24.578882: Pseudo dice [0.9499]\n","2024-07-18 11:33:24.579244: Epoch time: 101.67 s\n","2024-07-18 11:33:26.150296: \n","2024-07-18 11:33:26.150718: Epoch 420\n","2024-07-18 11:33:26.150867: Current learning rate: 0.00612\n","2024-07-18 11:35:07.819514: train_loss -0.6538\n","2024-07-18 11:35:07.819767: val_loss -0.7299\n","2024-07-18 11:35:07.819867: Pseudo dice [0.9557]\n","2024-07-18 11:35:07.819993: Epoch time: 101.67 s\n","2024-07-18 11:35:09.422989: \n","2024-07-18 11:35:09.423367: Epoch 421\n","2024-07-18 11:35:09.423527: Current learning rate: 0.00612\n","2024-07-18 11:36:51.113840: train_loss -0.6846\n","2024-07-18 11:36:51.114155: val_loss -0.7089\n","2024-07-18 11:36:51.114281: Pseudo dice [0.9525]\n","2024-07-18 11:36:51.114397: Epoch time: 101.69 s\n","2024-07-18 11:36:52.642710: \n","2024-07-18 11:36:52.643092: Epoch 422\n","2024-07-18 11:36:52.643247: Current learning rate: 0.00611\n","2024-07-18 11:38:34.295833: train_loss -0.6777\n","2024-07-18 11:38:34.296122: val_loss -0.6159\n","2024-07-18 11:38:34.296309: Pseudo dice [0.9044]\n","2024-07-18 11:38:34.296436: Epoch time: 101.66 s\n","2024-07-18 11:38:35.848370: \n","2024-07-18 11:38:35.848737: Epoch 423\n","2024-07-18 11:38:35.848877: Current learning rate: 0.0061\n","2024-07-18 11:40:17.738600: train_loss -0.645\n","2024-07-18 11:40:17.739244: val_loss -0.6371\n","2024-07-18 11:40:17.739437: Pseudo dice [0.9508]\n","2024-07-18 11:40:17.739575: Epoch time: 101.89 s\n","2024-07-18 11:40:19.352363: \n","2024-07-18 11:40:19.352726: Epoch 424\n","2024-07-18 11:40:19.352896: Current learning rate: 0.00609\n","2024-07-18 11:42:00.968874: train_loss -0.6873\n","2024-07-18 11:42:00.969216: val_loss -0.6817\n","2024-07-18 11:42:00.969361: Pseudo dice [0.949]\n","2024-07-18 11:42:00.969546: Epoch time: 101.62 s\n","2024-07-18 11:42:02.503596: \n","2024-07-18 11:42:02.504031: Epoch 425\n","2024-07-18 11:42:02.504177: Current learning rate: 0.00608\n","2024-07-18 11:43:44.762784: train_loss -0.6452\n","2024-07-18 11:43:44.763182: val_loss -0.7661\n","2024-07-18 11:43:44.763323: Pseudo dice [0.9601]\n","2024-07-18 11:43:44.763443: Epoch time: 102.26 s\n","2024-07-18 11:43:46.351577: \n","2024-07-18 11:43:46.351972: Epoch 426\n","2024-07-18 11:43:46.352134: Current learning rate: 0.00607\n","2024-07-18 11:45:28.072572: train_loss -0.6774\n","2024-07-18 11:45:28.072821: val_loss -0.6732\n","2024-07-18 11:45:28.073056: Pseudo dice [0.9635]\n","2024-07-18 11:45:28.073215: Epoch time: 101.73 s\n","2024-07-18 11:45:29.741890: \n","2024-07-18 11:45:29.742331: Epoch 427\n","2024-07-18 11:45:29.742472: Current learning rate: 0.00606\n","2024-07-18 11:47:11.551186: train_loss -0.7018\n","2024-07-18 11:47:11.551442: val_loss -0.7402\n","2024-07-18 11:47:11.551542: Pseudo dice [0.9693]\n","2024-07-18 11:47:11.551637: Epoch time: 101.81 s\n","2024-07-18 11:47:13.099243: \n","2024-07-18 11:47:13.099666: Epoch 428\n","2024-07-18 11:47:13.099804: Current learning rate: 0.00605\n","2024-07-18 11:48:54.968830: train_loss -0.6812\n","2024-07-18 11:48:54.969089: val_loss -0.6242\n","2024-07-18 11:48:54.969242: Pseudo dice [0.9573]\n","2024-07-18 11:48:54.969394: Epoch time: 101.87 s\n","2024-07-18 11:48:56.455077: \n","2024-07-18 11:48:56.455459: Epoch 429\n","2024-07-18 11:48:56.455602: Current learning rate: 0.00604\n","2024-07-18 11:50:38.326178: train_loss -0.6828\n","2024-07-18 11:50:38.326426: val_loss -0.7282\n","2024-07-18 11:50:38.326526: Pseudo dice [0.9627]\n","2024-07-18 11:50:38.326619: Epoch time: 101.88 s\n","2024-07-18 11:50:38.326709: Yayy! New best EMA pseudo Dice: 0.9507\n","2024-07-18 11:50:41.788067: \n","2024-07-18 11:50:41.788457: Epoch 430\n","2024-07-18 11:50:41.788617: Current learning rate: 0.00603\n","2024-07-18 11:52:23.617147: train_loss -0.6738\n","2024-07-18 11:52:23.617458: val_loss -0.66\n","2024-07-18 11:52:23.617562: Pseudo dice [0.9642]\n","2024-07-18 11:52:23.617661: Epoch time: 101.83 s\n","2024-07-18 11:52:23.617746: Yayy! New best EMA pseudo Dice: 0.952\n","2024-07-18 11:52:27.110836: \n","2024-07-18 11:52:27.111303: Epoch 431\n","2024-07-18 11:52:27.111459: Current learning rate: 0.00602\n","2024-07-18 11:54:08.935549: train_loss -0.6754\n","2024-07-18 11:54:08.935899: val_loss -0.7081\n","2024-07-18 11:54:08.936137: Pseudo dice [0.9488]\n","2024-07-18 11:54:08.936240: Epoch time: 101.83 s\n","2024-07-18 11:54:11.098643: \n","2024-07-18 11:54:11.099053: Epoch 432\n","2024-07-18 11:54:11.099221: Current learning rate: 0.00601\n","2024-07-18 11:55:52.910949: train_loss -0.6616\n","2024-07-18 11:55:52.911298: val_loss -0.5973\n","2024-07-18 11:55:52.911421: Pseudo dice [0.8421]\n","2024-07-18 11:55:52.911529: Epoch time: 101.82 s\n","2024-07-18 11:55:54.409913: \n","2024-07-18 11:55:54.410274: Epoch 433\n","2024-07-18 11:55:54.410427: Current learning rate: 0.006\n","2024-07-18 11:57:36.106799: train_loss -0.6647\n","2024-07-18 11:57:36.107074: val_loss -0.6987\n","2024-07-18 11:57:36.107382: Pseudo dice [0.949]\n","2024-07-18 11:57:36.107592: Epoch time: 101.7 s\n","2024-07-18 11:57:37.740083: \n","2024-07-18 11:57:37.740459: Epoch 434\n","2024-07-18 11:57:37.740612: Current learning rate: 0.00599\n","2024-07-18 11:59:19.569490: train_loss -0.6506\n","2024-07-18 11:59:19.569736: val_loss -0.6518\n","2024-07-18 11:59:19.569867: Pseudo dice [0.9241]\n","2024-07-18 11:59:19.570027: Epoch time: 101.83 s\n","2024-07-18 11:59:21.138355: \n","2024-07-18 11:59:21.138770: Epoch 435\n","2024-07-18 11:59:21.138941: Current learning rate: 0.00598\n","2024-07-18 12:01:02.944466: train_loss -0.7017\n","2024-07-18 12:01:02.944711: val_loss -0.6759\n","2024-07-18 12:01:02.944908: Pseudo dice [0.9494]\n","2024-07-18 12:01:02.945040: Epoch time: 101.81 s\n","2024-07-18 12:01:04.504609: \n","2024-07-18 12:01:04.505009: Epoch 436\n","2024-07-18 12:01:04.505153: Current learning rate: 0.00597\n","2024-07-18 12:02:46.415831: train_loss -0.6747\n","2024-07-18 12:02:46.416140: val_loss -0.6877\n","2024-07-18 12:02:46.416348: Pseudo dice [0.9575]\n","2024-07-18 12:02:46.416493: Epoch time: 101.92 s\n","2024-07-18 12:02:48.022347: \n","2024-07-18 12:02:48.022830: Epoch 437\n","2024-07-18 12:02:48.023006: Current learning rate: 0.00596\n","2024-07-18 12:04:29.872701: train_loss -0.6897\n","2024-07-18 12:04:29.872986: val_loss -0.6989\n","2024-07-18 12:04:29.873120: Pseudo dice [0.9656]\n","2024-07-18 12:04:29.873279: Epoch time: 101.85 s\n","2024-07-18 12:04:31.450973: \n","2024-07-18 12:04:31.451426: Epoch 438\n","2024-07-18 12:04:31.451584: Current learning rate: 0.00595\n","2024-07-18 12:06:13.372679: train_loss -0.7114\n","2024-07-18 12:06:13.372969: val_loss -0.7348\n","2024-07-18 12:06:13.373100: Pseudo dice [0.9642]\n","2024-07-18 12:06:13.373273: Epoch time: 101.93 s\n","2024-07-18 12:06:15.492762: \n","2024-07-18 12:06:15.493165: Epoch 439\n","2024-07-18 12:06:15.493318: Current learning rate: 0.00594\n","2024-07-18 12:07:57.356912: train_loss -0.6701\n","2024-07-18 12:07:57.357172: val_loss -0.7197\n","2024-07-18 12:07:57.357488: Pseudo dice [0.9585]\n","2024-07-18 12:07:57.357648: Epoch time: 101.87 s\n","2024-07-18 12:07:58.907367: \n","2024-07-18 12:07:58.907810: Epoch 440\n","2024-07-18 12:07:58.907999: Current learning rate: 0.00593\n","2024-07-18 12:09:40.824337: train_loss -0.6618\n","2024-07-18 12:09:40.824585: val_loss -0.6338\n","2024-07-18 12:09:40.824728: Pseudo dice [0.9312]\n","2024-07-18 12:09:40.824911: Epoch time: 101.92 s\n","2024-07-18 12:09:42.368432: \n","2024-07-18 12:09:42.368815: Epoch 441\n","2024-07-18 12:09:42.368965: Current learning rate: 0.00592\n","2024-07-18 12:11:24.319132: train_loss -0.6821\n","2024-07-18 12:11:24.319380: val_loss -0.699\n","2024-07-18 12:11:24.319486: Pseudo dice [0.9516]\n","2024-07-18 12:11:24.319619: Epoch time: 101.95 s\n","2024-07-18 12:11:25.860568: \n","2024-07-18 12:11:25.861009: Epoch 442\n","2024-07-18 12:11:25.861181: Current learning rate: 0.00592\n","2024-07-18 12:13:07.813040: train_loss -0.6568\n","2024-07-18 12:13:07.813367: val_loss -0.648\n","2024-07-18 12:13:07.813507: Pseudo dice [0.9443]\n","2024-07-18 12:13:07.813662: Epoch time: 101.96 s\n","2024-07-18 12:13:09.337037: \n","2024-07-18 12:13:09.337336: Epoch 443\n","2024-07-18 12:13:09.337476: Current learning rate: 0.00591\n","2024-07-18 12:14:51.161302: train_loss -0.6687\n","2024-07-18 12:14:51.161546: val_loss -0.4826\n","2024-07-18 12:14:51.161656: Pseudo dice [0.7592]\n","2024-07-18 12:14:51.161752: Epoch time: 101.83 s\n","2024-07-18 12:14:52.724539: \n","2024-07-18 12:14:52.724984: Epoch 444\n","2024-07-18 12:14:52.725139: Current learning rate: 0.0059\n","2024-07-18 12:16:34.606844: train_loss -0.6646\n","2024-07-18 12:16:34.607148: val_loss -0.6457\n","2024-07-18 12:16:34.607301: Pseudo dice [0.9383]\n","2024-07-18 12:16:34.607417: Epoch time: 101.89 s\n","2024-07-18 12:16:36.084004: \n","2024-07-18 12:16:36.084347: Epoch 445\n","2024-07-18 12:16:36.084487: Current learning rate: 0.00589\n","2024-07-18 12:18:17.963993: train_loss -0.6527\n","2024-07-18 12:18:17.964218: val_loss -0.7581\n","2024-07-18 12:18:17.964312: Pseudo dice [0.9603]\n","2024-07-18 12:18:17.964413: Epoch time: 101.88 s\n","2024-07-18 12:18:19.531473: \n","2024-07-18 12:18:19.531842: Epoch 446\n","2024-07-18 12:18:19.531991: Current learning rate: 0.00588\n","2024-07-18 12:20:01.965468: train_loss -0.6692\n","2024-07-18 12:20:01.965714: val_loss -0.7633\n","2024-07-18 12:20:01.965812: Pseudo dice [0.9626]\n","2024-07-18 12:20:01.965906: Epoch time: 102.44 s\n","2024-07-18 12:20:03.643807: \n","2024-07-18 12:20:03.644327: Epoch 447\n","2024-07-18 12:20:03.644485: Current learning rate: 0.00587\n","2024-07-18 12:21:45.541877: train_loss -0.6929\n","2024-07-18 12:21:45.542312: val_loss -0.7299\n","2024-07-18 12:21:45.542437: Pseudo dice [0.9614]\n","2024-07-18 12:21:45.542530: Epoch time: 101.9 s\n","2024-07-18 12:21:47.057352: \n","2024-07-18 12:21:47.057734: Epoch 448\n","2024-07-18 12:21:47.057874: Current learning rate: 0.00586\n","2024-07-18 12:23:28.907670: train_loss -0.6657\n","2024-07-18 12:23:28.908072: val_loss -0.6845\n","2024-07-18 12:23:28.908208: Pseudo dice [0.9592]\n","2024-07-18 12:23:28.908397: Epoch time: 101.85 s\n","2024-07-18 12:23:30.416222: \n","2024-07-18 12:23:30.416565: Epoch 449\n","2024-07-18 12:23:30.416705: Current learning rate: 0.00585\n","2024-07-18 12:25:12.126894: train_loss -0.6684\n","2024-07-18 12:25:12.127142: val_loss -0.6621\n","2024-07-18 12:25:12.127238: Pseudo dice [0.9357]\n","2024-07-18 12:25:12.127330: Epoch time: 101.71 s\n","2024-07-18 12:25:15.695109: \n","2024-07-18 12:25:15.695519: Epoch 450\n","2024-07-18 12:25:15.695663: Current learning rate: 0.00584\n","2024-07-18 12:26:57.398320: train_loss -0.6691\n","2024-07-18 12:26:57.398582: val_loss -0.6832\n","2024-07-18 12:26:57.398816: Pseudo dice [0.9558]\n","2024-07-18 12:26:57.399049: Epoch time: 101.71 s\n","2024-07-18 12:26:58.956864: \n","2024-07-18 12:26:58.957253: Epoch 451\n","2024-07-18 12:26:58.957403: Current learning rate: 0.00583\n","2024-07-18 12:28:40.664524: train_loss -0.6545\n","2024-07-18 12:28:40.664976: val_loss -0.6538\n","2024-07-18 12:28:40.665118: Pseudo dice [0.9248]\n","2024-07-18 12:28:40.665229: Epoch time: 101.71 s\n","2024-07-18 12:28:42.205772: \n","2024-07-18 12:28:42.206105: Epoch 452\n","2024-07-18 12:28:42.206243: Current learning rate: 0.00582\n","2024-07-18 12:30:23.982615: train_loss -0.6718\n","2024-07-18 12:30:23.983004: val_loss -0.6669\n","2024-07-18 12:30:23.983160: Pseudo dice [0.9561]\n","2024-07-18 12:30:23.983278: Epoch time: 101.78 s\n","2024-07-18 12:30:25.594456: \n","2024-07-18 12:30:25.594974: Epoch 453\n","2024-07-18 12:30:25.595136: Current learning rate: 0.00581\n","2024-07-18 12:32:07.935683: train_loss -0.6808\n","2024-07-18 12:32:07.936022: val_loss -0.7058\n","2024-07-18 12:32:07.936214: Pseudo dice [0.9365]\n","2024-07-18 12:32:07.936311: Epoch time: 102.35 s\n","2024-07-18 12:32:09.485976: \n","2024-07-18 12:32:09.486387: Epoch 454\n","2024-07-18 12:32:09.486527: Current learning rate: 0.0058\n","2024-07-18 12:33:51.214855: train_loss -0.6592\n","2024-07-18 12:33:51.215186: val_loss -0.6264\n","2024-07-18 12:33:51.215292: Pseudo dice [0.9001]\n","2024-07-18 12:33:51.215400: Epoch time: 101.73 s\n","2024-07-18 12:33:52.754804: \n","2024-07-18 12:33:52.755273: Epoch 455\n","2024-07-18 12:33:52.755437: Current learning rate: 0.00579\n","2024-07-18 12:35:34.559183: train_loss -0.644\n","2024-07-18 12:35:34.559442: val_loss -0.7174\n","2024-07-18 12:35:34.559566: Pseudo dice [0.9626]\n","2024-07-18 12:35:34.559689: Epoch time: 101.81 s\n","2024-07-18 12:35:36.120667: \n","2024-07-18 12:35:36.121116: Epoch 456\n","2024-07-18 12:35:36.121270: Current learning rate: 0.00578\n","2024-07-18 12:37:17.843572: train_loss -0.6734\n","2024-07-18 12:37:17.843861: val_loss -0.6879\n","2024-07-18 12:37:17.844004: Pseudo dice [0.9464]\n","2024-07-18 12:37:17.844121: Epoch time: 101.73 s\n","2024-07-18 12:37:19.382836: \n","2024-07-18 12:37:19.383187: Epoch 457\n","2024-07-18 12:37:19.383325: Current learning rate: 0.00577\n","2024-07-18 12:39:01.190909: train_loss -0.669\n","2024-07-18 12:39:01.191178: val_loss -0.6716\n","2024-07-18 12:39:01.191269: Pseudo dice [0.951]\n","2024-07-18 12:39:01.191360: Epoch time: 101.81 s\n","2024-07-18 12:39:02.674733: \n","2024-07-18 12:39:02.675170: Epoch 458\n","2024-07-18 12:39:02.675321: Current learning rate: 0.00576\n","2024-07-18 12:40:44.407201: train_loss -0.6408\n","2024-07-18 12:40:44.407453: val_loss -0.7062\n","2024-07-18 12:40:44.407553: Pseudo dice [0.9526]\n","2024-07-18 12:40:44.407654: Epoch time: 101.74 s\n","2024-07-18 12:40:45.934383: \n","2024-07-18 12:40:45.934691: Epoch 459\n","2024-07-18 12:40:45.934830: Current learning rate: 0.00575\n","2024-07-18 12:42:27.579845: train_loss -0.6557\n","2024-07-18 12:42:27.580178: val_loss -0.6244\n","2024-07-18 12:42:27.580309: Pseudo dice [0.926]\n","2024-07-18 12:42:27.580458: Epoch time: 101.65 s\n","2024-07-18 12:42:29.162401: \n","2024-07-18 12:42:29.162789: Epoch 460\n","2024-07-18 12:42:29.162967: Current learning rate: 0.00574\n","2024-07-18 12:44:11.420870: train_loss -0.635\n","2024-07-18 12:44:11.421140: val_loss -0.7794\n","2024-07-18 12:44:11.421239: Pseudo dice [0.9509]\n","2024-07-18 12:44:11.421333: Epoch time: 102.26 s\n","2024-07-18 12:44:12.927092: \n","2024-07-18 12:44:12.927461: Epoch 461\n","2024-07-18 12:44:12.927627: Current learning rate: 0.00573\n","2024-07-18 12:45:54.915868: train_loss -0.6512\n","2024-07-18 12:45:54.916149: val_loss -0.7023\n","2024-07-18 12:45:54.916272: Pseudo dice [0.9312]\n","2024-07-18 12:45:54.916433: Epoch time: 101.99 s\n","2024-07-18 12:45:56.465904: \n","2024-07-18 12:45:56.466308: Epoch 462\n","2024-07-18 12:45:56.466468: Current learning rate: 0.00572\n","2024-07-18 12:47:38.294453: train_loss -0.6643\n","2024-07-18 12:47:38.294719: val_loss -0.6784\n","2024-07-18 12:47:38.294860: Pseudo dice [0.9312]\n","2024-07-18 12:47:38.294990: Epoch time: 101.83 s\n","2024-07-18 12:47:39.837160: \n","2024-07-18 12:47:39.837587: Epoch 463\n","2024-07-18 12:47:39.837784: Current learning rate: 0.00571\n","2024-07-18 12:49:21.688949: train_loss -0.6763\n","2024-07-18 12:49:21.689289: val_loss -0.6673\n","2024-07-18 12:49:21.689408: Pseudo dice [0.9083]\n","2024-07-18 12:49:21.689521: Epoch time: 101.86 s\n","2024-07-18 12:49:23.204790: \n","2024-07-18 12:49:23.205226: Epoch 464\n","2024-07-18 12:49:23.205372: Current learning rate: 0.0057\n","2024-07-18 12:51:05.055665: train_loss -0.6341\n","2024-07-18 12:51:05.055940: val_loss -0.7074\n","2024-07-18 12:51:05.056142: Pseudo dice [0.9579]\n","2024-07-18 12:51:05.056260: Epoch time: 101.85 s\n","2024-07-18 12:51:06.569851: \n","2024-07-18 12:51:06.570248: Epoch 465\n","2024-07-18 12:51:06.570397: Current learning rate: 0.0057\n","2024-07-18 12:52:48.325698: train_loss -0.6766\n","2024-07-18 12:52:48.326247: val_loss -0.7079\n","2024-07-18 12:52:48.326353: Pseudo dice [0.949]\n","2024-07-18 12:52:48.326450: Epoch time: 101.76 s\n","2024-07-18 12:52:49.920391: \n","2024-07-18 12:52:49.920707: Epoch 466\n","2024-07-18 12:52:49.920970: Current learning rate: 0.00569\n","2024-07-18 12:54:31.702559: train_loss -0.6745\n","2024-07-18 12:54:31.702803: val_loss -0.6961\n","2024-07-18 12:54:31.702911: Pseudo dice [0.9622]\n","2024-07-18 12:54:31.703066: Epoch time: 101.79 s\n","2024-07-18 12:54:33.248799: \n","2024-07-18 12:54:33.249252: Epoch 467\n","2024-07-18 12:54:33.249401: Current learning rate: 0.00568\n","2024-07-18 12:56:15.838258: train_loss -0.6715\n","2024-07-18 12:56:15.838568: val_loss -0.7497\n","2024-07-18 12:56:15.838690: Pseudo dice [0.9654]\n","2024-07-18 12:56:15.838831: Epoch time: 102.59 s\n","2024-07-18 12:56:17.435639: \n","2024-07-18 12:56:17.435974: Epoch 468\n","2024-07-18 12:56:17.436109: Current learning rate: 0.00567\n","2024-07-18 12:57:59.225698: train_loss -0.6847\n","2024-07-18 12:57:59.226057: val_loss -0.6883\n","2024-07-18 12:57:59.226173: Pseudo dice [0.9535]\n","2024-07-18 12:57:59.226278: Epoch time: 101.79 s\n","2024-07-18 12:58:00.774260: \n","2024-07-18 12:58:00.774702: Epoch 469\n","2024-07-18 12:58:00.774878: Current learning rate: 0.00566\n","2024-07-18 12:59:42.732019: train_loss -0.6637\n","2024-07-18 12:59:42.732349: val_loss -0.6683\n","2024-07-18 12:59:42.732459: Pseudo dice [0.9307]\n","2024-07-18 12:59:42.732563: Epoch time: 101.96 s\n","2024-07-18 12:59:44.214902: \n","2024-07-18 12:59:44.215308: Epoch 470\n","2024-07-18 12:59:44.215451: Current learning rate: 0.00565\n","2024-07-18 13:01:26.171804: train_loss -0.6352\n","2024-07-18 13:01:26.172223: val_loss -0.6853\n","2024-07-18 13:01:26.172329: Pseudo dice [0.95]\n","2024-07-18 13:01:26.172437: Epoch time: 101.96 s\n","2024-07-18 13:01:27.736077: \n","2024-07-18 13:01:27.736478: Epoch 471\n","2024-07-18 13:01:27.736618: Current learning rate: 0.00564\n","2024-07-18 13:03:09.531768: train_loss -0.6817\n","2024-07-18 13:03:09.532038: val_loss -0.7032\n","2024-07-18 13:03:09.532154: Pseudo dice [0.9584]\n","2024-07-18 13:03:09.532250: Epoch time: 101.8 s\n","2024-07-18 13:03:11.017274: \n","2024-07-18 13:03:11.017660: Epoch 472\n","2024-07-18 13:03:11.017806: Current learning rate: 0.00563\n","2024-07-18 13:04:52.898110: train_loss -0.6419\n","2024-07-18 13:04:52.898405: val_loss -0.6784\n","2024-07-18 13:04:52.898519: Pseudo dice [0.9483]\n","2024-07-18 13:04:52.898707: Epoch time: 101.88 s\n","2024-07-18 13:04:54.439366: \n","2024-07-18 13:04:54.439749: Epoch 473\n","2024-07-18 13:04:54.439911: Current learning rate: 0.00562\n","2024-07-18 13:06:36.285354: train_loss -0.6673\n","2024-07-18 13:06:36.285739: val_loss -0.6711\n","2024-07-18 13:06:36.285855: Pseudo dice [0.9396]\n","2024-07-18 13:06:36.286069: Epoch time: 101.85 s\n","2024-07-18 13:06:37.942688: \n","2024-07-18 13:06:37.943146: Epoch 474\n","2024-07-18 13:06:37.943285: Current learning rate: 0.00561\n","2024-07-18 13:08:20.478728: train_loss -0.6515\n","2024-07-18 13:08:20.479049: val_loss -0.6906\n","2024-07-18 13:08:20.479179: Pseudo dice [0.9213]\n","2024-07-18 13:08:20.479343: Epoch time: 102.54 s\n","2024-07-18 13:08:22.048737: \n","2024-07-18 13:08:22.049164: Epoch 475\n","2024-07-18 13:08:22.049304: Current learning rate: 0.0056\n","2024-07-18 13:10:03.888748: train_loss -0.6666\n","2024-07-18 13:10:03.889032: val_loss -0.7051\n","2024-07-18 13:10:03.889145: Pseudo dice [0.9389]\n","2024-07-18 13:10:03.889249: Epoch time: 101.84 s\n","2024-07-18 13:10:05.373375: \n","2024-07-18 13:10:05.373705: Epoch 476\n","2024-07-18 13:10:05.373867: Current learning rate: 0.00559\n","2024-07-18 13:11:47.311732: train_loss -0.672\n","2024-07-18 13:11:47.312050: val_loss -0.7114\n","2024-07-18 13:11:47.312213: Pseudo dice [0.9609]\n","2024-07-18 13:11:47.312472: Epoch time: 101.94 s\n","2024-07-18 13:11:48.846422: \n","2024-07-18 13:11:48.846833: Epoch 477\n","2024-07-18 13:11:48.847001: Current learning rate: 0.00558\n","2024-07-18 13:13:30.495883: train_loss -0.6664\n","2024-07-18 13:13:30.496264: val_loss -0.6761\n","2024-07-18 13:13:30.496393: Pseudo dice [0.9591]\n","2024-07-18 13:13:30.496507: Epoch time: 101.65 s\n","2024-07-18 13:13:32.035345: \n","2024-07-18 13:13:32.035674: Epoch 478\n","2024-07-18 13:13:32.035872: Current learning rate: 0.00557\n","2024-07-18 13:15:13.914648: train_loss -0.661\n","2024-07-18 13:15:13.914914: val_loss -0.6406\n","2024-07-18 13:15:13.915061: Pseudo dice [0.9499]\n","2024-07-18 13:15:13.915199: Epoch time: 101.88 s\n","2024-07-18 13:15:15.467770: \n","2024-07-18 13:15:15.468094: Epoch 479\n","2024-07-18 13:15:15.468283: Current learning rate: 0.00556\n","2024-07-18 13:16:57.177105: train_loss -0.6637\n","2024-07-18 13:16:57.177433: val_loss -0.681\n","2024-07-18 13:16:57.177578: Pseudo dice [0.966]\n","2024-07-18 13:16:57.177683: Epoch time: 101.71 s\n","2024-07-18 13:16:58.793802: \n","2024-07-18 13:16:58.794199: Epoch 480\n","2024-07-18 13:16:58.794343: Current learning rate: 0.00555\n","2024-07-18 13:18:40.612455: train_loss -0.6524\n","2024-07-18 13:18:40.612688: val_loss -0.6582\n","2024-07-18 13:18:40.612841: Pseudo dice [0.903]\n","2024-07-18 13:18:40.612985: Epoch time: 101.82 s\n","2024-07-18 13:18:42.222722: \n","2024-07-18 13:18:42.223231: Epoch 481\n","2024-07-18 13:18:42.223390: Current learning rate: 0.00554\n","2024-07-18 13:20:24.558714: train_loss -0.6949\n","2024-07-18 13:20:24.559031: val_loss -0.6627\n","2024-07-18 13:20:24.559183: Pseudo dice [0.9247]\n","2024-07-18 13:20:24.559360: Epoch time: 102.34 s\n","2024-07-18 13:20:26.106222: \n","2024-07-18 13:20:26.106597: Epoch 482\n","2024-07-18 13:20:26.106764: Current learning rate: 0.00553\n","2024-07-18 13:22:07.944749: train_loss -0.6824\n","2024-07-18 13:22:07.945050: val_loss -0.7236\n","2024-07-18 13:22:07.945166: Pseudo dice [0.9597]\n","2024-07-18 13:22:07.945267: Epoch time: 101.84 s\n","2024-07-18 13:22:09.543560: \n","2024-07-18 13:22:09.544006: Epoch 483\n","2024-07-18 13:22:09.544163: Current learning rate: 0.00552\n","2024-07-18 13:23:51.290772: train_loss -0.6802\n","2024-07-18 13:23:51.291133: val_loss -0.7255\n","2024-07-18 13:23:51.291269: Pseudo dice [0.9537]\n","2024-07-18 13:23:51.291410: Epoch time: 101.75 s\n","2024-07-18 13:23:52.814632: \n","2024-07-18 13:23:52.815022: Epoch 484\n","2024-07-18 13:23:52.815169: Current learning rate: 0.00551\n","2024-07-18 13:25:34.765704: train_loss -0.6789\n","2024-07-18 13:25:34.766102: val_loss -0.7548\n","2024-07-18 13:25:34.766236: Pseudo dice [0.9434]\n","2024-07-18 13:25:34.766354: Epoch time: 101.96 s\n","2024-07-18 13:25:36.289682: \n","2024-07-18 13:25:36.290016: Epoch 485\n","2024-07-18 13:25:36.290153: Current learning rate: 0.0055\n","2024-07-18 13:27:18.129142: train_loss -0.6887\n","2024-07-18 13:27:18.129389: val_loss -0.6951\n","2024-07-18 13:27:18.129490: Pseudo dice [0.9602]\n","2024-07-18 13:27:18.129586: Epoch time: 101.84 s\n","2024-07-18 13:27:19.686601: \n","2024-07-18 13:27:19.686965: Epoch 486\n","2024-07-18 13:27:19.687107: Current learning rate: 0.00549\n","2024-07-18 13:29:01.625498: train_loss -0.6765\n","2024-07-18 13:29:01.625750: val_loss -0.7121\n","2024-07-18 13:29:01.625849: Pseudo dice [0.9664]\n","2024-07-18 13:29:01.625959: Epoch time: 101.94 s\n","2024-07-18 13:29:03.170576: \n","2024-07-18 13:29:03.170973: Epoch 487\n","2024-07-18 13:29:03.171196: Current learning rate: 0.00548\n","2024-07-18 13:30:44.965564: train_loss -0.6438\n","2024-07-18 13:30:44.965816: val_loss -0.7157\n","2024-07-18 13:30:44.966061: Pseudo dice [0.9424]\n","2024-07-18 13:30:44.966169: Epoch time: 101.8 s\n","2024-07-18 13:30:46.466854: \n","2024-07-18 13:30:46.467159: Epoch 488\n","2024-07-18 13:30:46.467299: Current learning rate: 0.00547\n","2024-07-18 13:32:28.889001: train_loss -0.6561\n","2024-07-18 13:32:28.889263: val_loss -0.6405\n","2024-07-18 13:32:28.889363: Pseudo dice [0.9553]\n","2024-07-18 13:32:28.889469: Epoch time: 102.43 s\n","2024-07-18 13:32:30.514526: \n","2024-07-18 13:32:30.514987: Epoch 489\n","2024-07-18 13:32:30.515144: Current learning rate: 0.00546\n","2024-07-18 13:34:12.435482: train_loss -0.6828\n","2024-07-18 13:34:12.435951: val_loss -0.7069\n","2024-07-18 13:34:12.436091: Pseudo dice [0.9624]\n","2024-07-18 13:34:12.436214: Epoch time: 101.93 s\n","2024-07-18 13:34:14.008425: \n","2024-07-18 13:34:14.008846: Epoch 490\n","2024-07-18 13:34:14.009151: Current learning rate: 0.00546\n","2024-07-18 13:35:56.006198: train_loss -0.6644\n","2024-07-18 13:35:56.006444: val_loss -0.6937\n","2024-07-18 13:35:56.006545: Pseudo dice [0.9566]\n","2024-07-18 13:35:56.006647: Epoch time: 102.0 s\n","2024-07-18 13:35:57.552008: \n","2024-07-18 13:35:57.552416: Epoch 491\n","2024-07-18 13:35:57.552572: Current learning rate: 0.00545\n","2024-07-18 13:37:39.410545: train_loss -0.6628\n","2024-07-18 13:37:39.411124: val_loss -0.6635\n","2024-07-18 13:37:39.411233: Pseudo dice [0.9422]\n","2024-07-18 13:37:39.411323: Epoch time: 101.86 s\n","2024-07-18 13:37:40.974626: \n","2024-07-18 13:37:40.975071: Epoch 492\n","2024-07-18 13:37:40.975245: Current learning rate: 0.00544\n","2024-07-18 13:39:22.782440: train_loss -0.6813\n","2024-07-18 13:39:22.782702: val_loss -0.6555\n","2024-07-18 13:39:22.782829: Pseudo dice [0.9632]\n","2024-07-18 13:39:22.783011: Epoch time: 101.81 s\n","2024-07-18 13:39:24.348793: \n","2024-07-18 13:39:24.349213: Epoch 493\n","2024-07-18 13:39:24.349401: Current learning rate: 0.00543\n","2024-07-18 13:41:06.316587: train_loss -0.6573\n","2024-07-18 13:41:06.316880: val_loss -0.675\n","2024-07-18 13:41:06.317048: Pseudo dice [0.953]\n","2024-07-18 13:41:06.317158: Epoch time: 101.97 s\n","2024-07-18 13:41:07.838157: \n","2024-07-18 13:41:07.838577: Epoch 494\n","2024-07-18 13:41:07.838726: Current learning rate: 0.00542\n","2024-07-18 13:42:49.658109: train_loss -0.6538\n","2024-07-18 13:42:49.658425: val_loss -0.725\n","2024-07-18 13:42:49.658551: Pseudo dice [0.956]\n","2024-07-18 13:42:49.658659: Epoch time: 101.82 s\n","2024-07-18 13:42:51.265389: \n","2024-07-18 13:42:51.265770: Epoch 495\n","2024-07-18 13:42:51.265968: Current learning rate: 0.00541\n","2024-07-18 13:44:33.859877: train_loss -0.6637\n","2024-07-18 13:44:33.860167: val_loss -0.6702\n","2024-07-18 13:44:33.860317: Pseudo dice [0.955]\n","2024-07-18 13:44:33.860427: Epoch time: 102.6 s\n","2024-07-18 13:44:35.444047: \n","2024-07-18 13:44:35.444546: Epoch 496\n","2024-07-18 13:44:35.444687: Current learning rate: 0.0054\n","2024-07-18 13:46:17.337081: train_loss -0.6618\n","2024-07-18 13:46:17.337385: val_loss -0.7144\n","2024-07-18 13:46:17.337579: Pseudo dice [0.9435]\n","2024-07-18 13:46:17.337698: Epoch time: 101.9 s\n","2024-07-18 13:46:18.901552: \n","2024-07-18 13:46:18.901962: Epoch 497\n","2024-07-18 13:46:18.902111: Current learning rate: 0.00539\n","2024-07-18 13:48:00.917039: train_loss -0.6548\n","2024-07-18 13:48:00.917317: val_loss -0.7307\n","2024-07-18 13:48:00.917454: Pseudo dice [0.9495]\n","2024-07-18 13:48:00.917591: Epoch time: 102.02 s\n","2024-07-18 13:48:02.540395: \n","2024-07-18 13:48:02.540783: Epoch 498\n","2024-07-18 13:48:02.541020: Current learning rate: 0.00538\n","2024-07-18 13:49:44.333443: train_loss -0.6706\n","2024-07-18 13:49:44.333724: val_loss -0.7312\n","2024-07-18 13:49:44.333860: Pseudo dice [0.9591]\n","2024-07-18 13:49:44.334027: Epoch time: 101.8 s\n","2024-07-18 13:49:45.904022: \n","2024-07-18 13:49:45.904370: Epoch 499\n","2024-07-18 13:49:45.904522: Current learning rate: 0.00537\n","2024-07-18 13:51:27.610168: train_loss -0.6971\n","2024-07-18 13:51:27.610427: val_loss -0.7737\n","2024-07-18 13:51:27.610533: Pseudo dice [0.961]\n","2024-07-18 13:51:27.610631: Epoch time: 101.71 s\n","2024-07-18 13:51:29.540412: Yayy! New best EMA pseudo Dice: 0.9527\n","2024-07-18 13:51:35.310637: \n","2024-07-18 13:51:35.311171: Epoch 500\n","2024-07-18 13:51:35.311326: Current learning rate: 0.00536\n","2024-07-18 13:53:17.025709: train_loss -0.6683\n","2024-07-18 13:53:17.026037: val_loss -0.6992\n","2024-07-18 13:53:17.026149: Pseudo dice [0.9614]\n","2024-07-18 13:53:17.026256: Epoch time: 101.72 s\n","2024-07-18 13:53:17.026329: Yayy! New best EMA pseudo Dice: 0.9536\n","2024-07-18 13:53:20.780869: \n","2024-07-18 13:53:20.781252: Epoch 501\n","2024-07-18 13:53:20.781419: Current learning rate: 0.00535\n","2024-07-18 13:55:02.650047: train_loss -0.6658\n","2024-07-18 13:55:02.650290: val_loss -0.7588\n","2024-07-18 13:55:02.650398: Pseudo dice [0.9591]\n","2024-07-18 13:55:02.650528: Epoch time: 101.87 s\n","2024-07-18 13:55:02.650626: Yayy! New best EMA pseudo Dice: 0.9541\n","2024-07-18 13:55:06.731514: \n","2024-07-18 13:55:06.731891: Epoch 502\n","2024-07-18 13:55:06.732040: Current learning rate: 0.00534\n","2024-07-18 13:56:48.525039: train_loss -0.6701\n","2024-07-18 13:56:48.525350: val_loss -0.714\n","2024-07-18 13:56:48.525481: Pseudo dice [0.9583]\n","2024-07-18 13:56:48.525655: Epoch time: 101.8 s\n","2024-07-18 13:56:48.525808: Yayy! New best EMA pseudo Dice: 0.9545\n","2024-07-18 13:56:51.993845: \n","2024-07-18 13:56:51.994287: Epoch 503\n","2024-07-18 13:56:51.994438: Current learning rate: 0.00533\n","2024-07-18 13:58:33.781509: train_loss -0.6578\n","2024-07-18 13:58:33.781749: val_loss -0.7129\n","2024-07-18 13:58:33.781850: Pseudo dice [0.9514]\n","2024-07-18 13:58:33.781960: Epoch time: 101.79 s\n","2024-07-18 13:58:35.349083: \n","2024-07-18 13:58:35.349462: Epoch 504\n","2024-07-18 13:58:35.349627: Current learning rate: 0.00532\n","2024-07-18 14:00:17.149085: train_loss -0.6833\n","2024-07-18 14:00:17.149383: val_loss -0.6574\n","2024-07-18 14:00:17.149486: Pseudo dice [0.9555]\n","2024-07-18 14:00:17.149581: Epoch time: 101.8 s\n","2024-07-18 14:00:18.692329: \n","2024-07-18 14:00:18.692780: Epoch 505\n","2024-07-18 14:00:18.692935: Current learning rate: 0.00531\n","2024-07-18 14:02:00.462056: train_loss -0.6649\n","2024-07-18 14:02:00.462520: val_loss -0.7403\n","2024-07-18 14:02:00.462635: Pseudo dice [0.9474]\n","2024-07-18 14:02:00.462735: Epoch time: 101.77 s\n","2024-07-18 14:02:02.012022: \n","2024-07-18 14:02:02.012433: Epoch 506\n","2024-07-18 14:02:02.012654: Current learning rate: 0.0053\n","2024-07-18 14:03:43.989519: train_loss -0.6968\n","2024-07-18 14:03:43.989807: val_loss -0.665\n","2024-07-18 14:03:43.989962: Pseudo dice [0.9546]\n","2024-07-18 14:03:43.990144: Epoch time: 101.98 s\n","2024-07-18 14:03:45.590180: \n","2024-07-18 14:03:45.590651: Epoch 507\n","2024-07-18 14:03:45.590801: Current learning rate: 0.00529\n","2024-07-18 14:05:27.326963: train_loss -0.6717\n","2024-07-18 14:05:27.327200: val_loss -0.6579\n","2024-07-18 14:05:27.327299: Pseudo dice [0.9537]\n","2024-07-18 14:05:27.327402: Epoch time: 101.74 s\n","2024-07-18 14:05:28.858225: \n","2024-07-18 14:05:28.858648: Epoch 508\n","2024-07-18 14:05:28.858787: Current learning rate: 0.00528\n","2024-07-18 14:07:10.638031: train_loss -0.6176\n","2024-07-18 14:07:10.638432: val_loss -0.6413\n","2024-07-18 14:07:10.638589: Pseudo dice [0.9384]\n","2024-07-18 14:07:10.638714: Epoch time: 101.78 s\n","2024-07-18 14:07:12.809645: \n","2024-07-18 14:07:12.810072: Epoch 509\n","2024-07-18 14:07:12.810213: Current learning rate: 0.00527\n","2024-07-18 14:08:54.691154: train_loss -0.6968\n","2024-07-18 14:08:54.691410: val_loss -0.6928\n","2024-07-18 14:08:54.691576: Pseudo dice [0.9313]\n","2024-07-18 14:08:54.691823: Epoch time: 101.89 s\n","2024-07-18 14:08:56.281554: \n","2024-07-18 14:08:56.282003: Epoch 510\n","2024-07-18 14:08:56.282145: Current learning rate: 0.00526\n","2024-07-18 14:10:38.017499: train_loss -0.6726\n","2024-07-18 14:10:38.017787: val_loss -0.6962\n","2024-07-18 14:10:38.017892: Pseudo dice [0.9476]\n","2024-07-18 14:10:38.018049: Epoch time: 101.74 s\n","2024-07-18 14:10:39.579385: \n","2024-07-18 14:10:39.579776: Epoch 511\n","2024-07-18 14:10:39.579969: Current learning rate: 0.00525\n","2024-07-18 14:12:21.494441: train_loss -0.6715\n","2024-07-18 14:12:21.494761: val_loss -0.6739\n","2024-07-18 14:12:21.494884: Pseudo dice [0.9648]\n","2024-07-18 14:12:21.495039: Epoch time: 101.92 s\n","2024-07-18 14:12:23.050415: \n","2024-07-18 14:12:23.050750: Epoch 512\n","2024-07-18 14:12:23.050910: Current learning rate: 0.00524\n","2024-07-18 14:14:04.796353: train_loss -0.681\n","2024-07-18 14:14:04.796629: val_loss -0.7083\n","2024-07-18 14:14:04.796750: Pseudo dice [0.9551]\n","2024-07-18 14:14:04.796849: Epoch time: 101.75 s\n","2024-07-18 14:14:06.357078: \n","2024-07-18 14:14:06.357425: Epoch 513\n","2024-07-18 14:14:06.357565: Current learning rate: 0.00523\n","2024-07-18 14:15:48.181640: train_loss -0.6787\n","2024-07-18 14:15:48.181883: val_loss -0.6871\n","2024-07-18 14:15:48.182008: Pseudo dice [0.9573]\n","2024-07-18 14:15:48.182107: Epoch time: 101.83 s\n","2024-07-18 14:15:49.742237: \n","2024-07-18 14:15:49.742637: Epoch 514\n","2024-07-18 14:15:49.742772: Current learning rate: 0.00522\n","2024-07-18 14:17:31.444340: train_loss -0.6769\n","2024-07-18 14:17:31.444780: val_loss -0.6759\n","2024-07-18 14:17:31.444894: Pseudo dice [0.9645]\n","2024-07-18 14:17:31.445029: Epoch time: 101.71 s\n","2024-07-18 14:17:32.966802: \n","2024-07-18 14:17:32.967137: Epoch 515\n","2024-07-18 14:17:32.967309: Current learning rate: 0.00521\n","2024-07-18 14:19:14.839394: train_loss -0.6798\n","2024-07-18 14:19:14.839726: val_loss -0.6535\n","2024-07-18 14:19:14.839839: Pseudo dice [0.9571]\n","2024-07-18 14:19:14.839966: Epoch time: 101.88 s\n","2024-07-18 14:19:17.029850: \n","2024-07-18 14:19:17.030234: Epoch 516\n","2024-07-18 14:19:17.030382: Current learning rate: 0.0052\n","2024-07-18 14:20:58.945572: train_loss -0.692\n","2024-07-18 14:20:58.945896: val_loss -0.7119\n","2024-07-18 14:20:58.946054: Pseudo dice [0.9594]\n","2024-07-18 14:20:58.946166: Epoch time: 101.92 s\n","2024-07-18 14:21:00.567400: \n","2024-07-18 14:21:00.567800: Epoch 517\n","2024-07-18 14:21:00.567950: Current learning rate: 0.00519\n","2024-07-18 14:22:42.410910: train_loss -0.6681\n","2024-07-18 14:22:42.411185: val_loss -0.7401\n","2024-07-18 14:22:42.411329: Pseudo dice [0.962]\n","2024-07-18 14:22:42.411435: Epoch time: 101.85 s\n","2024-07-18 14:22:42.411518: Yayy! New best EMA pseudo Dice: 0.9552\n","2024-07-18 14:22:45.947341: \n","2024-07-18 14:22:45.947797: Epoch 518\n","2024-07-18 14:22:45.947990: Current learning rate: 0.00518\n","2024-07-18 14:24:27.744523: train_loss -0.6834\n","2024-07-18 14:24:27.744776: val_loss -0.7817\n","2024-07-18 14:24:27.744877: Pseudo dice [0.9656]\n","2024-07-18 14:24:27.744994: Epoch time: 101.8 s\n","2024-07-18 14:24:27.745086: Yayy! New best EMA pseudo Dice: 0.9562\n","2024-07-18 14:24:31.160589: \n","2024-07-18 14:24:31.160998: Epoch 519\n","2024-07-18 14:24:31.161154: Current learning rate: 0.00518\n","2024-07-18 14:26:12.920282: train_loss -0.6774\n","2024-07-18 14:26:12.920586: val_loss -0.7185\n","2024-07-18 14:26:12.920694: Pseudo dice [0.9606]\n","2024-07-18 14:26:12.920789: Epoch time: 101.76 s\n","2024-07-18 14:26:12.920876: Yayy! New best EMA pseudo Dice: 0.9567\n","2024-07-18 14:26:16.443847: \n","2024-07-18 14:26:16.444215: Epoch 520\n","2024-07-18 14:26:16.444358: Current learning rate: 0.00517\n","2024-07-18 14:27:58.268092: train_loss -0.6861\n","2024-07-18 14:27:58.268305: val_loss -0.7036\n","2024-07-18 14:27:58.268403: Pseudo dice [0.9622]\n","2024-07-18 14:27:58.268504: Epoch time: 101.83 s\n","2024-07-18 14:27:58.268653: Yayy! New best EMA pseudo Dice: 0.9572\n","2024-07-18 14:28:01.920420: \n","2024-07-18 14:28:01.920814: Epoch 521\n","2024-07-18 14:28:01.920978: Current learning rate: 0.00516\n","2024-07-18 14:29:43.571245: train_loss -0.6889\n","2024-07-18 14:29:43.571598: val_loss -0.7198\n","2024-07-18 14:29:43.571718: Pseudo dice [0.9686]\n","2024-07-18 14:29:43.571823: Epoch time: 101.66 s\n","2024-07-18 14:29:43.571897: Yayy! New best EMA pseudo Dice: 0.9583\n","2024-07-18 14:29:47.053446: \n","2024-07-18 14:29:47.053872: Epoch 522\n","2024-07-18 14:29:47.054029: Current learning rate: 0.00515\n","2024-07-18 14:31:29.424789: train_loss -0.7133\n","2024-07-18 14:31:29.425058: val_loss -0.6843\n","2024-07-18 14:31:29.425160: Pseudo dice [0.9664]\n","2024-07-18 14:31:29.425254: Epoch time: 102.38 s\n","2024-07-18 14:31:29.425341: Yayy! New best EMA pseudo Dice: 0.9592\n","2024-07-18 14:31:32.901842: \n","2024-07-18 14:31:32.902253: Epoch 523\n","2024-07-18 14:31:32.902394: Current learning rate: 0.00514\n","2024-07-18 14:33:14.858722: train_loss -0.6723\n","2024-07-18 14:33:14.859047: val_loss -0.6776\n","2024-07-18 14:33:14.859206: Pseudo dice [0.964]\n","2024-07-18 14:33:14.859318: Epoch time: 101.96 s\n","2024-07-18 14:33:14.859404: Yayy! New best EMA pseudo Dice: 0.9596\n","2024-07-18 14:33:18.430655: \n","2024-07-18 14:33:18.431131: Epoch 524\n","2024-07-18 14:33:18.431315: Current learning rate: 0.00513\n","2024-07-18 14:35:00.131509: train_loss -0.6911\n","2024-07-18 14:35:00.131877: val_loss -0.7266\n","2024-07-18 14:35:00.132052: Pseudo dice [0.9653]\n","2024-07-18 14:35:00.132171: Epoch time: 101.7 s\n","2024-07-18 14:35:00.132276: Yayy! New best EMA pseudo Dice: 0.9602\n","2024-07-18 14:35:03.714031: \n","2024-07-18 14:35:03.714422: Epoch 525\n","2024-07-18 14:35:03.714563: Current learning rate: 0.00512\n","2024-07-18 14:36:45.400494: train_loss -0.6572\n","2024-07-18 14:36:45.400776: val_loss -0.5903\n","2024-07-18 14:36:45.400916: Pseudo dice [0.8473]\n","2024-07-18 14:36:45.401126: Epoch time: 101.69 s\n","2024-07-18 14:36:46.982048: \n","2024-07-18 14:36:46.982466: Epoch 526\n","2024-07-18 14:36:46.982645: Current learning rate: 0.00511\n","2024-07-18 14:38:28.743318: train_loss -0.6446\n","2024-07-18 14:38:28.743578: val_loss -0.695\n","2024-07-18 14:38:28.743681: Pseudo dice [0.958]\n","2024-07-18 14:38:28.743790: Epoch time: 101.77 s\n","2024-07-18 14:38:30.306708: \n","2024-07-18 14:38:30.307088: Epoch 527\n","2024-07-18 14:38:30.307222: Current learning rate: 0.0051\n","2024-07-18 14:40:12.184117: train_loss -0.6798\n","2024-07-18 14:40:12.184411: val_loss -0.6524\n","2024-07-18 14:40:12.184621: Pseudo dice [0.9495]\n","2024-07-18 14:40:12.184757: Epoch time: 101.88 s\n","2024-07-18 14:40:13.820093: \n","2024-07-18 14:40:13.820456: Epoch 528\n","2024-07-18 14:40:13.820607: Current learning rate: 0.00509\n","2024-07-18 14:41:55.933723: train_loss -0.6616\n","2024-07-18 14:41:55.934012: val_loss -0.7025\n","2024-07-18 14:41:55.934169: Pseudo dice [0.9525]\n","2024-07-18 14:41:55.934266: Epoch time: 102.12 s\n","2024-07-18 14:41:57.475647: \n","2024-07-18 14:41:57.476095: Epoch 529\n","2024-07-18 14:41:57.476248: Current learning rate: 0.00508\n","2024-07-18 14:43:39.262143: train_loss -0.6923\n","2024-07-18 14:43:39.262534: val_loss -0.6955\n","2024-07-18 14:43:39.262646: Pseudo dice [0.9577]\n","2024-07-18 14:43:39.262740: Epoch time: 101.79 s\n","2024-07-18 14:43:40.839478: \n","2024-07-18 14:43:40.839838: Epoch 530\n","2024-07-18 14:43:40.840032: Current learning rate: 0.00507\n","2024-07-18 14:45:22.608889: train_loss -0.674\n","2024-07-18 14:45:22.609383: val_loss -0.7146\n","2024-07-18 14:45:22.609518: Pseudo dice [0.9609]\n","2024-07-18 14:45:22.609638: Epoch time: 101.77 s\n","2024-07-18 14:45:24.125967: \n","2024-07-18 14:45:24.126349: Epoch 531\n","2024-07-18 14:45:24.126518: Current learning rate: 0.00506\n","2024-07-18 14:47:05.811055: train_loss -0.6864\n","2024-07-18 14:47:05.811436: val_loss -0.7478\n","2024-07-18 14:47:05.811583: Pseudo dice [0.9569]\n","2024-07-18 14:47:05.811708: Epoch time: 101.69 s\n","2024-07-18 14:47:07.508816: \n","2024-07-18 14:47:07.509203: Epoch 532\n","2024-07-18 14:47:07.509362: Current learning rate: 0.00505\n","2024-07-18 14:48:49.294734: train_loss -0.6876\n","2024-07-18 14:48:49.295005: val_loss -0.6941\n","2024-07-18 14:48:49.295108: Pseudo dice [0.9428]\n","2024-07-18 14:48:49.295203: Epoch time: 101.79 s\n","2024-07-18 14:48:50.838609: \n","2024-07-18 14:48:50.839107: Epoch 533\n","2024-07-18 14:48:50.839268: Current learning rate: 0.00504\n","2024-07-18 14:50:32.420040: train_loss -0.6878\n","2024-07-18 14:50:32.420539: val_loss -0.7154\n","2024-07-18 14:50:32.420685: Pseudo dice [0.9525]\n","2024-07-18 14:50:32.420790: Epoch time: 101.59 s\n","2024-07-18 14:50:34.068141: \n","2024-07-18 14:50:34.068613: Epoch 534\n","2024-07-18 14:50:34.068826: Current learning rate: 0.00503\n","2024-07-18 14:52:15.826845: train_loss -0.6847\n","2024-07-18 14:52:15.827165: val_loss -0.6656\n","2024-07-18 14:52:15.827312: Pseudo dice [0.9364]\n","2024-07-18 14:52:15.827429: Epoch time: 101.76 s\n","2024-07-18 14:52:17.488994: \n","2024-07-18 14:52:17.489364: Epoch 535\n","2024-07-18 14:52:17.489512: Current learning rate: 0.00502\n","2024-07-18 14:53:59.925342: train_loss -0.6785\n","2024-07-18 14:53:59.925594: val_loss -0.7666\n","2024-07-18 14:53:59.925840: Pseudo dice [0.9499]\n","2024-07-18 14:53:59.925977: Epoch time: 102.44 s\n","2024-07-18 14:54:01.483971: \n","2024-07-18 14:54:01.484384: Epoch 536\n","2024-07-18 14:54:01.484560: Current learning rate: 0.00501\n","2024-07-18 14:55:43.376877: train_loss -0.6691\n","2024-07-18 14:55:43.377210: val_loss -0.7543\n","2024-07-18 14:55:43.377315: Pseudo dice [0.9307]\n","2024-07-18 14:55:43.377426: Epoch time: 101.9 s\n","2024-07-18 14:55:44.912298: \n","2024-07-18 14:55:44.912631: Epoch 537\n","2024-07-18 14:55:44.912770: Current learning rate: 0.005\n","2024-07-18 14:57:26.562662: train_loss -0.6791\n","2024-07-18 14:57:26.562956: val_loss -0.6414\n","2024-07-18 14:57:26.563107: Pseudo dice [0.9541]\n","2024-07-18 14:57:26.563328: Epoch time: 101.65 s\n","2024-07-18 14:57:28.163958: \n","2024-07-18 14:57:28.164341: Epoch 538\n","2024-07-18 14:57:28.164518: Current learning rate: 0.00499\n","2024-07-18 14:59:09.777527: train_loss -0.6713\n","2024-07-18 14:59:09.777781: val_loss -0.7433\n","2024-07-18 14:59:09.777899: Pseudo dice [0.959]\n","2024-07-18 14:59:09.778185: Epoch time: 101.62 s\n","2024-07-18 14:59:11.326018: \n","2024-07-18 14:59:11.326382: Epoch 539\n","2024-07-18 14:59:11.326529: Current learning rate: 0.00498\n","2024-07-18 15:00:53.343472: train_loss -0.7001\n","2024-07-18 15:00:53.343948: val_loss -0.6619\n","2024-07-18 15:00:53.344117: Pseudo dice [0.9555]\n","2024-07-18 15:00:53.344240: Epoch time: 102.02 s\n","2024-07-18 15:00:54.871802: \n","2024-07-18 15:00:54.872277: Epoch 540\n","2024-07-18 15:00:54.872452: Current learning rate: 0.00497\n","2024-07-18 15:02:36.595549: train_loss -0.679\n","2024-07-18 15:02:36.595789: val_loss -0.636\n","2024-07-18 15:02:36.596015: Pseudo dice [0.9563]\n","2024-07-18 15:02:36.596128: Epoch time: 101.73 s\n","2024-07-18 15:02:38.208949: \n","2024-07-18 15:02:38.209296: Epoch 541\n","2024-07-18 15:02:38.209465: Current learning rate: 0.00496\n","2024-07-18 15:04:19.948785: train_loss -0.6864\n","2024-07-18 15:04:19.949071: val_loss -0.6738\n","2024-07-18 15:04:19.949184: Pseudo dice [0.9635]\n","2024-07-18 15:04:19.949281: Epoch time: 101.74 s\n","2024-07-18 15:04:21.471052: \n","2024-07-18 15:04:21.471345: Epoch 542\n","2024-07-18 15:04:21.471492: Current learning rate: 0.00495\n","2024-07-18 15:06:03.844586: train_loss -0.6745\n","2024-07-18 15:06:03.844900: val_loss -0.675\n","2024-07-18 15:06:03.845061: Pseudo dice [0.9325]\n","2024-07-18 15:06:03.845190: Epoch time: 102.38 s\n","2024-07-18 15:06:05.403604: \n","2024-07-18 15:06:05.403975: Epoch 543\n","2024-07-18 15:06:05.404121: Current learning rate: 0.00494\n","2024-07-18 15:07:47.198136: train_loss -0.6812\n","2024-07-18 15:07:47.198381: val_loss -0.7631\n","2024-07-18 15:07:47.198486: Pseudo dice [0.9638]\n","2024-07-18 15:07:47.198582: Epoch time: 101.8 s\n","2024-07-18 15:07:48.880246: \n","2024-07-18 15:07:48.880570: Epoch 544\n","2024-07-18 15:07:48.880733: Current learning rate: 0.00493\n","2024-07-18 15:09:30.601762: train_loss -0.6887\n","2024-07-18 15:09:30.602090: val_loss -0.7385\n","2024-07-18 15:09:30.602237: Pseudo dice [0.9439]\n","2024-07-18 15:09:30.602344: Epoch time: 101.73 s\n","2024-07-18 15:09:32.147804: \n","2024-07-18 15:09:32.148278: Epoch 545\n","2024-07-18 15:09:32.148436: Current learning rate: 0.00492\n","2024-07-18 15:11:13.739851: train_loss -0.6946\n","2024-07-18 15:11:13.740139: val_loss -0.7091\n","2024-07-18 15:11:13.740240: Pseudo dice [0.9538]\n","2024-07-18 15:11:13.740362: Epoch time: 101.6 s\n","2024-07-18 15:11:15.301808: \n","2024-07-18 15:11:15.302181: Epoch 546\n","2024-07-18 15:11:15.302361: Current learning rate: 0.00491\n","2024-07-18 15:12:57.087548: train_loss -0.6909\n","2024-07-18 15:12:57.087855: val_loss -0.6552\n","2024-07-18 15:12:57.088092: Pseudo dice [0.9525]\n","2024-07-18 15:12:57.088222: Epoch time: 101.79 s\n","2024-07-18 15:12:58.667327: \n","2024-07-18 15:12:58.667744: Epoch 547\n","2024-07-18 15:12:58.667879: Current learning rate: 0.0049\n","2024-07-18 15:14:40.498440: train_loss -0.6773\n","2024-07-18 15:14:40.498688: val_loss -0.6949\n","2024-07-18 15:14:40.498864: Pseudo dice [0.9254]\n","2024-07-18 15:14:40.499022: Epoch time: 101.84 s\n","2024-07-18 15:14:42.033827: \n","2024-07-18 15:14:42.034260: Epoch 548\n","2024-07-18 15:14:42.034399: Current learning rate: 0.00489\n","2024-07-18 15:16:23.870645: train_loss -0.6842\n","2024-07-18 15:16:23.870902: val_loss -0.6862\n","2024-07-18 15:16:23.871059: Pseudo dice [0.9515]\n","2024-07-18 15:16:23.871164: Epoch time: 101.84 s\n","2024-07-18 15:16:25.427886: \n","2024-07-18 15:16:25.428298: Epoch 549\n","2024-07-18 15:16:25.428452: Current learning rate: 0.00488\n","2024-07-18 15:18:07.655198: train_loss -0.6832\n","2024-07-18 15:18:07.655434: val_loss -0.6972\n","2024-07-18 15:18:07.655529: Pseudo dice [0.9628]\n","2024-07-18 15:18:07.655617: Epoch time: 102.23 s\n","2024-07-18 15:18:11.198014: \n","2024-07-18 15:18:11.198460: Epoch 550\n","2024-07-18 15:18:11.198615: Current learning rate: 0.00487\n","2024-07-18 15:19:52.949677: train_loss -0.691\n","2024-07-18 15:19:52.949977: val_loss -0.695\n","2024-07-18 15:19:52.950104: Pseudo dice [0.9654]\n","2024-07-18 15:19:52.950203: Epoch time: 101.76 s\n","2024-07-18 15:19:54.512698: \n","2024-07-18 15:19:54.513122: Epoch 551\n","2024-07-18 15:19:54.513268: Current learning rate: 0.00486\n","2024-07-18 15:21:36.283189: train_loss -0.659\n","2024-07-18 15:21:36.283450: val_loss -0.6541\n","2024-07-18 15:21:36.283560: Pseudo dice [0.9591]\n","2024-07-18 15:21:36.283657: Epoch time: 101.77 s\n","2024-07-18 15:21:37.829860: \n","2024-07-18 15:21:37.830209: Epoch 552\n","2024-07-18 15:21:37.830368: Current learning rate: 0.00485\n","2024-07-18 15:23:19.501363: train_loss -0.6614\n","2024-07-18 15:23:19.501639: val_loss -0.7241\n","2024-07-18 15:23:19.501747: Pseudo dice [0.9522]\n","2024-07-18 15:23:19.502067: Epoch time: 101.68 s\n","2024-07-18 15:23:21.088151: \n","2024-07-18 15:23:21.088462: Epoch 553\n","2024-07-18 15:23:21.088618: Current learning rate: 0.00484\n","2024-07-18 15:25:02.914557: train_loss -0.6413\n","2024-07-18 15:25:02.914808: val_loss -0.696\n","2024-07-18 15:25:02.914985: Pseudo dice [0.9632]\n","2024-07-18 15:25:02.915111: Epoch time: 101.83 s\n","2024-07-18 15:25:04.488672: \n","2024-07-18 15:25:04.489041: Epoch 554\n","2024-07-18 15:25:04.489218: Current learning rate: 0.00484\n","2024-07-18 15:26:46.272603: train_loss -0.6803\n","2024-07-18 15:26:46.272847: val_loss -0.6587\n","2024-07-18 15:26:46.273176: Pseudo dice [0.9536]\n","2024-07-18 15:26:46.273396: Epoch time: 101.79 s\n","2024-07-18 15:26:47.829406: \n","2024-07-18 15:26:47.829744: Epoch 555\n","2024-07-18 15:26:47.829891: Current learning rate: 0.00483\n","2024-07-18 15:28:29.573023: train_loss -0.6645\n","2024-07-18 15:28:29.573309: val_loss -0.6997\n","2024-07-18 15:28:29.573407: Pseudo dice [0.9695]\n","2024-07-18 15:28:29.573509: Epoch time: 101.75 s\n","2024-07-18 15:28:31.113863: \n","2024-07-18 15:28:31.114207: Epoch 556\n","2024-07-18 15:28:31.114342: Current learning rate: 0.00482\n","2024-07-18 15:30:13.541626: train_loss -0.6691\n","2024-07-18 15:30:13.542044: val_loss -0.7482\n","2024-07-18 15:30:13.542231: Pseudo dice [0.9681]\n","2024-07-18 15:30:13.542336: Epoch time: 102.43 s\n","2024-07-18 15:30:15.156360: \n","2024-07-18 15:30:15.156759: Epoch 557\n","2024-07-18 15:30:15.156895: Current learning rate: 0.00481\n","2024-07-18 15:31:56.849157: train_loss -0.6536\n","2024-07-18 15:31:56.849585: val_loss -0.6707\n","2024-07-18 15:31:56.849708: Pseudo dice [0.9501]\n","2024-07-18 15:31:56.849804: Epoch time: 101.7 s\n","2024-07-18 15:31:58.365008: \n","2024-07-18 15:31:58.365411: Epoch 558\n","2024-07-18 15:31:58.365549: Current learning rate: 0.0048\n","2024-07-18 15:33:40.148319: train_loss -0.6979\n","2024-07-18 15:33:40.148597: val_loss -0.6743\n","2024-07-18 15:33:40.148697: Pseudo dice [0.9537]\n","2024-07-18 15:33:40.148884: Epoch time: 101.79 s\n","2024-07-18 15:33:41.705471: \n","2024-07-18 15:33:41.705880: Epoch 559\n","2024-07-18 15:33:41.706065: Current learning rate: 0.00479\n","2024-07-18 15:35:23.430714: train_loss -0.6727\n","2024-07-18 15:35:23.430997: val_loss -0.7374\n","2024-07-18 15:35:23.431118: Pseudo dice [0.96]\n","2024-07-18 15:35:23.431215: Epoch time: 101.73 s\n","2024-07-18 15:35:25.086738: \n","2024-07-18 15:35:25.087113: Epoch 560\n","2024-07-18 15:35:25.087276: Current learning rate: 0.00478\n","2024-07-18 15:37:06.952550: train_loss -0.6611\n","2024-07-18 15:37:06.952864: val_loss -0.5801\n","2024-07-18 15:37:06.953037: Pseudo dice [0.9022]\n","2024-07-18 15:37:06.953173: Epoch time: 101.87 s\n","2024-07-18 15:37:08.498126: \n","2024-07-18 15:37:08.498504: Epoch 561\n","2024-07-18 15:37:08.498673: Current learning rate: 0.00477\n","2024-07-18 15:38:50.628889: train_loss -0.6843\n","2024-07-18 15:38:50.629182: val_loss -0.7456\n","2024-07-18 15:38:50.629289: Pseudo dice [0.9332]\n","2024-07-18 15:38:50.629399: Epoch time: 102.13 s\n","2024-07-18 15:38:52.169763: \n","2024-07-18 15:38:52.170168: Epoch 562\n","2024-07-18 15:38:52.170309: Current learning rate: 0.00476\n","2024-07-18 15:40:34.018133: train_loss -0.6658\n","2024-07-18 15:40:34.018393: val_loss -0.7121\n","2024-07-18 15:40:34.018499: Pseudo dice [0.9616]\n","2024-07-18 15:40:34.018594: Epoch time: 101.85 s\n","2024-07-18 15:40:35.590242: \n","2024-07-18 15:40:35.590599: Epoch 563\n","2024-07-18 15:40:35.590758: Current learning rate: 0.00475\n","2024-07-18 15:42:17.943446: train_loss -0.6635\n","2024-07-18 15:42:17.943704: val_loss -0.7008\n","2024-07-18 15:42:17.943804: Pseudo dice [0.963]\n","2024-07-18 15:42:17.943900: Epoch time: 102.36 s\n","2024-07-18 15:42:19.492745: \n","2024-07-18 15:42:19.493173: Epoch 564\n","2024-07-18 15:42:19.493339: Current learning rate: 0.00474\n","2024-07-18 15:44:01.329569: train_loss -0.6787\n","2024-07-18 15:44:01.329856: val_loss -0.6755\n","2024-07-18 15:44:01.330002: Pseudo dice [0.9551]\n","2024-07-18 15:44:01.330127: Epoch time: 101.84 s\n","2024-07-18 15:44:02.922255: \n","2024-07-18 15:44:02.922696: Epoch 565\n","2024-07-18 15:44:02.922846: Current learning rate: 0.00473\n","2024-07-18 15:45:44.796701: train_loss -0.6855\n","2024-07-18 15:45:44.796997: val_loss -0.7583\n","2024-07-18 15:45:44.797165: Pseudo dice [0.9666]\n","2024-07-18 15:45:44.797402: Epoch time: 101.88 s\n","2024-07-18 15:45:46.434171: \n","2024-07-18 15:45:46.434553: Epoch 566\n","2024-07-18 15:45:46.434691: Current learning rate: 0.00472\n","2024-07-18 15:47:28.226393: train_loss -0.6776\n","2024-07-18 15:47:28.226641: val_loss -0.7383\n","2024-07-18 15:47:28.226739: Pseudo dice [0.9652]\n","2024-07-18 15:47:28.226849: Epoch time: 101.8 s\n","2024-07-18 15:47:29.774540: \n","2024-07-18 15:47:29.774948: Epoch 567\n","2024-07-18 15:47:29.775095: Current learning rate: 0.00471\n","2024-07-18 15:49:11.500283: train_loss -0.6995\n","2024-07-18 15:49:11.500541: val_loss -0.79\n","2024-07-18 15:49:11.500678: Pseudo dice [0.9656]\n","2024-07-18 15:49:11.500781: Epoch time: 101.73 s\n","2024-07-18 15:49:13.047415: \n","2024-07-18 15:49:13.047769: Epoch 568\n","2024-07-18 15:49:13.047995: Current learning rate: 0.0047\n","2024-07-18 15:50:54.918550: train_loss -0.6683\n","2024-07-18 15:50:54.918799: val_loss -0.6315\n","2024-07-18 15:50:54.918902: Pseudo dice [0.9575]\n","2024-07-18 15:50:54.919052: Epoch time: 101.88 s\n","2024-07-18 15:50:56.569345: \n","2024-07-18 15:50:56.569797: Epoch 569\n","2024-07-18 15:50:56.569978: Current learning rate: 0.00469\n","2024-07-18 15:52:38.308297: train_loss -0.6805\n","2024-07-18 15:52:38.308583: val_loss -0.6999\n","2024-07-18 15:52:38.308688: Pseudo dice [0.9597]\n","2024-07-18 15:52:38.308784: Epoch time: 101.74 s\n","2024-07-18 15:52:39.843452: \n","2024-07-18 15:52:39.843885: Epoch 570\n","2024-07-18 15:52:39.844048: Current learning rate: 0.00468\n","2024-07-18 15:54:22.280200: train_loss -0.6661\n","2024-07-18 15:54:22.280449: val_loss -0.7205\n","2024-07-18 15:54:22.280550: Pseudo dice [0.9495]\n","2024-07-18 15:54:22.280646: Epoch time: 102.44 s\n","2024-07-18 15:54:23.812096: \n","2024-07-18 15:54:23.812477: Epoch 571\n","2024-07-18 15:54:23.812616: Current learning rate: 0.00467\n","2024-07-18 15:56:05.791702: train_loss -0.6506\n","2024-07-18 15:56:05.792010: val_loss -0.7224\n","2024-07-18 15:56:05.792170: Pseudo dice [0.9512]\n","2024-07-18 15:56:05.792288: Epoch time: 101.98 s\n","2024-07-18 15:56:07.418583: \n","2024-07-18 15:56:07.419038: Epoch 572\n","2024-07-18 15:56:07.419217: Current learning rate: 0.00466\n","2024-07-18 15:57:49.121113: train_loss -0.696\n","2024-07-18 15:57:49.121341: val_loss -0.6946\n","2024-07-18 15:57:49.121443: Pseudo dice [0.9639]\n","2024-07-18 15:57:49.121540: Epoch time: 101.71 s\n","2024-07-18 15:57:50.755598: \n","2024-07-18 15:57:50.756005: Epoch 573\n","2024-07-18 15:57:50.756173: Current learning rate: 0.00465\n","2024-07-18 15:59:32.693919: train_loss -0.6718\n","2024-07-18 15:59:32.694245: val_loss -0.7218\n","2024-07-18 15:59:32.694382: Pseudo dice [0.9459]\n","2024-07-18 15:59:32.694491: Epoch time: 101.94 s\n","2024-07-18 15:59:34.245816: \n","2024-07-18 15:59:34.246270: Epoch 574\n","2024-07-18 15:59:34.246414: Current learning rate: 0.00464\n","2024-07-18 16:01:16.040429: train_loss -0.6754\n","2024-07-18 16:01:16.040702: val_loss -0.78\n","2024-07-18 16:01:16.040803: Pseudo dice [0.957]\n","2024-07-18 16:01:16.040905: Epoch time: 101.8 s\n","2024-07-18 16:01:17.652762: \n","2024-07-18 16:01:17.653162: Epoch 575\n","2024-07-18 16:01:17.653330: Current learning rate: 0.00463\n","2024-07-18 16:02:59.535407: train_loss -0.6979\n","2024-07-18 16:02:59.535709: val_loss -0.7229\n","2024-07-18 16:02:59.535884: Pseudo dice [0.9619]\n","2024-07-18 16:02:59.536108: Epoch time: 101.89 s\n","2024-07-18 16:03:01.296957: \n","2024-07-18 16:03:01.297350: Epoch 576\n","2024-07-18 16:03:01.297489: Current learning rate: 0.00462\n","2024-07-18 16:04:43.105682: train_loss -0.6507\n","2024-07-18 16:04:43.106282: val_loss -0.7269\n","2024-07-18 16:04:43.106407: Pseudo dice [0.9545]\n","2024-07-18 16:04:43.106499: Epoch time: 101.81 s\n","2024-07-18 16:04:44.675845: \n","2024-07-18 16:04:44.676205: Epoch 577\n","2024-07-18 16:04:44.676350: Current learning rate: 0.00461\n","2024-07-18 16:06:27.040639: train_loss -0.6917\n","2024-07-18 16:06:27.041357: val_loss -0.7112\n","2024-07-18 16:06:27.041488: Pseudo dice [0.9625]\n","2024-07-18 16:06:27.041582: Epoch time: 102.37 s\n","2024-07-18 16:06:28.639911: \n","2024-07-18 16:06:28.640362: Epoch 578\n","2024-07-18 16:06:28.640512: Current learning rate: 0.0046\n","2024-07-18 16:08:10.580883: train_loss -0.657\n","2024-07-18 16:08:10.581204: val_loss -0.7037\n","2024-07-18 16:08:10.581311: Pseudo dice [0.9598]\n","2024-07-18 16:08:10.581424: Epoch time: 101.94 s\n","2024-07-18 16:08:12.189976: \n","2024-07-18 16:08:12.190416: Epoch 579\n","2024-07-18 16:08:12.190578: Current learning rate: 0.00459\n","2024-07-18 16:09:54.058823: train_loss -0.6897\n","2024-07-18 16:09:54.059137: val_loss -0.6848\n","2024-07-18 16:09:54.059241: Pseudo dice [0.9624]\n","2024-07-18 16:09:54.059336: Epoch time: 101.87 s\n","2024-07-18 16:09:55.691972: \n","2024-07-18 16:09:55.692392: Epoch 580\n","2024-07-18 16:09:55.692549: Current learning rate: 0.00458\n","2024-07-18 16:11:37.683810: train_loss -0.69\n","2024-07-18 16:11:37.684106: val_loss -0.6397\n","2024-07-18 16:11:37.684239: Pseudo dice [0.9473]\n","2024-07-18 16:11:37.684435: Epoch time: 102.0 s\n","2024-07-18 16:11:39.281949: \n","2024-07-18 16:11:39.282347: Epoch 581\n","2024-07-18 16:11:39.282485: Current learning rate: 0.00457\n","2024-07-18 16:13:21.149155: train_loss -0.6351\n","2024-07-18 16:13:21.149458: val_loss -0.6813\n","2024-07-18 16:13:21.149568: Pseudo dice [0.9419]\n","2024-07-18 16:13:21.149710: Epoch time: 101.87 s\n","2024-07-18 16:13:22.723572: \n","2024-07-18 16:13:22.724017: Epoch 582\n","2024-07-18 16:13:22.724162: Current learning rate: 0.00456\n","2024-07-18 16:15:04.496165: train_loss -0.6543\n","2024-07-18 16:15:04.496426: val_loss -0.6994\n","2024-07-18 16:15:04.496528: Pseudo dice [0.9671]\n","2024-07-18 16:15:04.496623: Epoch time: 101.78 s\n","2024-07-18 16:15:06.072049: \n","2024-07-18 16:15:06.072391: Epoch 583\n","2024-07-18 16:15:06.072530: Current learning rate: 0.00455\n","2024-07-18 16:16:47.919414: train_loss -0.7064\n","2024-07-18 16:16:47.919753: val_loss -0.6695\n","2024-07-18 16:16:47.919888: Pseudo dice [0.9355]\n","2024-07-18 16:16:47.920009: Epoch time: 101.85 s\n","2024-07-18 16:16:49.489979: \n","2024-07-18 16:16:49.490391: Epoch 584\n","2024-07-18 16:16:49.490533: Current learning rate: 0.00454\n","2024-07-18 16:18:31.892232: train_loss -0.7012\n","2024-07-18 16:18:31.892486: val_loss -0.6998\n","2024-07-18 16:18:31.892586: Pseudo dice [0.956]\n","2024-07-18 16:18:31.892680: Epoch time: 102.41 s\n","2024-07-18 16:18:33.513501: \n","2024-07-18 16:18:33.513799: Epoch 585\n","2024-07-18 16:18:33.513985: Current learning rate: 0.00453\n","2024-07-18 16:20:15.435594: train_loss -0.7005\n","2024-07-18 16:20:15.435853: val_loss -0.7245\n","2024-07-18 16:20:15.436069: Pseudo dice [0.9492]\n","2024-07-18 16:20:15.436360: Epoch time: 101.93 s\n","2024-07-18 16:20:17.061561: \n","2024-07-18 16:20:17.061942: Epoch 586\n","2024-07-18 16:20:17.062085: Current learning rate: 0.00452\n","2024-07-18 16:21:58.855785: train_loss -0.695\n","2024-07-18 16:21:58.856054: val_loss -0.7265\n","2024-07-18 16:21:58.856152: Pseudo dice [0.9692]\n","2024-07-18 16:21:58.856248: Epoch time: 101.8 s\n","2024-07-18 16:22:00.451287: \n","2024-07-18 16:22:00.451755: Epoch 587\n","2024-07-18 16:22:00.451902: Current learning rate: 0.00451\n","2024-07-18 16:23:42.279326: train_loss -0.695\n","2024-07-18 16:23:42.279579: val_loss -0.7138\n","2024-07-18 16:23:42.279685: Pseudo dice [0.9663]\n","2024-07-18 16:23:42.279782: Epoch time: 101.83 s\n","2024-07-18 16:23:43.829437: \n","2024-07-18 16:23:43.829842: Epoch 588\n","2024-07-18 16:23:43.829993: Current learning rate: 0.0045\n","2024-07-18 16:25:25.689579: train_loss -0.6675\n","2024-07-18 16:25:25.689910: val_loss -0.726\n","2024-07-18 16:25:25.690058: Pseudo dice [0.9604]\n","2024-07-18 16:25:25.690170: Epoch time: 101.86 s\n","2024-07-18 16:25:27.292259: \n","2024-07-18 16:25:27.292849: Epoch 589\n","2024-07-18 16:25:27.293024: Current learning rate: 0.00449\n","2024-07-18 16:27:09.196580: train_loss -0.691\n","2024-07-18 16:27:09.196836: val_loss -0.6943\n","2024-07-18 16:27:09.196961: Pseudo dice [0.9626]\n","2024-07-18 16:27:09.197066: Epoch time: 101.91 s\n","2024-07-18 16:27:10.820106: \n","2024-07-18 16:27:10.820441: Epoch 590\n","2024-07-18 16:27:10.820583: Current learning rate: 0.00448\n","2024-07-18 16:28:52.666029: train_loss -0.673\n","2024-07-18 16:28:52.666297: val_loss -0.6309\n","2024-07-18 16:28:52.666403: Pseudo dice [0.9482]\n","2024-07-18 16:28:52.666502: Epoch time: 101.85 s\n","2024-07-18 16:28:54.254587: \n","2024-07-18 16:28:54.255006: Epoch 591\n","2024-07-18 16:28:54.255160: Current learning rate: 0.00447\n","2024-07-18 16:30:36.571394: train_loss -0.6839\n","2024-07-18 16:30:36.571882: val_loss -0.7212\n","2024-07-18 16:30:36.572032: Pseudo dice [0.9521]\n","2024-07-18 16:30:36.572173: Epoch time: 102.32 s\n","2024-07-18 16:30:38.232225: \n","2024-07-18 16:30:38.232629: Epoch 592\n","2024-07-18 16:30:38.232800: Current learning rate: 0.00446\n","2024-07-18 16:32:20.087291: train_loss -0.694\n","2024-07-18 16:32:20.087518: val_loss -0.6946\n","2024-07-18 16:32:20.087620: Pseudo dice [0.9637]\n","2024-07-18 16:32:20.087776: Epoch time: 101.86 s\n","2024-07-18 16:32:21.674345: \n","2024-07-18 16:32:21.674674: Epoch 593\n","2024-07-18 16:32:21.674815: Current learning rate: 0.00445\n","2024-07-18 16:34:03.459754: train_loss -0.6606\n","2024-07-18 16:34:03.460081: val_loss -0.7018\n","2024-07-18 16:34:03.460200: Pseudo dice [0.9658]\n","2024-07-18 16:34:03.460306: Epoch time: 101.79 s\n","2024-07-18 16:34:05.035748: \n","2024-07-18 16:34:05.036211: Epoch 594\n","2024-07-18 16:34:05.036363: Current learning rate: 0.00444\n","2024-07-18 16:35:46.870371: train_loss -0.6867\n","2024-07-18 16:35:46.870625: val_loss -0.6616\n","2024-07-18 16:35:46.870725: Pseudo dice [0.9509]\n","2024-07-18 16:35:46.870917: Epoch time: 101.84 s\n","2024-07-18 16:35:48.445975: \n","2024-07-18 16:35:48.446423: Epoch 595\n","2024-07-18 16:35:48.446587: Current learning rate: 0.00443\n","2024-07-18 16:37:30.172623: train_loss -0.6589\n","2024-07-18 16:37:30.172985: val_loss -0.6837\n","2024-07-18 16:37:30.173135: Pseudo dice [0.9636]\n","2024-07-18 16:37:30.173248: Epoch time: 101.73 s\n","2024-07-18 16:37:31.814397: \n","2024-07-18 16:37:31.814799: Epoch 596\n","2024-07-18 16:37:31.814975: Current learning rate: 0.00442\n","2024-07-18 16:39:13.607457: train_loss -0.6842\n","2024-07-18 16:39:13.607752: val_loss -0.7018\n","2024-07-18 16:39:13.608021: Pseudo dice [0.9611]\n","2024-07-18 16:39:13.608133: Epoch time: 101.8 s\n","2024-07-18 16:39:15.147244: \n","2024-07-18 16:39:15.147643: Epoch 597\n","2024-07-18 16:39:15.147781: Current learning rate: 0.00441\n","2024-07-18 16:40:56.916136: train_loss -0.6679\n","2024-07-18 16:40:56.916409: val_loss -0.6576\n","2024-07-18 16:40:56.916509: Pseudo dice [0.9628]\n","2024-07-18 16:40:56.916603: Epoch time: 101.77 s\n","2024-07-18 16:40:58.496639: \n","2024-07-18 16:40:58.497018: Epoch 598\n","2024-07-18 16:40:58.497158: Current learning rate: 0.0044\n","2024-07-18 16:42:40.817707: train_loss -0.6503\n","2024-07-18 16:42:40.817997: val_loss -0.6879\n","2024-07-18 16:42:40.818128: Pseudo dice [0.9635]\n","2024-07-18 16:42:40.818284: Epoch time: 102.33 s\n","2024-07-18 16:42:42.412407: \n","2024-07-18 16:42:42.412822: Epoch 599\n","2024-07-18 16:42:42.412986: Current learning rate: 0.00439\n","2024-07-18 16:44:24.157543: train_loss -0.6899\n","2024-07-18 16:44:24.157940: val_loss -0.7235\n","2024-07-18 16:44:24.158116: Pseudo dice [0.9548]\n","2024-07-18 16:44:24.158241: Epoch time: 101.75 s\n","2024-07-18 16:44:27.785139: \n","2024-07-18 16:44:27.785562: Epoch 600\n","2024-07-18 16:44:27.785707: Current learning rate: 0.00438\n","2024-07-18 16:46:09.470980: train_loss -0.6622\n","2024-07-18 16:46:09.471232: val_loss -0.6641\n","2024-07-18 16:46:09.471334: Pseudo dice [0.9584]\n","2024-07-18 16:46:09.471442: Epoch time: 101.69 s\n","2024-07-18 16:46:11.064282: \n","2024-07-18 16:46:11.064644: Epoch 601\n","2024-07-18 16:46:11.064796: Current learning rate: 0.00437\n","2024-07-18 16:47:53.036160: train_loss -0.7083\n","2024-07-18 16:47:53.036446: val_loss -0.7595\n","2024-07-18 16:47:53.036649: Pseudo dice [0.9578]\n","2024-07-18 16:47:53.036762: Epoch time: 101.98 s\n","2024-07-18 16:47:54.676557: \n","2024-07-18 16:47:54.677033: Epoch 602\n","2024-07-18 16:47:54.677195: Current learning rate: 0.00436\n","2024-07-18 16:49:36.671071: train_loss -0.6527\n","2024-07-18 16:49:36.671332: val_loss -0.6986\n","2024-07-18 16:49:36.671434: Pseudo dice [0.9647]\n","2024-07-18 16:49:36.671527: Epoch time: 102.0 s\n","2024-07-18 16:49:38.296724: \n","2024-07-18 16:49:38.297149: Epoch 603\n","2024-07-18 16:49:38.297298: Current learning rate: 0.00435\n","2024-07-18 16:51:20.309660: train_loss -0.6772\n","2024-07-18 16:51:20.310052: val_loss -0.6759\n","2024-07-18 16:51:20.310173: Pseudo dice [0.9361]\n","2024-07-18 16:51:20.310277: Epoch time: 102.02 s\n","2024-07-18 16:51:21.918980: \n","2024-07-18 16:51:21.919466: Epoch 604\n","2024-07-18 16:51:21.919622: Current learning rate: 0.00434\n","2024-07-18 16:53:04.084883: train_loss -0.7062\n","2024-07-18 16:53:04.085286: val_loss -0.7206\n","2024-07-18 16:53:04.085412: Pseudo dice [0.9565]\n","2024-07-18 16:53:04.085520: Epoch time: 102.17 s\n","2024-07-18 16:53:05.698168: \n","2024-07-18 16:53:05.698604: Epoch 605\n","2024-07-18 16:53:05.698755: Current learning rate: 0.00433\n","2024-07-18 16:54:48.320477: train_loss -0.6827\n","2024-07-18 16:54:48.320792: val_loss -0.6594\n","2024-07-18 16:54:48.320903: Pseudo dice [0.9366]\n","2024-07-18 16:54:48.321060: Epoch time: 102.63 s\n","2024-07-18 16:54:49.943099: \n","2024-07-18 16:54:49.943470: Epoch 606\n","2024-07-18 16:54:49.943644: Current learning rate: 0.00432\n","2024-07-18 16:56:31.941032: train_loss -0.6615\n","2024-07-18 16:56:31.941329: val_loss -0.7837\n","2024-07-18 16:56:31.941435: Pseudo dice [0.9525]\n","2024-07-18 16:56:31.941550: Epoch time: 102.0 s\n","2024-07-18 16:56:33.535456: \n","2024-07-18 16:56:33.535847: Epoch 607\n","2024-07-18 16:56:33.536021: Current learning rate: 0.00431\n","2024-07-18 16:58:15.460635: train_loss -0.6895\n","2024-07-18 16:58:15.460909: val_loss -0.7393\n","2024-07-18 16:58:15.461065: Pseudo dice [0.9588]\n","2024-07-18 16:58:15.461190: Epoch time: 101.93 s\n","2024-07-18 16:58:17.154761: \n","2024-07-18 16:58:17.155211: Epoch 608\n","2024-07-18 16:58:17.155360: Current learning rate: 0.0043\n","2024-07-18 16:59:58.908637: train_loss -0.6848\n","2024-07-18 16:59:58.909015: val_loss -0.6891\n","2024-07-18 16:59:58.909196: Pseudo dice [0.9355]\n","2024-07-18 16:59:58.909294: Epoch time: 101.76 s\n","2024-07-18 17:00:00.527157: \n","2024-07-18 17:00:00.527561: Epoch 609\n","2024-07-18 17:00:00.527709: Current learning rate: 0.00429\n","2024-07-18 17:01:42.460637: train_loss -0.6915\n","2024-07-18 17:01:42.460903: val_loss -0.6581\n","2024-07-18 17:01:42.461024: Pseudo dice [0.9481]\n","2024-07-18 17:01:42.461198: Epoch time: 101.94 s\n","2024-07-18 17:01:44.078700: \n","2024-07-18 17:01:44.079139: Epoch 610\n","2024-07-18 17:01:44.079294: Current learning rate: 0.00429\n","2024-07-18 17:03:26.093668: train_loss -0.6841\n","2024-07-18 17:03:26.094013: val_loss -0.6409\n","2024-07-18 17:03:26.094144: Pseudo dice [0.919]\n","2024-07-18 17:03:26.094253: Epoch time: 102.02 s\n","2024-07-18 17:03:27.732339: \n","2024-07-18 17:03:27.732795: Epoch 611\n","2024-07-18 17:03:27.732991: Current learning rate: 0.00428\n","2024-07-18 17:05:09.635464: train_loss -0.6894\n","2024-07-18 17:05:09.635711: val_loss -0.7368\n","2024-07-18 17:05:09.635809: Pseudo dice [0.9567]\n","2024-07-18 17:05:09.635904: Epoch time: 101.91 s\n","2024-07-18 17:05:11.241448: \n","2024-07-18 17:05:11.241854: Epoch 612\n","2024-07-18 17:05:11.242025: Current learning rate: 0.00427\n"]}]}]}